<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GaliGlobal</title>
    <link>https://www.galiglobal.com</link>
    <atom:link href="https://www.galiglobal.com/feed.xml" rel="self" type="application/rss+xml" />
    <description>GaliGlobal - Antón Rodríguez Blog</description>
    <language>en-us</language>
    <pubDate>Mon, 10 May 2021 12:21:02 +0200</pubDate>
    <lastBuildDate>Mon, 10 May 2021 12:21:02 +0200</lastBuildDate>

    
    <item>
      <title>My thoughts about the Principal role</title>
      <link>https://www.galiglobal.com/blog/2021/20210313-The-principal-role.html</link>
      <pubDate>Wed, 5 May 2021 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2021/20210313-The-principal-role.html</guid>
      <description>
      &lt;p&gt;&lt;img src=&quot;principal.jpg&quot; alt=&quot;Principal Software Engineer role&quot; title=&quot;Principal Software Engineer&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;What&apos;s a Principal Software Engineer?&lt;/h2&gt;
&lt;p&gt;One of the things I couldn&apos;t answer in the last 4-5 years was my role.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Am I a manager? No.&lt;/strong&gt; In some cases, people may report to me from an organisational point of view but my way to manage is &amp;quot;don&apos;t manage at all&amp;quot; and let the team self organize with my help. I tend to focus more on the team and processes and less on people. I&apos;m not a manager, I try to be a technical leader. Organizations that understand the &lt;a href=&quot;https://www.thekua.com/atwork/2019/02/the-trident-model-of-career-development/&quot;&gt;Trident Career Model&lt;/a&gt; have &lt;em&gt;&amp;quot;a great advantage because at scale, it is often hard to find people who have deep skills and experiences at both of these areas, and that it can be useful to discuss where someone’s focus, passion or development progression lies&amp;quot;&lt;/em&gt;. I think I could be a manager, but it wouldn&apos;t be so fun and, definitively, I don&apos;t want to be both things at the same time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Am I a developer?&lt;/strong&gt; Well, coding is something I like to do but I spent a lot more time helping others to code than coding myself. Even more important, because of frequent interruptions, I don&apos;t enjoy too much coding new features with hard deadlines. I prefer to work in proof of concepts or refactoring code because it isn&apos;t so problematic if I have to stop and resume it later. I also spend more time doing coding review than coding myself.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;An architect?&lt;/strong&gt; A big part of my work is to improve systems and platforms. Listen to problems and propose solutions. But I don&apos;t feel like the guy who does a plan which must be blindly followed by others. I don&apos;t want to be a gatekeeper who says what can be used and what can&apos;t.&lt;/p&gt;
&lt;p&gt;As Miguel Garcia pointed reviewing the article, not all architects are gatekeepers. But it may happen some times. I prefer the role of Principal because I see it as something less theoretical. It&apos;s hard to visualize a real architect building a house with their own hands. It isn&apos;t so hard to imagine a skilled workman designing and building a house. I see design and architecture as something more collaborative and myself as a facilitator.  I usually share my experience doing similar things in the past and I help to make teams think out of the box or see their problems from a different perspective. &lt;strong&gt;I want teams working with me to find the right solution together&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I also like to be involved in global architecture. As I see systems design as a collaborative task, global architecture works exactly in the same way but with other technical leaders and actors in the organization. When a C-level role defines the architecture without feedback from the technical leaders of the organization, it isn&apos;t only frustrating, it&apos;s also incomplete. Big organizations are too big to be designed by one individual (or a very small group): they need to be open and collaborative. See &lt;a href=&quot;https://www.theatlantic.com/ideas/archive/2021/04/case-disagreeing-yourself/618688/&quot;&gt;Before You Answer, Consider the Opposite Possibility&lt;/a&gt; for more info.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Am I a product manager?&lt;/strong&gt; I work a lot with the roadmap and backlog of the platforms where I&apos;m more involved. Evangelize the usage of the service is very important. But this applies more to internal platforms. For public services, it&apos;s just too much work and someone focused only on that is required. As it&apos;s a bad idea to have the product manager taking decisions on the technical side (implementation), it isn&apos;t a good thing for the Principal to go too much in Product management: define the roadmap of the product, what works for the users, etc. PMs and principals should work together and respect their boundaries. When one of them push too much, the delivery slows down because of excess technical debt or over-engineering. Both things are wrong.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Staff Engineer?&lt;/strong&gt; That&apos;s a tricky one because it&apos;s very dependant on the organization so I don&apos;t have an answer for that. In some places, the role is for seniors who jump between teams. In others, it&apos;s for engineers more focused on processes than in systems. Anyway, in my opinion, a Principal Software Engineer builds long term relations with systems and teams.&lt;/p&gt;
&lt;p&gt;The list goes on and on: Systems Engineer, Support Engineer, Project Manager, etc. Even the term &amp;quot;Individual contributor&amp;quot; seems wrong. &lt;strong&gt;My contributions aren&apos;t individual but working with individuals&lt;/strong&gt;. The reality of the role is to do whatever is necessary to make teams and platforms succeed with the freedom to choose the best way to achieve it. A sort of technical &amp;quot;Jack of all trades, master of none&amp;quot;. &lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/40#issuecomment-831733828&quot;&gt;Martín Pérez comment&lt;/a&gt; on this article explains it perfectly.&lt;/p&gt;
&lt;p&gt;One day I found this blog post in my timeline: &lt;a href=&quot;https://margint.blog/2020/10/07/some-thoughts-on-the-principal-role/&quot;&gt;Some Thoughts on the Principal Role&lt;/a&gt;. Based on this article, it was clear to me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I prefer to &lt;strong&gt;help people&lt;/strong&gt; instead of manage people.&lt;/li&gt;
&lt;li&gt;I like to be &lt;strong&gt;very involved in development&lt;/strong&gt; but not necessarily code it myself, in special features which take more time and need more focus.&lt;/li&gt;
&lt;li&gt;I help with ideas, patterns and processes to &lt;strong&gt;build better systems&lt;/strong&gt; but I don&apos;t like to tell other engineers what have to do.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What a revelation! As explained in the article, I&apos;ve been a Principal Software Engineer for years without being aware of it. Not only that, &lt;strong&gt;it&apos;s what I want to do, what makes me happy&lt;/strong&gt; nowadays. It was great to know there is a name for my role and other people out there with the same motivations and struggles. It&apos;s for them, I wrote this article. I want to share my main challenges and experiences in this role.&lt;/p&gt;
&lt;h2&gt;No clear definition of the role: the management trap&lt;/h2&gt;
&lt;p&gt;Many organizations don&apos;t understand the role. They understand they need it but not the role itself. This tends to lead to the &amp;quot;we need people with a strong technical background to lead our teams&amp;quot; approach.&lt;/p&gt;
&lt;p&gt;It&apos;s easier to fall into that trap. I think I&apos;m joining the company as Principal but I end working as Project Manager (or similar). I have experience as an Engineering Manager but even with that, things don&apos;t evolve well in this situation. If I continue working as a manager, I will slowly lose my technical skills but the organization expects them so, in the long term, I won&apos;t meet their expectations. If I focus more on the technical part, &lt;strong&gt;I will neglect the people I manage&lt;/strong&gt; which it&apos;s the most important job of a manager. If, somehow, I fight to keep both things &lt;strong&gt;I will end suffering job burnout&lt;/strong&gt;. The article &lt;a href=&quot;http://www.paulgraham.com/makersschedule.html&quot;&gt;Maker&apos;s schedule, manager&apos;s schedule&lt;/a&gt; is a great explanation about why both things aren&apos;t compatible in the long term.&lt;/p&gt;
&lt;p&gt;It isn&apos;t easy to solve this misalignment between the company and you. I usually try to &lt;strong&gt;make alliances with people managers&lt;/strong&gt; so I can focus on my role as an engineer. I also evangelize about the role and how to implement it properly in the organization. Some of my tasks (recruiting, DevRel, community) require a lot of communication with HR and it helps to make them see the need for separated technical and people career paths.&lt;/p&gt;
&lt;p&gt;If after a while things don&apos;t evolve, a job change is the only alternative. Most organizations tend to listen when their engineers leave so it&apos;s a good opportunity to help them to make this right.&lt;/p&gt;
&lt;h2&gt;Relation with managers&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Build a good relation with engineering managers is very important&lt;/strong&gt; to succeed in the role. It&apos;s quite frustrating when managers take decisions without taking engineers into account. It&apos;s especially problematic when they decide on technical things which have a huge impact on the platform. They should ask about architecture and processes. Principals should inform them to have the knowledge to report and publish to the rest of the organization what we are doing.&lt;/p&gt;
&lt;p&gt;This is particularly complex with managers who have a good technical background. Because they tend to try to manage people and systems. They are too busy so they take shortcuts: decide now, explain to the team later. It&apos;s hard to deal with this because it&apos;s an organisational issue. &lt;strong&gt;Managers should focus on people, engineers on systems. Processes should be the common ground.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Based in Eloy Coto&apos;s feedback, I&apos;m going to stop here. Relation with managers is tricky and, in many cases, very dependant of the organization. If you have been working in big organization, you already know the relation with your manager is probably one of the main factors for success. I&apos;m not particularly good on this so I need more advise than the advise I can give!&lt;/p&gt;
&lt;h2&gt;Don&apos;t be a hero&lt;/h2&gt;
&lt;p&gt;Another typical trap of the role is to become a hero. It may happen for many reasons, being typical that &lt;strong&gt;it&apos;s easier to ask you about something than to think about it&lt;/strong&gt;. So other engineers may rely on you for tasks they don&apos;t like.&lt;/p&gt;
&lt;p&gt;This isn&apos;t an issue when starting with a team but it&apos;s a huge problem in the long term. &lt;strong&gt;If after one year, you can&apos;t leave a team without impact, you&apos;ve failed in your work&lt;/strong&gt;. It&apos;s that simple.&lt;/p&gt;
&lt;p&gt;One of the best ways to avoid this is to apply &lt;strong&gt;the leader-leader approach&lt;/strong&gt; as explained in the book &lt;a href=&quot;https://www.goodreads.com/book/show/16158601-turn-the-ship-around&quot;&gt;Turn the ship around&lt;/a&gt;. Don&apos;t tell people what they have to do but help them to define next the steps and identify trade-offs. I always try to make questions instead of giving answers: &amp;quot;Have you tried ...?&amp;quot;, &amp;quot;What do you think of... ?&amp;quot;, &amp;quot;What do you propose as an alternative?&amp;quot;, etc.  &lt;a href=&quot;https://hyperbo.la/w/nemawashi/&quot;&gt;Senior Engineers build consensus&lt;/a&gt;. Mentorship is one of my main tasks.&lt;/p&gt;
&lt;p&gt;You will have a better life, and which it&apos;s more important, you will focus on what&apos;s important. Your teams will grow and learn and they will be happy because of that. &lt;strong&gt;Being a hero, you become the villain.&lt;/strong&gt; Don&apos;t do that.&lt;/p&gt;
&lt;h2&gt;Keep your optimism&lt;/h2&gt;
&lt;p&gt;Be a principal can be frustrating because your goals are now more aligned with your organization. It&apos;s a technical role but it&apos;s also oriented to people. You usually have a lot of meetings because of that, which it&apos;s probably one of the reasons you didn&apos;t become a manager in the first place. &lt;strong&gt;At some point, you may sense you aren&apos;t learning as much as you did in the past.&lt;/strong&gt; That&apos;s a warning signal for me: things have to change.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Give you some space to experiment and do things that motivates you&lt;/strong&gt; is essential to be successful in the long term. They may be not the most urgent things for the company but, in my experience, that&apos;s exactly why they are important. &lt;strong&gt;Principals should be able to see to the future and start that journey.&lt;/strong&gt; If you are stuck all the time in what&apos;s urgent, it&apos;s very difficult to do that. Nacho Garmilla, another of my mentors, wrote in &lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/40#issuecomment-835821073&quot;&gt;a comment&lt;/a&gt; that the flexibility of the role can help on this: you don&apos;t have to limit yourself to your usual tasks: you can contribute in other areas if it&apos;s something motivating.&lt;/p&gt;
&lt;p&gt;There is an excellent article about this: &lt;a href=&quot;https://noidea.dog/glue&quot;&gt;Being glue&lt;/a&gt;. It&apos;s from the perspective of a junior software engineer who wants to be promoted but it isn&apos;t because it&apos;s doing what&apos;s best for the team always. It ends badly. So, instead, try to save some time to do whatever makes you happy in your work. &lt;strong&gt;Ask for help.&lt;/strong&gt; In the end, you will discover it has also value when properly combined with Glue work.&lt;/p&gt;
&lt;p&gt;Finally, if you encounter toxic people, &lt;strong&gt;don&apos;t let them make you lose your optimism.&lt;/strong&gt; In most cases, report it to my manager and ignore them after that worked well for me. &lt;strong&gt;There are a lot of wonderful people out there&lt;/strong&gt;: focus on them!.&lt;/p&gt;
&lt;h2&gt;Don&apos;t stop coding&lt;/h2&gt;
&lt;p&gt;Coding is the best expression of the work of a Software Engineer. &lt;strong&gt;It&apos;s how we transform ideas into something real&lt;/strong&gt;. It&apos;s also a very demanding task. If you stop coding for a while, you lose a lot of fluency and it becomes very frustrating.  If you add the lack of enough long calendar slots and all the interruptions, it can be a nightmare. It&apos;s important for a Principal to feel confident when coding even if it isn&apos;t her primary task but it isn&apos;t easy to achieve it.&lt;/p&gt;
&lt;p&gt;Some tricks that help me with this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Try to &lt;strong&gt;block in your calendar some time every day for coding&lt;/strong&gt;: I usually use my early mornings. Most of the team isn&apos;t connected yet and I&apos;m fresh. Start the day with a Pull Request is a great feeling.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Avoid working on things that are on the critical path&lt;/strong&gt;: you aren&apos;t going to have time. You think you will, but you don&apos;t. Deadline will arrive and the whole process will become very frustrating: deliver late or working after-hours. Both options are bad in the long term. So be realistic, don&apos;t work on critical features. I prefer to work in Technical Debt, refactorings or Proofs of Concept. There is a lot of value there because the team don&apos;t always have time to address these things and I can work without pressure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Daily goal: code every day&lt;/strong&gt;. I track my daily tasks and I have one for coding and another one for writing/reading. It isn&apos;t always possible but at least I have it very present.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Find something fun&lt;/strong&gt;: pet projects are a good way to stay motivated and learn. They also require some time and that&apos;s very personal. Don&apos;t get frustrated if you don&apos;t have time for them, but if you do and you have fun, go for it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Coding platforms&lt;/strong&gt; are a great way to keep your skills. I recommend &lt;a href=&quot;https://exercism.io/&quot;&gt;exercism.io&lt;/a&gt;.  It&apos;s open and the exercise can be done in your favourite IDE. The feeling is quite close to a real problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Career goals&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;One of the problems in the role is what&apos;s come next&lt;/strong&gt;. The principal role is at the end of the Individual Contributor path. Indeed, your contributions come now from the group you are helping. Yes, you can aspire to add Senior or whatever level number has your company... but that&apos;s just naming, which usually implies better a salary. &lt;strong&gt;Nobody complains about a salary raise but optimize to career based on the salary is a quite bad idea if you are already covered&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You can aspire to a Distinguished / Fellow role. It&apos;s a legit goal. I&apos;m not very familiar with these roles. In my head, they mean more salary and more contact with the C-Suite. Both things are fine but they aren&apos;t intrinsic motivations (at least not for me).&lt;/p&gt;
&lt;p&gt;There is always the option to move to the Management track as Senior Engineer Manager or Director. That&apos;s fine if it&apos;s what you want to do but it&apos;s just a different role and you should be aware of that. &lt;strong&gt;It has little value as a promotion if it isn&apos;t what makes your life happier&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In summary, as Principal Software Engineer, promotions aren&apos;t going to be the goal so you need to find new ones and that&apos;s highly dependant on each person. In my case, it&apos;s to learn new things. It has been always my passion and the reason I&apos;m a software engineer. &lt;strong&gt;This role allows me to learn new things every day and help others.&lt;/strong&gt; I can&apos;t ask for anything more.&lt;/p&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;I didn&apos;t cover everything I would like but this is article is already too long and I don&apos;t want to write a book (there is already one: &lt;a href=&quot;https://www.goodreads.com/book/show/56481725-staff-engineer&quot;&gt;Staff Engineer: Leadership beyond the management track&lt;/a&gt;). I would love to know what do you think about the Principal role, especially if you disagree with me. Leave a comment on &lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/40&quot;&gt;GitHub&lt;/a&gt; or just drop me a message on &lt;a href=&quot;https://twitter.com/antonmry&quot;&gt;Twitter&lt;/a&gt;, I&apos;m always open to have a chat about the role or share my experiences.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Three simple ideas to make your life easier with Kafka</title>
      <link>https://www.galiglobal.com/blog/2021/20210430-Three-Kafka-good-practices.html</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2021/20210430-Three-Kafka-good-practices.html</guid>
      <description>
      &lt;p&gt;Apache Kafka was open-sourced by LinkedIn in early 2011. Despite all the initial limitations, it was a huge success and it became the de-facto standard for streaming data. The performance, possibility to replay events and multiple consumers independently were some of the features which disrupted the streaming arena.&lt;/p&gt;
&lt;p&gt;But Kafka has been also known for its difficult learning curve and difficulties with the operation. In my experience, both things are improved a lot in the last few years but the original gotchas remain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka has been created from the very beginning for performance, so it&apos;s by default more balanced to improve latency/throughput than reliability.&lt;/li&gt;
&lt;li&gt;One of the key ideas behind Kafka it&apos;s to put part of the responsibility on the producer and the consumer. This simple idea allows Kafka to have its legendary performance. But it makes Kafka more complex for the clients: you need to make some decisions and they will have a huge impact on the broker and the whole pipeline.&lt;/li&gt;
&lt;li&gt;Kafka can be used for many different use cases which, in the end, means it needs to be tuned for each one... and there are a lot of things to tune. Most of the decisions and knowledge required to use Kafka are based on experience and spread over the Internet in blog posts and talks. Which it&apos;s worse, one pattern can be perfectly valid for a use case and total disaster for others.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this article, we are going to cover three simple things which can help a lot to make the use of Kafka much more smooth.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;kafka-loves-small.png&quot; alt=&quot;Kafka loves small messages, topics, clusters&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Small messages&lt;/h2&gt;
&lt;p&gt;Kafka doesn&apos;t like big messages. By default, it&apos;s limited to 1Mb. You can modify &lt;a href=&quot;https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes&quot;&gt;message.max.bytes&lt;/a&gt; in the broker to allow bigger messages but it isn&apos;t usually a good idea. It requires fine tuning in the clients and the brokers and it&apos;s going to make the whole cluster less performant. Not only that, you can&apos;t change this for a particular topic but for the whole cluster which makes capacity planning much harder.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The ideal size for a message in Kafka is 1Kb&lt;/strong&gt;. I had quite performant pipelines with messages much smaller than that. It doesn&apos;t matter too much when they are small. The Kafka producer is going to put them together and send them in a batch. The broker will store them as a batch and the consumer will read them as a batch. You can configure batch size independently of message size (trading latency for throughput) so small messages are ok, big messages aren&apos;t.&lt;/p&gt;
&lt;p&gt;Another problem with big messages is that if you want to migrate to a managed service at some point, they may not support them. It&apos;s the case of &lt;a href=&quot;https://docs.confluent.io/5.2.0/cloud/limits.html&quot;&gt;Confluent Cloud&lt;/a&gt;(6 Mb), &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-faq#:~:text=The%20maximum%20message%20size%20allowed%20for%20Event%20Hubs%20is%201%20MB&quot;&gt;Azure EventHub&lt;/a&gt;(1 Mb) or &lt;a href=&quot;https://cloud.google.com/pubsub/quotas&quot;&gt;Google PubSub&lt;/a&gt;(10 Mb).&lt;/p&gt;
&lt;p&gt;I had to announce this bad news many times and deal with the developer&apos;s sad faces. Luckily, after some discussion, we always found a way to solve this without modifying &lt;a href=&quot;https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes&quot;&gt;message.max.bytes&lt;/a&gt;. Let&apos;s review three different options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Split the message into several messages&lt;/strong&gt;: this is possible almost always even if it isn&apos;t easy to see it at first. Look at the schema and see how you can split it into messages which have sense individually. It&apos;s perfectly ok to have information duplicated between them, typically metadata. As we mentioned before, Kafka is going to send them in batches, and almost always, compressed (Hint: don&apos;t use E2E compression with Kafka is almost always a bad idea) so duplicates don&apos;t have a big impact on the overall size of the batch.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Move messages to different storage&lt;/strong&gt;: when messages are too big and there is no way to split them (images, PDFs, etc.) is usually better to publish them in another place as S3, and send the URI of the stored file in the Kafka message. There are even &lt;a href=&quot;https://github.com/bakdata/kafka-s3-backed-serde&quot;&gt;some libraries&lt;/a&gt; that allow doing this in an automatic way: the serializer writes to S3 when the message is too big, the deserializer downloads the payload from S3 when it receives a URI.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use something different than Kafka&lt;/strong&gt;: almost all messaging brokers have problems with big messages but Kafka has a lower limit. Apache Pulsar for example maximum message by default is 10 Mb and it has a feature to split it into smaller messages and re-join it in the producer when needed. This isn&apos;t a solution for a specific use case but, if you know you are going to deal with a lot of big messages, it may be an important factor to choose one technology or another.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If anything of that works, then go and increase &lt;a href=&quot;https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes&quot;&gt;message.max.bytes&lt;/a&gt;. It isn&apos;t the end of the world but be aware some fine tuning which requires Kafka expertise may be needed.&lt;/p&gt;
&lt;h2&gt;Small topics&lt;/h2&gt;
&lt;p&gt;Another quite problematic thing with Kafka is big topics. This tends to happen organically. Instead of creating a new topic for a different type of information, you use one existent which has the same consumers. There are several problems with this approach:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Consumers interested in some part of the data have to read everything&lt;/strong&gt; and filter to select the data they need. That&apos;s very inefficient. There are some tricks to avoid the deserialization of the non-required messages but the consumer has to read them and consume network bandwidth anyway.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A big topic usually means a lot of partitions&lt;/strong&gt;. It&apos;s how Kafka works: a topic is divided into partitions over different brokers. If you need more throughput, you increase the number. That’s great but there are some caveats: you can’t decrease the number of partitions. Also, when adding partitions, consumers are affected and some lag will happen. Also, there is some coordination Kafka has to do which is proportional to the number of partitions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Big topics mean big clusters&lt;/strong&gt;. We’ll cover big clusters later but it’s very usual to split the load between different clusters. If you have small topics, it’s easy to move topics to a different cluster. If not, it may be impossible.&lt;/li&gt;
&lt;li&gt;There are several operations in Kafka that require &lt;strong&gt;creating a new version of the topic&lt;/strong&gt;: typically decrease the number of partitions or introduce breaking changes in the message schema. In that case, you will need a V2 topic. This is very usual and automation is key to make the migration process smooth. When you have small topics, that process is much simpler because there are fewer consumers impacted.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The list is much bigger but it’s probably enough to illustrate the point. There are also some problems with small topics, for example, if a consumer needs to read all the messages. Kafka has evolved to solve it: it’s quite easy to subscribe to a list of topics. You can also &lt;a href=&quot;https://kafka.apache.org/26/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#subscribe-java.util.regex.Pattern-org.apache.kafka.clients.consumer.ConsumerRebalanceListener&quot;&gt;specify a Regex&lt;/a&gt; pattern so topics will be assigned dynamically even if they are created later.&lt;/p&gt;
&lt;h2&gt;Small clusters&lt;/h2&gt;
&lt;p&gt;Big clusters are hard to maintain even for the companies with the most Kafka experience. You can see in &lt;a href=&quot;https://twitter.com/gunnarmorling/status/1384903606407729153&quot;&gt;this thread&lt;/a&gt; many of the most important companies recommending small clusters and Netflix wrote &lt;a href=&quot;https://netflixtechblog.com/kafka-inside-keystone-pipeline-dd5aeabaf6bb&quot;&gt;an article&lt;/a&gt; about it (Kafka deployment strategy section).&lt;/p&gt;
&lt;p&gt;Another problem for big clusters is &lt;strong&gt;configurations that are done at cluster-level&lt;/strong&gt; (&lt;a href=&quot;https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes&quot;&gt;message.max.bytes&lt;/a&gt;, auto.create.topics.enable (for CDC use cases), compaction/retention threads, etc.) which can be use-case dependent and it’s interesting to be able to optimize them for particular loads.&lt;/p&gt;
&lt;p&gt;Another good point for small clusters is &lt;strong&gt;to make easier upgrades&lt;/strong&gt; which it’s something very important in Kafka. The community is super active and Kafka has evolved a lot in the last years. Being able to run the last stable version of Kafka is almost mandatory for resilience and saving cost in the cloud. A great example of this is Confluent Cloud which only supports a shortlist of the last versions. If you use it, you will need to upgrade to newer versions at some point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Small clusters in the cloud are particularly handy&lt;/strong&gt;. I know a company (gaming) with very short-time huge peaks of traffic. That’s problematic for Kafka because you can’t easily add/decrease the number of partitions. So for those situations, we automatically created a new cluster with much more resources and dynamically migrated all the traffic to the new one. Once the peak has passed, we repeat the same operation in the inverse order. This isn’t usual but it gives a good view of what you can do in the cloud when your clusters are split, they are easy to manage and you can control producers and consumers.&lt;/p&gt;
&lt;p&gt;One of the problems with small clusters is when you want to join data from different topics. It can be quite complex when topics are in different clusters. Because of that, it’s usually appropriated to split the cluster by business domain or type/requirements of the load so you don’t need to replicate (too much) data between clusters.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;This is a list of only three things (but there are much more!) that may help to use Kafka properly and avoid the need to look for alternatives. They are based on my previous experience. They worked well for me until now but don&apos;t use them blindly. It&apos;s perfectly fine to break any of those rules, the point is to do it by being aware of the challenges and plan for the consequences.&lt;/p&gt;
&lt;p&gt;Did I miss something? You can comment on &lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/39&quot;&gt;GitHub&lt;/a&gt; or just drop me a note on &lt;a href=&quot;https://twitter.com/antonmry&quot;&gt;Twitter&lt;/a&gt;!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>How to build and debug a Flink pipeline based in Event Time</title>
      <link>https://www.galiglobal.com/blog/2021/20210207-Flink-event-time.html</link>
      <pubDate>Sun, 28 Feb 2021 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2021/20210207-Flink-event-time.html</guid>
      <description>
      &lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;One of the most important concepts for stream-processing frameworks is the concept of time. There are different concepts of time:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Processing time&lt;/strong&gt;: it&apos;s the time-based on the clock of the machine where the event is being processed. It&apos;s easy to use but because that time changes when the job is executed, the result of the job isn&apos;t consistent. Each time you execute the job, you may have different results. This isn&apos;t an acceptable trade-off for many use cases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Event time&lt;/strong&gt;: it&apos;s the time-based on some of the fields in the event, typically a timestamp field. Each time you execute the pipeline with the same input, you obtain the same result which it&apos;s a good thing. But it also tends to be a bit harder to work with it for several reasons. We&apos;ll cover them later in the article.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ingestion time&lt;/strong&gt;: it&apos;s based on the timestamp when the event was ingested in the streaming platform (Kafka) and it usually goes in the metadata. From a Flink perspective, we can consider it a particular mix of Event time and processing time with the disadvantages of both.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://flink.apache.org/&quot;&gt;Apache Flink&lt;/a&gt; has excellent support for Event time processing, probably the best of the different stream-processing frameworks available. For more information, you can read &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.12/concepts/timely-stream-processing.html#notions-of-time-event-time-and-processing-time&quot;&gt;Notions of Time: Event Time and Processing Time&lt;/a&gt; in the official documentation. If you prefer videos, &lt;a href=&quot;https://www.youtube.com/watch?v=QVDJFZVHZ3c&quot;&gt;Streaming Concepts &amp;amp; Introduction to Flink - Event Time and Watermarks&lt;/a&gt; is a good explanation.&lt;/p&gt;
&lt;p&gt;In this article, we&apos;ll take a look at Event time based pipelines and also to some common problems and misunderstandings working on this type of pipelines.&lt;/p&gt;
&lt;h2&gt;Timestamps and watermarks&lt;/h2&gt;
&lt;p&gt;When we speak about timestamps in Flink, we are referring to a particular field in the event.  We can extract it and make it available to Flink so it knows what&apos;s the actual time from the pipeline perspective. The format expected by Flink is &lt;a href=&quot;https://en.wikipedia.org/wiki/Unix_time&quot;&gt;Unix time&lt;/a&gt;, specified as milliseconds since the Java epoch of 1970-01-01T00:00:00Z, so we may need to do some type of conversion. To be able to map current time with the event timestamp, Flink expects an implementation of the &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/api/java/org/apache/flink/api/common/eventtime/TimestampAssigner.html&quot;&gt;TimestampAssigner&lt;/a&gt;. We&apos;ll see later an example.&lt;/p&gt;
&lt;p&gt;Once Flink knows what time it is, it&apos;s the moment to generate a watermark. This is one of the most surprising and genial thinks working with Flink. A watermark is a special type of event. That means, it flows through your job and it&apos;s processed under the hood for each task. This is a clever way to propagate a change through the entire pipeline and it&apos;s used for more things in flink, like for example &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/ops/state/savepoints.html&quot;&gt;savepoints&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Generate watermarks is the way to tell the system about progress in event time. To do it, you use a &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/api/java/org/apache/flink/api/common/eventtime/WatermarkGenerator.html&quot;&gt;WatermarkGenerator&lt;/a&gt;. We&apos;ll see later an example.&lt;/p&gt;
&lt;p&gt;Both together, &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/api/java/org/apache/flink/api/common/eventtime/TimestampAssigner.html&quot;&gt;TimestampAssigner&lt;/a&gt; and &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/api/java/org/apache/flink/api/common/eventtime/WatermarkGenerator.html&quot;&gt;WatermarkGenerator&lt;/a&gt; form a &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/api/common/eventtime/WatermarkStrategy.html&quot;&gt;WatermarkStrategy&lt;/a&gt; which defines how to generate Watermarks in the stream sources.&lt;/p&gt;
&lt;h2&gt;Use case example&lt;/h2&gt;
&lt;p&gt;Let&apos;s illustrate this with an example. Our flink job will receive readings from different sensors. Every sensor will send measures for each 100ms.  We would like to detect when a measure from a particular sensor is missing, for example, because it was off-line.&lt;/p&gt;
&lt;p&gt;Sensors send a JSON file like this one:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json { &amp;quot;id&amp;quot;: &amp;quot;sensor0&amp;quot;, &amp;quot;timestamp&amp;quot;: 0, &amp;quot;measure&amp;quot;: 0.1 }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The job will generate a normal event but the measure value will have value -1 when the event wasn&apos;t generated by the sensor or lost in the network.&lt;/p&gt;
&lt;h2&gt;Initial implementation with periodic watermark generators&lt;/h2&gt;
&lt;p&gt;We&apos;ll have to choose a &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/api/common/eventtime/WatermarkStrategy.html&quot;&gt;WatermarkStrategy&lt;/a&gt;. We have several options, let&apos;s start with Periodic WatermarkGenerator:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WatermarkStrategy.&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/event_timestamp_extractors.html#fixed-amount-of-lateness&quot;&gt;forBoundedOutOfOrderness&lt;/a&gt;: this is a periodic generator that allows dealing with records out of order when it&apos;s inside a defined range.&lt;/li&gt;
&lt;li&gt;WatermarkStrategy.&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/event_timestamp_extractors.html#monotonously-increasing-timestamps&quot;&gt;forMonotonousTimestamps&lt;/a&gt;: this is the same as &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/event_timestamp_extractors.html#fixed-amount-of-lateness&quot;&gt;forBoundedOutOfOrderness&lt;/a&gt; but the out-of-order tolerance is zero.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In both cases, the framework invokes periodically the Strategy which generates the watermark. &lt;code&gt;setAutoWatermarkInterval&lt;/code&gt; allows lo define that periodicity:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java env.getConfig().setAutoWatermarkInterval(Duration.ofMillis(100).toMillis());&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The problem with this approach is we are mixing processing and event time so the result won&apos;t be deterministic, or even correct depending on the circumstances.&lt;/p&gt;
&lt;p&gt;For example, with &lt;a href=&quot;https://github.com/antonmry/flink-playground/blob/main/src/main/java/galiglobal/flink/eventTime/BoundedOutOfOrdernessStrategyJob.java&quot;&gt;BoundedOutOfOrdernessStrategyJob&lt;/a&gt;, we start defining the watermark interval each 100 ms.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java env.getConfig().setAutoWatermarkInterval(Duration.ofMillis(100).toMillis());&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then we create the DataStream with the watermarks:&lt;/p&gt;
&lt;p&gt;```java DataStream&lt;SensorData&gt; sensorStream = env.addSource(source) .returns(TypeInformation.of(SensorData.class));&lt;/p&gt;
&lt;p&gt;var sensorEventTimeStream = sensorStream.assignTimestampsAndWatermarks( WatermarkStrategy.&lt;SensorData&gt;forBoundedOutOfOrderness( Duration.ofMillis(100) ).withTimestampAssigner( (event, timestamp) -&amp;gt; event.getTimestamp() ) ); ```&lt;/p&gt;
&lt;p&gt;To detect missing events, we used a timer so we need a keyed stream and a KeyedProcessFunction:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java sensorEventTimeStream .keyBy((event) -&amp;gt; event.getId()) .process(new TimeoutFunction()) .addSink(sink);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/antonmry/flink-playground/blob/main/src/main/java/galiglobal/flink/eventTime/TimeoutFunction.java&quot;&gt;TimeoutFunction&lt;/a&gt; stores each event in the state and creates a timer for each one. It cancels the timer if the next event arrives on time. If not, &lt;code&gt;onTimer&lt;/code&gt; should be invoked and the event in the state identifying the missing sensor is emitted.&lt;/p&gt;
&lt;h2&gt;Testing and debugging the first implementation&lt;/h2&gt;
&lt;p&gt;Let&apos;s create a simple test: two sensors and one of them misses one of the measures. When we launch the test &lt;a href=&quot;https://github.com/antonmry/flink-playground/blob/main/src/test/java/galiglobal/flink/eventTime/StreamingJobTest.java#L24&quot;&gt;testBoundedOutOfOrdernessStrategyJob&lt;/a&gt;, we obtain the following result:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Timer: 500 -&amp;gt; sensor0&lt;br /&gt;
Timer: 500 -&amp;gt; sensor1&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=0, measure=0.1}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=0, measure=0.2}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=100, measure=0.3}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=100, measure=0.4}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=200, measure=0.5}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=300, measure=0.7}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=300, measure=0.8}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=400, measure=0.9}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=400, measure=1.0}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=500, measure=-1.0}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=500, measure=-1.0}&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The job doesn&apos;t detect the missing event but it detects the end of the stream. Why? It&apos;s time to do some debugging. Debug watermarks issues isn&apos;t easy. There are three options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check the current watermark metric. See &lt;a href=&quot;https://www.galiglobal.com/blog/2021/20210130-Flink-setup.html#metrics&quot;&gt;my previous article about the Flink setup&lt;/a&gt;. This is ideal for real jobs but a bit more complicated with tests because they finish almost immediately.&lt;/li&gt;
&lt;li&gt;Check the current watermark in the Flink UI: as with the previous one, it doesn&apos;t work with tests if they finish too quickly.&lt;/li&gt;
&lt;li&gt;Introduce a custom operator which has access to the current watermark. I used this one which allows us also to play with some more advanced operators.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;eventtime-flink.png&quot; alt=&quot;Flink UI&quot; title=&quot;Flink UI&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/antonmry/flink-playground/blob/main/src/main/java/galiglobal/flink/eventTime/StreamWatermarkDebugFilter.java&quot;&gt;StreamWatermarkDebugFilter&lt;/a&gt; is the internal class &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/api/java/org/apache/flink/streaming/api/operators/StreamFilter.html&quot;&gt;StreamFilter&lt;/a&gt; with some minor modifications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We don&apos;t want to filter any event. This could be improved a bit avoiding the filtering but because it&apos;s a class only for debugging, I didn&apos;t care too much.&lt;/li&gt;
&lt;li&gt;In the method &lt;code&gt;processWatermark&lt;/code&gt;, emit the watermark to be consumed for the next operator and print it for debugging purposes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We apply the new operator to the job:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java sensorEventTimeStream .transform(&amp;quot;debugFilter&amp;quot;, sensorEventTimeStream.getType(), new StreamWatermarkDebugFilter&amp;lt;&amp;gt;()) .keyBy((event) -&amp;gt; event.getId()) .process(new TimeoutFunction()) .addSink(sink);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We can see the watermarks generated executing the test again:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Watermark: 9223372036854775807&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Only one watermark is generated: &lt;code&gt;Long.MAX_VALUE&lt;/code&gt;. This watermark seems to be executed at the end of the job because it&apos;s the bigger possible watermark. This is consequent with the last two timers we see. They are launched with timestamp 500 but there is no watermark with that value: it&apos;s just the end of the job.&lt;/p&gt;
&lt;p&gt;So the Watermark generator isn&apos;t generating a watermark. The only reason I see for that it&apos;s because the job is ending before any watermark is generated. We could set the periodic generation with a smaller value but the problem remains: we are mixing processing and event time so it&apos;s really hard to know how the pipeline is going to proceed in some conditions.&lt;/p&gt;
&lt;h2&gt;Final implementation with a Punctuated WatermarkGenerator&lt;/h2&gt;
&lt;p&gt;We are going to create a generator which will be able to generate watermarks based in the elements of the stream: a &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/event_timestamps_watermarks.html#writing-a-punctuated-watermarkgenerator&quot;&gt;Punctuated WatermarkGenerator&lt;/a&gt;. So we create a new job &lt;a href=&quot;https://github.com/antonmry/flink-playground/blob/main/src/main/java/galiglobal/flink/eventTime/CustomStrategyJob.java&quot;&gt;CustomStrategyJob&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java var sensorEventTimeStream = sensorStream .assignTimestampsAndWatermarks( new WatermarkStrategy&amp;lt;SensorData&amp;gt;() { @Override public WatermarkGenerator&amp;lt;SensorData&amp;gt; createWatermarkGenerator( WatermarkGeneratorSupplier.Context context) { return new BoundedOutOfOrdernessWatermarks&amp;lt;&amp;gt;( Duration.ofMillis(0) ) { @Override public void onEvent( SensorData event, long eventTimestamp, WatermarkOutput output) { super.onEvent(event, eventTimestamp, output); super.onPeriodicEmit(output); } }; } } .withTimestampAssigner((event, timestamp) -&amp;gt; event.getTimestamp()) );&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It&apos;s similar to &lt;code&gt;BoundedOutOfOrdernessWatermarks&lt;/code&gt; but we modify the method &lt;code&gt;onEvent&lt;/code&gt; to invoke &lt;code&gt;onPeriodicEmit&lt;/code&gt; which emits the watermark. So, instead of being invoked by the framework, now it emits a new watermark each time it receives an event.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;eventtime-pipeline.png&quot; alt=&quot;Flink Pipeline with Punctuated Generator&quot; title=&quot;Flink Pipeline with Punctuated Generator&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The test produces the following output now:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Watermark: -1&lt;br /&gt;
Watermark: -1&lt;br /&gt;
Watermark: 99&lt;br /&gt;
Watermark: 99&lt;br /&gt;
Watermark: 199&lt;br /&gt;
Watermark: 299&lt;br /&gt;
Watermark: 299&lt;br /&gt;
Watermark: 399&lt;br /&gt;
Watermark: 399&lt;br /&gt;
Watermark: 9223372036854775807&lt;br /&gt;
Watermark: 9223372036854775807&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This seems a lot better but there is a problem. We don&apos;t have a watermark generated for the sensor 0 at 199. The problem here it&apos;s our stream is keyed, so it&apos;s being processed by two different tasks. Watermarks generations works per task so they don&apos;t advance at the same time. To solve this, the easier way is to set parallelism to 1. Unfortunately, this approach isn&apos;t very efficient.&lt;/p&gt;
&lt;p&gt;Relaunching the test, we obtain the expected result:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;SensorData{id=&apos;sensor0&apos;, timestamp=0, measure=0.1}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=0, measure=0.2}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=100, measure=0.3}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=100, measure=0.4}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=200, measure=0.5}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=300, measure=0.7}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=200, measure=-1.0}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=300, measure=0.8}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=400, measure=0.9}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=400, measure=1.0}&lt;br /&gt;
SensorData{id=&apos;sensor0&apos;, timestamp=500, measure=-1.0}&lt;br /&gt;
SensorData{id=&apos;sensor1&apos;, timestamp=500, measure=-1.0}&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Summary and next steps&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://flink.apache.org/&quot;&gt;Apache Flink&lt;/a&gt; is a great framework and it supports Event time in a nice way. The concept of watermarks as events in the pipeline is superb and full of advantages over other frameworks. But it&apos;s also quite complex to understand because:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The official documentation is scarce.&lt;/li&gt;
&lt;li&gt;APIs have changed a lot between versions. It&apos;s hard to find updated examples even in GitHub.&lt;/li&gt;
&lt;li&gt;Debug Event Time pipelines is hard.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I wrote this article to contribute to these points. But I have yet some doubts about different points in Event Time so take my conclusions with scepticism and draw your own. If they are different or you would like to share your thoughts, I would appreciate knowing more about it.&lt;/p&gt;
&lt;p&gt;There are some resources that helped me a lot and they may help you too:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Book &lt;a href=&quot;https://www.goodreads.com/book/show/34431411-stream-processing-with-apache-flink&quot;&gt;Stream Processing with Apache Flink: Fundamentals, Implementation, and Operation of Streaming Applications&lt;/a&gt;: chapter 6 provides the better explanation I found about watermarks with some nice diagrams. It&apos;s a bit outdated now but the general concepts apply in the same way.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43864.pdf&quot;&gt;The Dataflow Model&lt;/a&gt; paper.&lt;/li&gt;
&lt;li&gt;Flink mail list: there are some very interesting discussions about this particular topic and people tend to help. I recommend two particular threads which I found very illustrative:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Timers-not-firing-until-stream-end-td41015.html&quot;&gt;Timers not firing until stream end&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/assignTimestampsAndWatermarks-not-work-after-KeyedStream-process-td27364.html&quot;&gt;assignTimestampsAndWatermarks not work after Keyed&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Source code is on this &lt;a href=&quot;https://github.com/antonmry/flink-playground&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Did I miss something? You can leave a comment on &lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/38&quot;&gt;GitHub&lt;/a&gt; or just drop me a message on &lt;a href=&quot;https://twitter.com/antonmry&quot;&gt;Twitter&lt;/a&gt;!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Flink setup for development (and some IntelliJ Idea cool tricks)</title>
      <link>https://www.galiglobal.com/blog/2021/20210130-Flink-setup.html</link>
      <pubDate>Sat, 30 Jan 2021 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2021/20210130-Flink-setup.html</guid>
      <description>
      &lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://flink.apache.org/&quot;&gt;Apache Flink&lt;/a&gt; is an open-source, unified stream-processing and batch-processing framework. As any of those framework, start to work with it can be a challenge. Even if there is a good &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/local_installation.html&quot;&gt;Getting Started&lt;/a&gt; or a great (and free) &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/&quot;&gt;Hands-on Training&lt;/a&gt;, there are always questions about how to start, how to debug problems or how to launch the project in your IDE.&lt;/p&gt;
&lt;p&gt;In this article, I summarize some of the notes I&apos;ve been writing since I started with Flink. If Flink is something new for you, it&apos;s an easy guide to follow. If you are already an experienced Flink developer, there are some tricks you may find useful: access to JMX metrics, profiling, etc.&lt;/p&gt;
&lt;p&gt;The source code is available in this &lt;a href=&quot;https://github.com/antonmry/flink-playground&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Install Flink&lt;/h2&gt;
&lt;p&gt;The first step is to install Flink. This is straightforward, just go to the Flink download page and download it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh wget https://archive.apache.org/dist/flink/flink-1.12.0/flink-1.12.0-bin-scala_2.12.tgz tar -zxvf flink-1.12.0-bin-scala_2.12.tgz&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Note: it&apos;s a good idea to create a variable $FLINK_HOME pointing to the Flink folder.&lt;/p&gt;
&lt;p&gt;Start the cluster:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh $FLINK_HOME/bin/start-cluster.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can access the &lt;a href=&quot;http://localhost:8081/&quot;&gt;Flink Web Dashboard&lt;/a&gt; in your browser.&lt;/p&gt;
&lt;p&gt;We aren&apos;t going to need it initially so it&apos;s better to stop it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh $FLINK_HOME/bin/stop-cluster.sh&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Bootstrap a Flink job&lt;/h2&gt;
&lt;p&gt;To bootstrap the project, just execute the following Maven command:&lt;/p&gt;
&lt;p&gt;```sh mvn archetype:generate                               &lt;br /&gt;
-DarchetypeGroupId=org.apache.flink &lt;br /&gt;
-DarchetypeArtifactId=flink-quickstart-java &lt;br /&gt;
-DarchetypeVersion=1.12.0 &lt;br /&gt;
-DgroupId=galiglobal &lt;br /&gt;
-DartifactId=flink-playground &lt;br /&gt;
-Dversion=0.1 &lt;br /&gt;
-Dpackage=galiglobal.flink &lt;br /&gt;
-DinteractiveMode=false&lt;/p&gt;
&lt;p&gt;cd flink-playground ```&lt;/p&gt;
&lt;p&gt;The structure of the project is quite simple:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;. ├── pom.xml └── src └── main ├── java │   └── galiglobal │   └── flink │   ├── BatchJob.java │   └── StreamingJob.java └── resources └── log4j2.properties&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We are going to focus only on &lt;code&gt;StreamingJob.java&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Import and run the job in IntelliJ IDEA&lt;/h2&gt;
&lt;p&gt;We are going only to cover my favourite Java IDE: IntelliJ IDEA. Other IDEs should work similarly. First of all, import in the IDE as a maven project. You can do it easily from the command-line.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh idea pom.xml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can go to &lt;code&gt;StreamingJob.java&lt;/code&gt; and execute it as a normal Java application using the Shift+F10 shortcut on Linux/Windows. An error like this should appear in the output:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.NoClassDefFoundError: org/apache/flink/streaming/api/environment/StreamExecutionEnvironment at galiglobal.flink.StreamingJob.main(StreamingJob.java:39) Caused by: java.lang.ClassNotFoundException: org.apache.flink.streaming.api.environment.StreamExecutionEnvironment at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ... 1 more&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a particular problem of Flink running in the IDE: some dependencies are missing. To solve it, go to &lt;code&gt;Run&lt;/code&gt; -&amp;gt; &lt;code&gt;Edit Configuration&lt;/code&gt; -&amp;gt; &lt;code&gt;Modify options&lt;/code&gt; -&amp;gt; &lt;code&gt;Use classpath of module&lt;/code&gt; and in the new field, mark &lt;code&gt;Include dependencies with &amp;quot;Provided&amp;quot; scope&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-idea-run-configuration.png&quot; alt=&quot;Run configuration for Flink&quot; title=&quot;Run configuration for Flink&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Re-run the job and a new error appears:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.IllegalStateException: No operators defined in streaming topology. Cannot execute. at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getStreamGraphGenerator(StreamExecutionEnvironment.java:2000) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getStreamGraph(StreamExecutionEnvironment.java:1991) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getStreamGraph(StreamExecutionEnvironment.java:1976) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1822) at galiglobal.flink.StreamingJob.main(StreamingJob.java:62)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It&apos;s time to create our Flink job.&lt;/p&gt;
&lt;h2&gt;Develop our first Flink job&lt;/h2&gt;
&lt;p&gt;Let&apos;s add a new Java class to our project called &lt;code&gt;RandomLongSource&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;```java public class RandomLongSource extends RichParallelSourceFunction&lt;Long&gt; {&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private volatile boolean cancelled = false;
private Random random;

@Override
public void open(Configuration parameters) throws Exception {
    super.open(parameters);
    random = new Random();
}

@Override
public void run(SourceContext&amp;lt;Long&amp;gt; ctx) throws Exception {
    while (!cancelled) {
        Long nextLong = random.nextLong();
        synchronized (ctx.getCheckpointLock()) {
            ctx.collect(nextLong);
        }
    }
}

@Override
public void cancel() {
    cancelled = true;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;} ```&lt;/p&gt;
&lt;p&gt;This class is just generating an infinite series of long numbers to feed our job.&lt;/p&gt;
&lt;p&gt;Let&apos;s modify now &lt;code&gt;StreamingJob.java&lt;/code&gt; to process it and print the result:&lt;/p&gt;
&lt;p&gt;```java public class StreamingJob { private SourceFunction&lt;Long&gt; source; private SinkFunction&lt;Long&gt; sink;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public StreamingJob(SourceFunction&amp;lt;Long&amp;gt; source, SinkFunction&amp;lt;Long&amp;gt; sink) {
    this.source = source;
    this.sink = sink;
}

public void execute() throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

    DataStream&amp;lt;Long&amp;gt; LongStream =
        env.addSource(source)
            .returns(TypeInformation.of(Long.class));

    LongStream
        .map(new IncrementMapFunction())
        .addSink(sink);

    env.execute();
}

public static void main(String[] args) throws Exception {
    StreamingJob job = new StreamingJob(new RandomLongSource(), new PrintSinkFunction&amp;lt;&amp;gt;());
    job.execute();
}

public class IncrementMapFunction implements MapFunction&amp;lt;Long, Long&amp;gt; {

    @Override
    public Long map(Long record) throws Exception {
        return record + 1;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;} ```&lt;/p&gt;
&lt;p&gt;Note: this class is from the &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/&quot;&gt;Hands-on Training&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you execute it, you will see an infinite list of long numbers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;...&lt;br /&gt;
3&amp;gt; 3869376031196493001&lt;br /&gt;
12&amp;gt; 4265560998598976840&lt;br /&gt;
12&amp;gt; -7434045225389162179&lt;br /&gt;
1&amp;gt; 3964290136030554255&lt;br /&gt;
1&amp;gt; 8881056576399978883&lt;br /&gt;
...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note: The 3&amp;gt;, 12&amp;gt;, 1&amp;gt; indicate which sub-task (i.e., thread) produced the output.&lt;/p&gt;
&lt;p&gt;This is one of the most surprising things for Flink beginners: you don&apos;t need a cluster to develop a Flink job, you can easily do it locally from your IDE and it works quite well.&lt;/p&gt;
&lt;p&gt;There are some minor differences. For example, to access the &lt;a href=&quot;http://localhost:8081/&quot;&gt;Flink Web Dashboard&lt;/a&gt; you will need to add the following dependency to maven:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;xml &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.flink&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;flink-runtime-web_2.11&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${flink.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And modify the &lt;code&gt;env&lt;/code&gt; variable with the following code:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java Configuration conf = new Configuration(); StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Note: credit goes to this &lt;a href=&quot;https://stackoverflow.com/questions/46988499/flink-webui-when-running-from-ide&quot;&gt;StackOverflow answer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Re-run the job and you should be able to access the &lt;a href=&quot;http://localhost:8081/&quot;&gt;Flink Web Dashboard&lt;/a&gt; and see your job running:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-dashboard.png&quot; alt=&quot;Flink Dashboard in local mode&quot; title=&quot;Flink Dashboard in local mode&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Debug with breakpoints&lt;/h2&gt;
&lt;p&gt;One of the nice things of run Flink jobs in your IDE is to able to debug your Flink job &lt;a href=&quot;https://www.jetbrains.com/help/idea/using-breakpoints.html&quot;&gt;using breakpoints&lt;/a&gt; as usual.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-breakpoint.png&quot; alt=&quot;Flink breakpoints&quot; title=&quot;Flink breakpoints&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Profiling&lt;/h2&gt;
&lt;p&gt;Other nice thing you may use with IntelliJ is profiling to research and improve the performance of your jobs. See &lt;a href=&quot;https://blog.jetbrains.com/idea/2020/03/profiling-tools-and-intellij-idea-ultimate/&quot;&gt;Profiling Tools and IntelliJ IDEA Ultimate&lt;/a&gt; for more info. It works well with this setup:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-profiler.png&quot; alt=&quot;Flink with IDEA profiler&quot; title=&quot;Flink with IDEA profiler&quot; /&gt;&lt;/p&gt;
&lt;p&gt;You can also use VisualVM and launch it from IntelliJ with the &lt;a href=&quot;https://github.com/krasa/VisualVMLauncher/&quot;&gt;VisualVMLauncher plugin&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-visualvm.png&quot; alt=&quot;Flink with VisualVM&quot; title=&quot;Flink with VisualVM&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Metrics&lt;/h2&gt;
&lt;p&gt;Flink generates metrics exposed through different interfaces including JMX. See &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.12/ops/metrics.html#metrics&quot;&gt;Flink metrics&lt;/a&gt; for more info.&lt;/p&gt;
&lt;p&gt;To activate it, add the following dependency to &lt;code&gt;pom.xml&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;xml &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.flink&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;flink-metrics-jmx_2.11&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${flink.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And change the &lt;code&gt;env&lt;/code&gt; variable to expose metrics in the JMX interface:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java Properties props = new Properties(); props.put(&amp;quot;metrics.reporter.jmx.factory.class&amp;quot;, &amp;quot;org.apache.flink.metrics.jmx.JMXReporterFactory&amp;quot;); Configuration conf = ConfigurationUtils.createConfiguration(props); StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);&lt;/code&gt; Run the job as usual and open it in VisualVM. You need to install the &lt;a href=&quot;https://visualvm.github.io/plugins.html&quot;&gt;VisualVM MBeans Browser&lt;/a&gt;. Metrics should be available in the MBeans tab:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-metrics.png&quot; alt=&quot;Flink metrics with VisualVM&quot; title=&quot;Flink metrics with VisualVM&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Logging&lt;/h2&gt;
&lt;p&gt;Let&apos;s add some proper logging to our job. First of all, add the following field to &lt;code&gt;StreamingJob.java&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java private static final Logger LOG = LoggerFactory.getLogger(StreamingJob.class);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let&apos;s delete the longStream variable and create a new one with some log messages:&lt;/p&gt;
&lt;p&gt;```java LOG.debug(&amp;quot;Start Flink example job&amp;quot;);&lt;/p&gt;
&lt;p&gt;DataStreamSink&lt;Long&gt; logTestStream = env.fromElements(0L, 1L, 2L) .map(new IncrementMapFunction()) .addSink(sink);&lt;/p&gt;
&lt;p&gt;LOG.debug(&amp;quot;Stop Flink example job&amp;quot;); ```&lt;/p&gt;
&lt;p&gt;Modify &lt;code&gt;src/main/resources/log4j2.properties&lt;/code&gt; to use the DEBUG log level:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rootLogger.level = DEBUG&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Re-run the job and you should see the new log traces:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-logtraces.png&quot; alt=&quot;Flink log messages&quot; title=&quot;Flink log messages&quot; /&gt;&lt;/p&gt;
&lt;p&gt;When running the job locally, the log level is quite verbose and it may be hard to find your messages between the Flink messages. Let&apos;s configure that. Edit &lt;code&gt;src/main/resources/log4j2.properties&lt;/code&gt; again to add the following lines:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;logger.flink.name = org.apache.flink logger.flink.level = warn&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Re-run the job and you should only see the proper logs messages.&lt;/p&gt;
&lt;h2&gt;Tests&lt;/h2&gt;
&lt;p&gt;One of the most important things when creating jobs is to have proper tests you can run from your IDE. It will make you go faster because you can make changes, run the test and be sure everything is working as it was before the change. That level of confidence in your changes worths the cost of writing the test from the very beginning.&lt;/p&gt;
&lt;p&gt;Add the following dependency to your &lt;code&gt;pom.xml&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;xml &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.flink&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;flink-test-utils-junit&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${flink.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Move the inner class &lt;code&gt;IncrementMapFunction&lt;/code&gt; to their own file:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-refactor.png&quot; alt=&quot;Refactor Map function&quot; title=&quot;Refactor Map function&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Now let&apos;s add a unit test to &lt;code&gt;src/test/java&lt;/code&gt; which tests this function:&lt;/p&gt;
&lt;p&gt;```java public class StreamingJobTest {&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Test
public void testMap() throws Exception {
    IncrementMapFunction statelessMap = new IncrementMapFunction();
    Long out = statelessMap.map(1L);
    Assert.assertEquals(2L, out.longValue());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Run the test from the IDE and see the result:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;flink-unittest.png&quot; alt=&quot;Flink Unit Test&quot; title=&quot;Flink Unit test&quot; /&gt;&lt;/p&gt;
&lt;p&gt;For more information, see &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html&quot;&gt;Testing Flink Jobs&lt;/a&gt; in the official documentation. It&apos;s particularly interesting how to &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html#testing-flink-jobs&quot;&gt;test complete jobs&lt;/a&gt;. You can find also good examples in the &lt;a href=&quot;https://github.com/apache/flink-training/blob/master/ride-cleansing/src/test/java/org/apache/flink/training/exercises/ridecleansing/RideCleansingTest.java&quot;&gt;official Flink training tests&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Run in the local cluster with proper logging&lt;/h2&gt;
&lt;p&gt;Once we are done with our job, we can deploy it in a local cluster. The first step is to enable the log level Debug for the local cluster. Edit &lt;code&gt;$FLINK_HOME/conf/log4j-cli.properties&lt;/code&gt; and change root level to debug:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;rootLogger.level = DEBUG&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Start the cluster again:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh $FLINK_HOME/bin/start-cluster.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We need to modify our source code to use a remote execution environment so you should replace the &lt;code&gt;env&lt;/code&gt; variable again:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Compile our job:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh mvn clean package -Pbuild-jar&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Run the job in the local cluster:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh $FLINK_HOME/bin/flink run target/flink-playground-0.1.jar&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It should obtain an output similar to:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Job has been submitted with JobID bbea3ed5f5082a7267f85d92807b19dc&lt;br /&gt;
Program execution finished&lt;br /&gt;
Job with JobID bbea3ed5f5082a7267f85d92807b19dc has finished.&lt;br /&gt;
Job Runtime: 827 ms&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you check the logs, you should see your traces:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh grep -R &amp;quot;example job&amp;quot; $FLINK_HOME/log/&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Summary and next steps&lt;/h2&gt;
&lt;p&gt;In this article, we have covered the basics and some typical gotchas to work with Apache Flink in local environments. It&apos;s really important to invest time in your setup to be productive and have a pleasant experience building your jobs. Each minute you spent improving your workflow will pay off in the future.&lt;/p&gt;
&lt;p&gt;Did I miss something? You can comment on &lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/37&quot;&gt;GitHub&lt;/a&gt; or just drop me a note on &lt;a href=&quot;https://twitter.com/antonmry&quot;&gt;Twitter&lt;/a&gt;!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Gentle (and practical) introduction to Apache Avro - Part 1</title>
      <link>https://www.galiglobal.com/blog/2020/20200813-Gentle-and-practical-introduction-to-Apache-Avro-Part-1.html</link>
      <pubDate>Sat, 5 Dec 2020 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2020/20200813-Gentle-and-practical-introduction-to-Apache-Avro-Part-1.html</guid>
      <description>
      &lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This post is a gentle introduction to &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt;. After several discussions with &lt;a href=&quot;https://github.com/dariocazas&quot;&gt;Dario Cazas&lt;/a&gt; about what&apos;s possible with &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt;, he did some research and summarize it in an email. I found myself looking for that email several times to forward it to different teams to clarify doubts about Avro. After a while, I thought it could be useful for others and this is how this series of three posts was born.&lt;/p&gt;
&lt;p&gt;In summary, &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt; is a binary format with the following characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It&apos;s a binary what means it&apos;s very efficient (the keys of your data aren&apos;t copied several times as with JSON) but you can&apos;t read it in your text editor.&lt;/li&gt;
&lt;li&gt;It&apos;s a row format so each record is stored independently (for example, Parquet is a columnar format) so it&apos;s bad for aggregations but quite good to send data independently from one place to another.&lt;/li&gt;
&lt;li&gt;It has great support to manage the schema of the data. The schema is typically defined in JSON format.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These characteristics make &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt; very popular in Event Streaming architectures based in &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Apache Kafka&lt;/a&gt; but it isn&apos;t the only possible use.&lt;/p&gt;
&lt;p&gt;If you have more interest in &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt;, take a look to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Apache_Avro&quot;&gt;Apache Avro Wikipedia page&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Avro with the Schema Registry and Kafka&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt; plays well with &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Apache Kafka&lt;/a&gt; because it provides good performance and an easy way to govern schemas. There is an important thing to note: because &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt; is a binary format, consumers need to know how is the schema of the information stored in that message to deserialize it.&lt;/p&gt;
&lt;p&gt;The most common way to do this is using the &lt;a href=&quot;https://docs.confluent.io/platform/current/schema-registry/index.html&quot;&gt;Schema Registry&lt;/a&gt;, aka SR. We are going to speak about the Confluent implementation but it isn&apos;t the only one and it isn&apos;t part of the Kafka project. The workflow is quite simple: the producer consults the ID of the schema in the SR (or create a new one if it doesn&apos;t exist) and add that ID to the message. The consumer retrieves the schema from the SR using that ID and deserializes the message.&lt;/p&gt;
&lt;p&gt;The way to add the ID to the message is also simple: one byte with the value &lt;code&gt;0&lt;/code&gt; in the case of Confluent, 4 bytes with the ID and the rest of the data. It&apos;s documented in the &lt;a href=&quot;https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#wire-format&quot;&gt;Wire Format&lt;/a&gt; entry.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;schema_registry.png&quot; alt=&quot;Schema Registry architecture&quot; title=&quot;Schema Registry architecture&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Environment setup&lt;/h2&gt;
&lt;p&gt;Using the Confluent Avro serializer/deserializer, the process is quite straight-forward. Let&apos;s try it using the Confluent Community Docker version. The setup is documented in the &lt;a href=&quot;https://docs.confluent.io/6.0.0/quickstart/cos-docker-quickstart.html&quot;&gt;Quick Start for Apache Kafka using Confluent Platform Community Components (Docker)&lt;/a&gt; which it&apos;s summarized here:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git clone https://github.com/confluentinc/cp-all-in-one.git cd cp-all-in-one/cp-all-in-one-community/ docker-compose up -d&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let&apos;s start creating a topic:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker-compose exec broker kafka-topics \ --create \ --bootstrap-server localhost:9092 \ --replication-factor 1 \ --partitions 1 \ --topic test&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The output should be:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Created topic test.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To test it, we are going to create a Kafka Producer and a Kafka Consumer.&lt;/p&gt;
&lt;h2&gt;Kafka Producer with Confluent Schema Registry&lt;/h2&gt;
&lt;p&gt;Download the &lt;a href=&quot;https://github.com/antonmry/kafka-java-client-examples&quot;&gt;kafka-java-client-examples&lt;/a&gt; project and open it with your favourite IDE. We are going to work with a schema which it&apos;s located in the &lt;code&gt;src/main/resources&lt;/code&gt; folder:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json { &amp;quot;namespace&amp;quot;: &amp;quot;com.galiglobal.examples.testavro&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;record&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Test&amp;quot;, &amp;quot;fields&amp;quot;: [ {&amp;quot;name&amp;quot;: &amp;quot;id&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;test&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;double&amp;quot;} ] }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This Avro file is going to create a Test class you can use in your project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note for IntelliJ Idea users&lt;/strong&gt;: you need to generate the classes from the Avro file.  Right-click on your project and choose &lt;code&gt;Maven&lt;/code&gt; &amp;gt; &lt;code&gt;Generate sources and update folders&lt;/code&gt;. It&apos;s important to do it each time you change the schema.&lt;/p&gt;
&lt;p&gt;You can run now the &lt;code&gt;ConfluentProducerExample&lt;/code&gt; and it should print:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Successfully produced 10 messages to a topic called test&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The more relevant parts are the properties of the producer:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class); props.put(AbstractKafkaSchemaSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, &amp;quot;http://localhost:8081&amp;quot;);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We indicate how to connect to the SR and the serializer which it&apos;s publishing to the SR under the hood. In the class &lt;code&gt;io.confluent.kafka.schemaregistry.client.CachedSchemaRegistryClient&lt;/code&gt; you can find the Rest client used to request schemas to the SR using http.&lt;/p&gt;
&lt;p&gt;If you check in the SR, you can see the schema which has been created by the producer:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh curl http://localhost:8081/subjects/test-value/versions/1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It should return:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json { &amp;quot;subject&amp;quot;: &amp;quot;test-value&amp;quot;, &amp;quot;version&amp;quot;: 1, &amp;quot;id&amp;quot;: 1, &amp;quot;schema&amp;quot;: &amp;quot;{\&amp;quot;type\&amp;quot;:\&amp;quot;record\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;Test\&amp;quot;,\&amp;quot;namespace\&amp;quot;:\&amp;quot;com.galiglobal.examples.testavro\&amp;quot;,\&amp;quot;fields\&amp;quot;:[{\&amp;quot;name\&amp;quot;:\&amp;quot;id\&amp;quot;,\&amp;quot;type\&amp;quot;:\&amp;quot;string\&amp;quot;},{\&amp;quot;name\&amp;quot;:\&amp;quot;test\&amp;quot;,\&amp;quot;type\&amp;quot;:\&amp;quot;double\&amp;quot;}]}&amp;quot; }&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Kafka Consumer&lt;/h2&gt;
&lt;p&gt;We are going to consume the messages using the Kafka Consumer just executing the &lt;code&gt;ConfluentConsumerExample&lt;/code&gt; class. It should print something similar to:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;key = id0, value = {&amp;quot;id&amp;quot;: &amp;quot;id0&amp;quot;, &amp;quot;amount&amp;quot;: 1000.0}&lt;br /&gt;
key = id1, value = {&amp;quot;id&amp;quot;: &amp;quot;id1&amp;quot;, &amp;quot;amount&amp;quot;: 1000.0}&lt;br /&gt;
key = id2, value = {&amp;quot;id&amp;quot;: &amp;quot;id2&amp;quot;, &amp;quot;amount&amp;quot;: 1000.0}&lt;br /&gt;
key = id3, value = {&amp;quot;id&amp;quot;: &amp;quot;id3&amp;quot;, &amp;quot;amount&amp;quot;: 1000.0}&lt;br /&gt;
key = id4, value = {&amp;quot;id&amp;quot;: &amp;quot;id4&amp;quot;, &amp;quot;amount&amp;quot;: 1000.0}&lt;br /&gt;
key = id5, value = {&amp;quot;id&amp;quot;: &amp;quot;id5&amp;quot;, &amp;quot;amount&amp;quot;: 1000.0}&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The relevant part is again the configuration of the SR and the deserializer:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;java props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class); props.put(AbstractKafkaSchemaSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, &amp;quot;http://localhost:8081&amp;quot;); props.put(KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG, true);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The schema url and deserializer are equivalent to the producer. &lt;code&gt;SPECIFIC_AVRO_READER_CONFIG&lt;/code&gt; indicates we would like to deserialize to a Test object instead of a &lt;a href=&quot;https://avro.apache.org/docs/1.8.2/api/java/org/apache/avro/generic/GenericRecord.html&quot;&gt;GenericRecord&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If we try to consume directly from the topic without use the Confluent deserializer, the result isn&apos;t quite legible:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker-compose exec broker kafka-console-consumer \ --topic test \ --bootstrap-server localhost:9092 \ --from-beginning \ --property print.key=true \ --property key.separator=&amp;quot; : &amp;quot; \ --key-deserializer &amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot; \ --value-deserializer &amp;quot;org.apache.kafka.common.serialization.StringDeserializer&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As you can see, it&apos;s a binary protocol and quite efficient! We aren&apos;t sending the schema with every record as we would do with JSON or any other based protocol and that&apos;s a good saving.&lt;/p&gt;
&lt;h2&gt;Schema Compatibility&lt;/h2&gt;
&lt;p&gt;Efficiency isn&apos;t the only positive point of this approach. One of the nice things you have with a Schema Registry is the possibility to govern schemas and make sure they are being used properly.&lt;/p&gt;
&lt;p&gt;One of the big issues with asynchronous communications is how to evolve the schema without affect consumers of that particular topic. Schema Registry helps with that because it can check the changes in the schema and validate if they are breaking compatibility. They are different types of compatibility, you can read more on &lt;a href=&quot;https://docs.confluent.io/platform/current/schema-registry/avro.html&quot;&gt;Schema Evolution and Compatibility&lt;/a&gt;. Let&apos;s test it. First, we&apos;ll check what type of compatibility the SR is enforcing:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh curl -X GET http://localhost:8081/config&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;By default, it should return:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;{&amp;quot;compatibilityLevel&amp;quot;:&amp;quot;BACKWARD&amp;quot;}&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Backward compatibility means new consumers can read old records but old consumers need to upgrade to the new version to be able to deserialize new messages.&lt;/p&gt;
&lt;p&gt;We can test it using curl but it&apos;s a bit tricky because we have to scape the JSON file. Let&apos;s do it instead with the Producer adding one field to the schema:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json { &amp;quot;namespace&amp;quot;: &amp;quot;com.galiglobal.examples.testavro&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;record&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Test&amp;quot;, &amp;quot;fields&amp;quot;: [ {&amp;quot;name&amp;quot;: &amp;quot;id&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;test&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;double&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;boom&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;double&amp;quot;} ] }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If we modify &lt;code&gt;ConfluentProducerExample&lt;/code&gt; and run it again, an exception will show:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;org.apache.kafka.common.errors.SerializationException: Error registering Avro schema: {&amp;quot;type&amp;quot;:&amp;quot;record&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Test&amp;quot;,&amp;quot;namespace&amp;quot;:&amp;quot;com.galiglobal.examples.testavro&amp;quot;,&amp;quot;fields&amp;quot;:[{&amp;quot;name&amp;quot;:&amp;quot;id&amp;quot;,&amp;quot;type&amp;quot;:&amp;quot;string&amp;quot;},{&amp;quot;name&amp;quot;:&amp;quot;boom&amp;quot;,&amp;quot;type&amp;quot;:&amp;quot;string&amp;quot;}]} Caused by: io.confluent.kafka.schemaregistry.client.rest.exceptions.RestClientException: Schema being registered is incompatible with an earlier schema for subject &amp;quot;test-value&amp;quot;; error code: 409&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Adding a new field isn&apos;t a backward compatible change because new consumers can&apos;t read old messages with that schema. They don&apos;t have a way to fill the new field which it&apos;s mandatory. One possibility to make this change backward compatible would be to give a default value to the new field, so consumers know what value give it when the field isn&apos;t present in the message.&lt;/p&gt;
&lt;p&gt;Let&apos;s add a default value to the new field in the schema:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json { &amp;quot;namespace&amp;quot;: &amp;quot;com.galiglobal.examples.testavro&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;record&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Test&amp;quot;, &amp;quot;fields&amp;quot;: [ {&amp;quot;name&amp;quot;: &amp;quot;id&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;test&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;double&amp;quot;}, {&amp;quot;name&amp;quot;: &amp;quot;boom&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;double&amp;quot;, &amp;quot;default&amp;quot;: 0.0} ] }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If we make the proper changes and run &lt;code&gt;ConfluentProducerExample&lt;/code&gt; again, it will produce 10 new events and save a new version of the schema:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh curl http://localhost:8081/subjects/test-value/versions/2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It should return:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json { &amp;quot;subject&amp;quot;: &amp;quot;test-value&amp;quot;, &amp;quot;version&amp;quot;: 2, &amp;quot;id&amp;quot;: 2, &amp;quot;schema&amp;quot;: &amp;quot;{\&amp;quot;type\&amp;quot;:\&amp;quot;record\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;Test\&amp;quot;,\&amp;quot;namespace\&amp;quot;:\&amp;quot;com.galiglobal.examples.testavro\&amp;quot;,\&amp;quot;fields\&amp;quot;:[{\&amp;quot;name\&amp;quot;:\&amp;quot;id\&amp;quot;,\&amp;quot;type\&amp;quot;:\&amp;quot;string\&amp;quot;},{\&amp;quot;name\&amp;quot;:\&amp;quot;test\&amp;quot;,\&amp;quot;type\&amp;quot;:\&amp;quot;double\&amp;quot;},{\&amp;quot;name\&amp;quot;:\&amp;quot;boom\&amp;quot;,\&amp;quot;type\&amp;quot;:\&amp;quot;double\&amp;quot;,\&amp;quot;default\&amp;quot;:0.0}]}&amp;quot; }&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Summary and next steps&lt;/h2&gt;
&lt;p&gt;We have covered here the basics of &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro&lt;/a&gt; in an &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Apache Kafka&lt;/a&gt; architecture.  It has important advantages in terms of performance, reduction of message size and governance of the schemas.&lt;/p&gt;
&lt;p&gt;But it also has some problems, especially when we are dealing with hybrid and/or multi-tenant architectures. In the following two parts of this series, we&apos;ll cover these problems in details and the different alternatives we have with Avro to deal with them.&lt;/p&gt;
&lt;p&gt;Do you have comments? I would love to read them. &lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/34&quot;&gt;Leave a message&lt;/a&gt;!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Thanks, Optare!</title>
      <link>https://www.galiglobal.com/blog/2019/20190510-Good-bye-Optare.html</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2019/20190510-Good-bye-Optare.html</guid>
      <description>
      &lt;p&gt;Today it&apos;s a very sad day for me: it&apos;s time to say goodbye to all my colleagues in Optare. I internally announced it four weeks ago so I should have enough time to process it, but I didn&apos;t yet :-(&lt;/p&gt;
&lt;p&gt;I started to work in Optare in 2007 as an intern. It was a great experience. I learnt so much. I always will be thankful for that. After 4 years and 5 months, I left the company to work as a project manager in a big consultancy firm. I didn&apos;t like it. That experience put my ethics and professionalism beyond my limit so, after that, I was completely lost.&lt;/p&gt;
&lt;p&gt;And again, Optare came to the rescue offering me to be the tech lead of a new team: NetApps. Cool people called it intrapreneurship or something like that. That has been my major professional success in my career and I don&apos;t ever deserve the merit. I resigned the first day as the tech lead to be just another software engineer in the team. It was a team effort from the very beginning and, because of that, it&apos;s so special. It isn&apos;t one person against the world but a team of highly-skilled engineers collaborating and doing great things.&lt;/p&gt;
&lt;p&gt;Once I discovered it was possible to have a happy team, a happy customer and earn money at the same time, I started to evangelize about it. And that&apos;s how I ended as technical director. I learnt a lot in this role too. It&apos;s easier to build things from scratch than change them once they are built but, sometimes, small impacts are enough to change things in the long term.&lt;/p&gt;
&lt;p&gt;So, after 6 years and 1 month, I decided I would look for new challenges again. 10 years and 6 months in total. Wow! I changed a lot. Also the company. But I&apos;m very proud of both things. In the case of a company, it&apos;s amazing how it has evolved. In my case, It&apos;s amazing how my wife and my manager have been able to make me stay in the correct path for so long.&lt;/p&gt;
&lt;p&gt;And no! I wasn&apos;t unhappy in Optare. That isn&apos;t the reason to leave. In fact, I am extremely happy with this company. Honestly, I can&apos;t think in any place better to work. Maybe there are some teams which I wouldn&apos;t recommend for a specific person, but most of them are great. It&apos;s a friendly environment, modern and full of interesting technologies applied to real and challenging architectures.&lt;/p&gt;
&lt;p&gt;Also, it has a brilliant future ahead. For a company which has grown so quickly, there will be always up &amp;amp; downs. But Optare is a modern company: medium size, highly-specialized and full of great talent. Any Telecom operator in the world will pay good money once they know what Optare can offer.&lt;/p&gt;
&lt;p&gt;But 11 years is a long time, I need a new challenge and I found one where I think I can have a real impact on things I care about: the Tech community and my area. Also the opportunity to work with some cool open-source technologies and continue learning.&lt;/p&gt;
&lt;p&gt;So, it hurts a lot but it&apos;s time to say goodbye. I&apos;m really going to miss you.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>How to open your company to the tech community?</title>
      <link>https://www.galiglobal.com/blog/2019/20190508-How-to-open-your-company-to-the-tech-community.html</link>
      <pubDate>Wed, 8 May 2019 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2019/20190508-How-to-open-your-company-to-the-tech-community.html</guid>
      <description>
      &lt;p&gt;As a Software Engineer and usual participant in different Tech communities, it was always a priority for me to involve in the Tech community the company where I work. I really believe it&apos;s a win-win for the company and for the community but I also know it&apos;s quite complex.&lt;/p&gt;
&lt;p&gt;Have you ever do it something for the first time? If someone appears from nowhere and says you suck on that, probably you will lose the interest very soon. Even if that person approached with good intentions or saying the truth, the timing is crucial here. This happens all the time to opening companies. They stop the process and it&apos;s a pity.&lt;/p&gt;
&lt;p&gt;As co-organizer of local JUGs and conferences, I was asked several times from different companies about this. It&apos;s hard to answer, there are so many things involved. So I prepared a list of possible answers to help you in the path to collaborate with the community.&lt;/p&gt;
&lt;h1&gt;Have clear your reasons&lt;/h1&gt;
&lt;p&gt;There a lot of reasons for a company to start collaborating with the Tech community. Just choose whatever makes sense for your company. But they must be valuable. In this case, pro-bono work is fine for individuals but not for companies. There is nothing wrong in analysing it as an investment.&lt;/p&gt;
&lt;p&gt;There are mainly three reasons for most of the companies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Recruiting. If you want to hire the best engineers you can find, go to the Tech community. They aren&apos;t the best only for their technical skills but also for their soft skills: they know how to speak in public, make a successful network of collaborators, organize events, etc. All those things are quite practical in any company.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Help to grow your own engineers. Have your own people attending meetups, conferences, katas, etc. will help them to have different ideas, see what&apos;s working in the industry, etc. If they participate actively (as speakers or organizers), they also will grow as professionals and they will be busy and motivated so it will help with retention.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To find new business opportunities. I lose the count of how many of those I found since I started to collaborate. This is a real thing. Just let your engineers speak with others and they will find solutions to their problems. That&apos;s what engineers do.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You may have others. It doesn&apos;t matter. Just make sure they are clear for your company and you act accordingly to them.&lt;/p&gt;
&lt;h1&gt;How do we start?&lt;/h1&gt;
&lt;p&gt;Baby steps. Never start with a big program or a big budget. It&apos;s very important to be cautious in the beginning. Most of the people don&apos;t know your company or they have an idea quite negative about it. That&apos;s normal. You never have collaborated with the community before and probably have rejected candidates, fired employees, etc. and nobody is sharing the good things. It&apos;s time to change it but it will require time. Be patient.&lt;/p&gt;
&lt;p&gt;My advice here it&apos;s to find a non-profit local community and ask the organizers. You will be surprised by how helpful they will be without any type of hiding interest or retribution.&lt;/p&gt;
&lt;p&gt;It should be local, it&apos;s better to start locally and grow from there instead of jump directly into national or international events. It doesn&apos;t matter your size. People are connected. When you go to an international conference, the organizers will have local contacts and they will ask so it&apos;s better if you make your homework first. Everything will be easier.&lt;/p&gt;
&lt;p&gt;Also, choose your first community carefully. It should be related to the technologies you are using and also non-profit. Most of the Tech communities are great and there aren&apos;t hidden interests but it isn&apos;t always the case, especially if they aren&apos;t related only to Technology (entrepreneurship, blockchain, etc.). They aren&apos;t bad but they aren&apos;t a good start because someone may take advantage and have her own interests. If they aren&apos;t helpful or just ask for money, jump to the next one.&lt;/p&gt;
&lt;p&gt;You will have time in the future to come back a start a deeper collaboration once you know who is who in the community (and no, sadly Twitter and popularity doesn&apos;t help on that).&lt;/p&gt;
&lt;h1&gt;Should we organize our own group/event?&lt;/h1&gt;
&lt;p&gt;Some companies like to start with their own group or conference. It usually doesn&apos;t work well in the short-term. My advice is to start contributing before to create something from scratch. Again, it isn&apos;t about your size or expertise, it takes time to do things well so start small and grow from there. Think about what&apos;s better for your interests. The ego never helps.&lt;/p&gt;
&lt;p&gt;It&apos;s a lot better if you name some of your engineers as ambassadors in the Tech community. It&apos;s a partial-time role. His mission is to establish the link between both words: help the communities from the company and promote the community inside. Make sure they can decide and you are listening when they give their opinion. If a possible sponsorship is evaluated only by HR, you are missing important information.&lt;/p&gt;
&lt;h1&gt;What can we do?&lt;/h1&gt;
&lt;p&gt;Once you have a connection with the organizers they will start to propose different types of collaboration. If they are good organizers, not only for their own community, for others too. Don&apos;t be surprised if the Java guys ask for sponsorship in a PHP conference ;-)&lt;/p&gt;
&lt;p&gt;The easiest thing is event sponsorship but most of the companies are doing it wrong. It isn&apos;t about giving money for a list of services (a talk slot, publish your logo, etc.). Those things are ok but they aren&apos;t enough.&lt;/p&gt;
&lt;p&gt;If your company is going to be a sponsor of a conference, there are things you should do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make sure some engineers of your company attend the conference and organizers know about them so they can introduce everybody to them. It&apos;s sad when a company pay money and there is nobody to ask at the conference. There is no better ambassador than your own employees and social networking is the most important thing in a conference.&lt;/li&gt;
&lt;li&gt;Ask the organizers if your company can help in some way: find speakers or other sponsors, promote the conference or record the talks. Once you start to collaborate in this way, organizers will start to contribute back and speak nicely about your company to others. That&apos;s the type of publicity you want.&lt;/li&gt;
&lt;li&gt;Promote the event and talks in your social media. It&apos;s free, easy to do and with a great impact on your Company image.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One of the best things in a conference it&apos;s sending some of your engineers to make a talk and share their experiences. Everybody loves that, people will provide great real feedback and will get interested. It&apos;s a win-win and quite easy.&lt;/p&gt;
&lt;h1&gt;Social media and blogs&lt;/h1&gt;
&lt;p&gt;If you don&apos;t show something to the world, it doesn&apos;t exist. Social media is important. Most of the HR departments are quite familiar with Linkedin, but most of the engineers receive their news from Twitter. So start to promote your projects, events, communities, etc. and show a more human view of your company. But be careful: in case of doubt, don&apos;t publish it. Nobody wants to deal with trolls.&lt;/p&gt;
&lt;p&gt;If you don&apos;t want to pollute your Social Media mixing messages for engineers and customers, create a new account specifically for that. It would help a lot but make sure you keep it alive!.&lt;/p&gt;
&lt;p&gt;There are companies also launching an Engineering blog. It&apos;s a great idea which helps to promote your brand, but also to create some type of shared identity in your company and gives deserved credit to your engineers. The only problem: it takes time. If you do it, plan it carefully for the long-term.&lt;/p&gt;
&lt;h1&gt;Open Source&lt;/h1&gt;
&lt;p&gt;Open source is another good way to collaborate with the community. Just open a GitHub organization and let your engineers know they can publish software there. It would need some reviewing and validation process but it&apos;s a great way, especially if they start to work in the open, not just publish the final outcome.&lt;/p&gt;
&lt;p&gt;Another way is contribute to open source projects. Part of the dedication of some of your engineers can go to fix bugs, create new features, documentation, etc.&lt;/p&gt;
&lt;p&gt;Not only will help to collaborate with the community, but it would also have a positive impact on the company improving quality, performance and talent retention. That deserves another blog post.&lt;/p&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;There are a lot of ways and reasons to collaborate with the community. Ask other companies: worth it. But it isn&apos;t as easy as you may think. So start small and ask people with experience and good intentions. They will help. And remember, your engineers are the best ambassadors you may have in the Tech community. Empower them!.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Kubernetes installation with Route 53 DNS and HTTPS load balancer</title>
      <link>https://www.galiglobal.com/blog/2019/20190404-Kubernetes-installation-with-route-53-dns-and-https-load-balancer.html</link>
      <pubDate>Thu, 4 Apr 2019 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2019/20190404-Kubernetes-installation-with-route-53-dns-and-https-load-balancer.html</guid>
      <description>
      &lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This post explains how to deploy a Kubernetes cluster in Amazon. We want to automatically update Route 53 to use our own domain and use &lt;a href=&quot;https://aws.amazon.com/elasticloadbalancing/&quot;&gt;AWS ELB&lt;/a&gt; to have Load Balancing to our pods. We&apos;ll use also &lt;a href=&quot;https://aws.amazon.com/certificate-manager/&quot;&gt;AWS Certificate Manager (ACM)&lt;/a&gt; so our pods open internally HTTP endpoints but externally they expose HTTPS with a proper certificate.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;Install awscli and &lt;a href=&quot;https://github.com/kubernetes/kops#installing&quot;&gt;kops&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;``` export bucket_name=test-kops export KOPS_CLUSTER_NAME=k8s.test.net export KOPS_STATE_STORE=s3://${bucket_name}&lt;/p&gt;
&lt;p&gt;aws s3api create-bucket --bucket ${bucket_name} --region eu-west-1 --create-bucket-configuration LocationConstraint=eu-west-1 aws s3api put-bucket-versioning --bucket ${bucket_name} --versioning-configuration Status=Enabled&lt;/p&gt;
&lt;p&gt;kops create cluster &lt;br /&gt;
--node-count=1 &lt;br /&gt;
--node-size=t2.medium &lt;br /&gt;
--zones=eu-west-1a &lt;br /&gt;
--dns-zone test.net &lt;br /&gt;
--cloud-labels=&amp;quot;Department=TEST&amp;quot; &lt;br /&gt;
--name=${KOPS_CLUSTER_NAME}&lt;/p&gt;
&lt;p&gt;kops edit cluster --name ${KOPS_CLUSTER_NAME} ```&lt;/p&gt;
&lt;p&gt;Add to the end:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yaml additionalPolicies: node: | [ { &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Action&amp;quot;: &amp;quot;route53:ChangeResourceRecordSets&amp;quot;, &amp;quot;Resource&amp;quot;: &amp;quot;*&amp;quot; }, { &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Action&amp;quot;: &amp;quot;route53:ListHostedZones&amp;quot;, &amp;quot;Resource&amp;quot;: &amp;quot;*&amp;quot; }, { &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Action&amp;quot;: &amp;quot;route53:ListResourceRecordSets&amp;quot;, &amp;quot;Resource&amp;quot;: &amp;quot;*&amp;quot; } ]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and create the cluster executing:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kops update cluster --name ${KOPS_CLUSTER_NAME} --yes kops rolling-update cluster&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It takes some time. Use &lt;code&gt;kops validate cluster&lt;/code&gt; to validate it. More options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;validate cluster: kops validate cluster&lt;/li&gt;
&lt;li&gt;list nodes: kubectl get nodes --show-labels&lt;/li&gt;
&lt;li&gt;ssh to the master: ssh -i ~/.ssh/id_rsa admin@api.k8s.test.net&lt;/li&gt;
&lt;li&gt;the admin user is specific to Debian. If not using Debian please use the appropriate user based on your OS.&lt;/li&gt;
&lt;li&gt;read about installing addons at: https://github.com/kubernetes/kops/blob/master/docs/addons.md.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Deploy the dashboard&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml kubectl proxy &amp;amp; kops get secrets kube --type secret -oplaintext&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Open http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login&lt;/p&gt;
&lt;p&gt;Click on Token and introduce the following output:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kops get secrets admin --type secret -oplaintext&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Configure DNS&lt;/h3&gt;
&lt;p&gt;Note: avoid route53-mapper, it&apos;s deprecated. The kops documentation is outdated.&lt;/p&gt;
&lt;p&gt;Obtain the zone ID for your Hosted Zone (you should create a new one if you don&apos;t have one, consult &lt;a href=&quot;https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/aws.md#set-up-a-hosted-zone&quot;&gt;here&lt;/a&gt; how to do it):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;aws route53 list-hosted-zones-by-name --output json --dns-name &amp;quot;test.net.&amp;quot; | jq -r &apos;.HostedZones[0].Id&apos;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In our case, it returns &lt;code&gt;/hostedzone/AAAAAA&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Create a new file external-dns.yml and update your data in the end:&lt;/p&gt;
&lt;h2&gt;```yaml apiVersion: v1 kind: ServiceAccount metadata: name: external-dns&lt;/h2&gt;
&lt;h2&gt;apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: external-dns rules: - apiGroups: [&amp;quot;&amp;quot;] resources: [&amp;quot;services&amp;quot;] verbs: [&amp;quot;get&amp;quot;,&amp;quot;watch&amp;quot;,&amp;quot;list&amp;quot;] - apiGroups: [&amp;quot;&amp;quot;] resources: [&amp;quot;pods&amp;quot;] verbs: [&amp;quot;get&amp;quot;,&amp;quot;watch&amp;quot;,&amp;quot;list&amp;quot;] - apiGroups: [&amp;quot;extensions&amp;quot;] resources: [&amp;quot;ingresses&amp;quot;] verbs: [&amp;quot;get&amp;quot;,&amp;quot;watch&amp;quot;,&amp;quot;list&amp;quot;] - apiGroups: [&amp;quot;&amp;quot;] resources: [&amp;quot;nodes&amp;quot;] verbs: [&amp;quot;list&amp;quot;]&lt;/h2&gt;
&lt;h2&gt;apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: external-dns-viewer roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: external-dns subjects: - kind: ServiceAccount name: external-dns namespace: default&lt;/h2&gt;
&lt;p&gt;apiVersion: extensions/v1beta1 kind: Deployment metadata: name: external-dns spec: strategy: type: Recreate template: metadata: labels: app: external-dns spec: serviceAccountName: external-dns containers: - name: external-dns image: registry.opensource.zalan.do/teapot/external-dns:latest args: - --source=service - --source=ingress - --domain-filter=test.net - --provider=aws #- --policy=upsert-only # would prevent ExternalDNS from deleting any records, omit to enable full synchronization - --aws-zone-type=public # only look at public hosted zones (valid values are public, private or no value for both) - --registry=txt - --txt-owner-id=AAAAAA ```&lt;/p&gt;
&lt;p&gt;and deploy it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl apply -f external-dns.yml&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Test your configuration with an example:&lt;/h2&gt;
&lt;p&gt;Create an AWS certificate for the service:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;aws acm request-certificate \ --domain-name nginx.test.net \ --validation-method DNS \ --idempotency-token 1234&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and save the &lt;code&gt;CertificateArn&lt;/code&gt;. We&apos;ll use it later.&lt;/p&gt;
&lt;p&gt;You will need to validate it. The easier way it&apos;s from the AWS web console as explained &lt;a href=&quot;https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-validate-dns.html&quot;&gt;in the official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;nginx-d.yml&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx spec: template: metadata: labels: app: nginx spec: containers: - image: nginx name: nginx ports: - containerPort: 80 name: http&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and &lt;code&gt;nginx-svc.yml&lt;/code&gt; with the domain you would like to use and the ACM certificate.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yaml apiVersion: v1 kind: Service metadata: name: nginx annotations: external-dns.alpha.kubernetes.io/hostname: nginx.test.net. service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:eu-west-1:888888:certificate/AAAAAA-BBBBB-CCCCC-DDDDD service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http service.beta.kubernetes.io/aws-load-balancer-ssl-ports: &amp;quot;443&amp;quot; spec: type: LoadBalancer ports: - port: 80 name: http targetPort: 80 - name: https port: 443 targetPort: http selector: app: nginx&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and deploy them:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubectl apply -f nginx-d.yml -d nginx-svc-yml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It would take some minutes. Once the pods are ready, you should be able to open in your browser on &lt;code&gt;http://nginx.test.net&lt;/code&gt; and &lt;code&gt;https://nginx.test.net&lt;/code&gt; and see the nginx welcome page.&lt;/p&gt;
&lt;h2&gt;Clean everything&lt;/h2&gt;
&lt;p&gt;Delete the ACM certificate and execute:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kops delete cluster --name k8s.test.net --yes&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes/kops/blob/master/docs/iam_roles.md&quot;&gt;Kops IAM roles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/aws.md&quot;&gt;Setting up ExternalDNS for Services on AWS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/containermind/how-to-create-a-kubernetes-cluster-on-aws-in-few-minutes-89dda10354f4&quot;&gt;How to Create a Kubernetes Cluster on AWS in Few Minutes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/@jkinkead/external-http-https-server-on-kubernetes-in-aws-9b182328fff1&quot;&gt;External HTTP/HTTPS Server on Kubernetes in AWS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

	  </description>
    </item>
    
    <item>
      <title>JUnit4, JUnit5 and Spock framework comparison</title>
      <link>https://www.galiglobal.com/blog/2018/20180111-JUnit4-JUnit5-Spock-Comparisson.html</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2018/20180111-JUnit4-JUnit5-Spock-Comparisson.html</guid>
      <description>
      &lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This article has been published on &lt;a href=&quot;https://dzone.com/articles/junit4-junit5-and-spock-framework-comparison&quot;&gt;DZone&lt;/a&gt; with editor revision so I recommend you to read it there.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_introduction_and_motivation&quot;&gt;Introduction and motivation&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Recently I gave a talk in my local Java User Group about unit testing. Some of the content of the talk was about some popular libraries you can use in your Java project. I&amp;#8217;ve reviewed &lt;a href=&quot;http://junit.org/junit4/&quot;&gt;JUnit4&lt;/a&gt;, &lt;a href=&quot;http://junit.org/junit5/&quot;&gt;JUnit5&lt;/a&gt; and &lt;a href=&quot;http://spockframework.org/&quot;&gt;Spock framework&lt;/a&gt;. Many of the attendees were quite surprised with the differences. In this post, I will summarize the most commented: assert, parametrized tests and mocking.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I always like to demonstrate the concepts with examples and live coding so I chose a simple algorithm: &lt;a href=&quot;https://en.wikipedia.org/wiki/Fibonacci&quot;&gt;Fibonacci number calculator&lt;/a&gt;. If you don&amp;#8217;t know it, it&amp;#8217;s just to generate numbers which are the sum of the two previous ones in the series: &lt;code&gt;1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I used the typical (and with very bad performance) implementation:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    private static int fibonacci(int n) {
        if (n &amp;lt;= 1) return n; else
            return fibonacci(n-1) + fibonacci(n-2);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_junit4&quot;&gt;JUnit4&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I started explaining JUnit4. It makes sense because it&amp;#8217;s the most popular library and the base for many others. I started explaining &lt;code&gt;assertTrue&lt;/code&gt; and then, more advances usages, including &lt;code&gt;assertEquals&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    @Test
    public void improvedFibonacciTestSimple() {
        FibonacciWithJUnit4 f = new FibonacciWithJUnit4();
        assertEquals(f.fibonacci(4), 3);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If it&amp;#8217;s false, it would give you an error like:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code&gt;java.lang.AssertionError:
Expected :3
Actual   :2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Not very spectacular but quite useful.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The next thing was to show how to write a parametrized test, a nice feature very useful for test algorithms. In JUnit4 is quite tricky. You need to create a Collection with the annotation &lt;code&gt;@Parameters&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    @Parameters
    public static Collection&amp;lt;Object[]&amp;gt; data() {
        return Arrays.asList(new Object[][]{
                {0, 0}, {1, 1}, {2, 1}, {3, 2}, {4, 3}, {5, 5}, {6, 8}
        });
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Then we create some local variables and a constructor:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    private int fInput;
    private int fExpected;

    public ParametrizedFibonacciJUnit4(int input, int expected) {
        fInput = input;
        fExpected = expected;
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;and finally, we can use the &lt;code&gt;assertEquals&lt;/code&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    @Test
    public void test() {
        FibonacciWithJUnit4 f = new FibonacciWithJUnit4();
        assertEquals(fExpected, f.fibonacci(fInput));
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s quite verbose and if the test fails, you would obtain a message which doesn&amp;#8217;t indicate clearly the order or the parameters used (but your IDE probably will help on that):&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code&gt;java.lang.AssertionError:
Expected :0
Actual   :1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I didn&amp;#8217;t explain mocking here because an external library as &lt;a href=&quot;http://site.mockito.org/&quot;&gt;Mockito&lt;/a&gt; is usually required when you want to use mocking with JUnit4. Mockito is great but I didn&amp;#8217;t have enough time to explain it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_junit5&quot;&gt;JUnit5&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since September 2017, JUnit5 is considered stable and it should be your choice over JUnit4 for several reasons. It has better support for Java 8 and Lambdas, it&amp;#8217;s compatible with JUnit4 (you can have both which it&amp;#8217;s great to migrate in a progressive way) and it provides new runners and better integrations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I repeated the same process. First, show an &lt;code&gt;assertEquals&lt;/code&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    @Test
    public void bestFibonacciTestSimple() {
        FibonacciWithJUnit5 f = new FibonacciWithJUnit5();
        Assertions.assertEquals(f.fibonacci(4), 3);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are important advances in other &lt;code&gt;assert&lt;/code&gt;, for instance the timeout, but for &lt;code&gt;assertEqual&lt;/code&gt; with integers, it&amp;#8217;s practically the same. Also the message is similar if there is an error:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code&gt;org.opentest4j.AssertionFailedError:
Expected :3
Actual   :2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Where we can find important changes is in the parametrized test. First, we need to use the &lt;code&gt;@ParametrizedTest&lt;/code&gt; annotation and we can specify a name using &lt;code&gt;{&lt;/code&gt; and &lt;code&gt;}&lt;/code&gt; to indicate important parameters as &lt;code&gt;index&lt;/code&gt; as &lt;code&gt;arguments&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    @ParameterizedTest(name = &quot;run #{index} with [{arguments}]&quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now we can define our test. We start defining the entries to test function with the annotation &lt;code&gt;@CsvSource&lt;/code&gt;. Each item will replace the parameters in the test function, in this case, &lt;code&gt;input&lt;/code&gt; and &lt;code&gt;expected&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;    @CsvSource({&quot;1, 1&quot;, &quot;4, 3&quot;})
        public void test2(int input , int expected) {
                FibonacciWithJUnit5 f = new FibonacciWithJUnit5();
             	Assertions.assertEquals(f.fibonacci(input), expected);
         }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is lot better than the JUnit4 implementation. Also, if there is a fail in the test, we obtain a better message indicating the difference, the index causing the fail and the used parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Finally, it&amp;#8217;s the same for mocking as JUnit4: you normally use an external library so I didn&amp;#8217;t explained it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_spock_framework&quot;&gt;Spock framework&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The last one was the Spock framework. It&amp;#8217;s based in &lt;a href=&quot;http://groovy-lang.org/&quot;&gt;Apache Groovy&lt;/a&gt;. If you don&amp;#8217;t know Groovy, it&amp;#8217;s a language which you can use with the JVM and it interact very well with Java. It allows write less code in a more clear way. It&amp;#8217;s very powerful. Some years ago we started to use it for &quot;non critical&quot; development: tests, dependency management, Continuous Integration, load testing and in any place where we need some configuration file avoiding XML, JSON or any format like that. We continue to develop in Java the core of our software and it isn&amp;#8217;t a problem because both languages play very well together. If you know Java, you know Groovy&amp;#8230;&amp;#8203; so we have the best of both worlds.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Write a test in Spock is quite different, it would be like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;groovy&quot;&gt;    def &quot;Simple test&quot;() {
        setup:
        BadFibonacci f = new BadFibonacci()

        expect:
        f.fibonacci(1) == 1
        assert f.fibonacci(4) == 3
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Basically, we can use &lt;code&gt;def&lt;/code&gt; where we don&amp;#8217;t care about the type. The name of the function can be defined between quotation marks, which allow us to use better naming for our tests. We have some special words as &lt;code&gt;setup&lt;/code&gt;, &lt;code&gt;when&lt;/code&gt;, &lt;code&gt;expect&lt;/code&gt;, &lt;code&gt;and&lt;/code&gt;, etc. to define our test in a more descriptive and structured way. And we have a power assert, which is part of the language itself, proving nice messages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code&gt;Condition not satisfied:

f.fibonacci(4) == 2
| |            |
| 3            false
BadFibonacci@23c30a20

Expected :2

Actual   :3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It provides all the information: the returned value (actual), the expected value, the function, the parameter, etc. &lt;code&gt;assert&lt;/code&gt; is Groovy is really handy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now it&amp;#8217;s the turn for the parametrized test. It would be something like this:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;groovy&quot;&gt;    def &quot;parametrized test&quot;() {
        setup:
        BadFibonacci f = new BadFibonacci()

        expect:
        f.fibonacci(index) == fibonacciNumber

        where:
        index | fibonacciNumber
        1     | 1
        2     | 1
        3     | 2
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After show this I heard some &apos;oooh&apos; in the audience. The magic of this code is: you don&amp;#8217;t need to explain it! There is a table in the &lt;code&gt;where:&lt;/code&gt; section and the values in &lt;code&gt;expect:&lt;/code&gt; are automagically replace it in each iteration. If there is a fail, the message is crystal clear:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code&gt;Condition not satisfied:

f.fibonacci(index) == fibonacciNumber
| |         |      |  |
| 2         3      |  4
|                  false
BadFibonacci@437da279

Expected :4

Actual   :2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Then I&amp;#8217;ve introduced very shortly mocks and stubs. &lt;a href=&quot;https://en.wikipedia.org/wiki/Mock_object&quot;&gt;A mock&lt;/a&gt; is a object you create in your test to avoid to use a real object. For example, you don&amp;#8217;t want to do real web requests or print a page in your tests, so you can use a mock from an interface or another object.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;groovy&quot;&gt;    Subscriber subscriber = Mock()

    def &quot;mock example&quot;() {
        when:
        publisher.send(&quot;hello&quot;)

        then:
        1 * subscriber.receive(&quot;hello&quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Basically, you create the &lt;code&gt;subscriber&lt;/code&gt; interface as Mock and then you can invoke the methods. The &lt;code&gt;1 *&lt;/code&gt; is another nice feature of Spock, it specify how many messages you should receive. Cool, right?.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In some occasions, you need to define what return the methods of your mocks. For that, you can create &lt;a href=&quot;https://en.wikipedia.org/wiki/Method_stub&quot;&gt;a stub&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;prettyprint highlight&quot;&gt;&lt;code data-lang=&quot;groovy&quot;&gt;    def &quot;stub example&quot;() {
        setup:
        subscriber.receive(_) &amp;gt;&amp;gt; &quot;ok&quot;

        when:
        publisher.send(&quot;message1&quot;)

        then:
        subscriber.receive(&quot;message1&quot;) == &apos;ok&apos;
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this case, with the &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; notation we are defining the method &lt;code&gt;receive&lt;/code&gt; should return &lt;code&gt;ok&lt;/code&gt; independently of the parameter (&lt;code&gt;_&lt;/code&gt; means any value). The test pass without any problem.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I don&amp;#8217;t like to recommend one library or another: all of the them have their use cases. It&amp;#8217;s pretty clear we have great options in Java and I just give some examples. Now it&amp;#8217;s your turn to decide which it&amp;#8217;s better for you. The only thing I can say: write test and master your library of choice, it would make you a better developer!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you want to take a deeper look to the examples, you will find them in &lt;a href=&quot;https://github.com/vigojug/developer-vago-1-unit-testing&quot;&gt;this GitHub repository&lt;/a&gt;. Enjoy!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/antonmry/galiglobal/pull/28&quot;&gt;Comments&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
	  </description>
    </item>
    
    <item>
      <title>Speaking about Jython in Python Vigo</title>
      <link>https://www.galiglobal.com/blog/2017/20170401-Speaking-about-jython-in-Python-Vigo.html</link>
      <pubDate>Sat, 1 Apr 2017 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2017/20170401-Speaking-about-jython-in-Python-Vigo.html</guid>
      <description>
      &lt;p&gt;Some weeks ago I had the opportunity to speak in &lt;a href=&quot;https://www.python-vigo.es/posts/reunion-del-grupo-el-16032017/&quot;&gt;the Python Vigo meetup&lt;/a&gt;. It was just a lightning talk, 5 minutes. Why?. I really enjoy Python Vigo meetups, they are useful, fun and I always learn something new. So, when I read an email asking for speakers, I proposed the only Python related subject I know something about: &lt;a href=&quot;http://www.jython.org/&quot;&gt;Jython&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I have been using Jython for years to manage Weblogic servers. Being honest, I don&apos;t like it, without any doubt I would prefer to use Groovy, in fact, that&apos;s what we usually do. But I thought it may be interesting for someone in the Python community.&lt;/p&gt;
&lt;p&gt;It was my first time doing a talk so short. Also I&apos;m more used to do them in English. It was clear to me how hard it&apos;s to do a 5 minutes talk, even for an easy subject like this.&lt;/p&gt;
&lt;p&gt;I just wanted to say three things, if possible, without slides:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Don&apos;t use Jython if you are looking for Python performance improvement.&lt;/li&gt;
&lt;li&gt;Use Jython to explore Java classes or change them dinamically using Python syntax.&lt;/li&gt;
&lt;li&gt;Use Jython to combine it with Java programs, to load configuration dinamically, something like a DSL (Domain Specific Language) but using Python as language.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Probably, the talk wasn&apos;t clear for most people... Also I miss 15 seconds more to finish my example. Yet, some people asked me some things later related to it... so I&apos;m not completely sad with the result and I learnt how hard it&apos;s to do a good lightning talk.&lt;/p&gt;
&lt;p&gt;In case you are insterested, in &lt;a href=&quot;https://github.com/antonmry/talk-pythonvigo-2017-introduction-to-jython&quot;&gt;this GitHub repo&lt;/a&gt; you can find the things I did and also a Readme with the explanation. The talk is recorded so you can watch it here:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/FwgpPsiYg_o&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Notes for the future:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be careful with short talks, they are harder than the long ones.&lt;/li&gt;
&lt;li&gt;Use introductory slides, at least one.&lt;/li&gt;
&lt;li&gt;It&apos;s better to say less and clear than more and hard to understand.&lt;/li&gt;
&lt;/ul&gt;

	  </description>
    </item>
    
    <item>
      <title>My experience in Refugal</title>
      <link>https://www.galiglobal.com/blog/2017/20170306-My-experience-in-the-Refugal.html</link>
      <pubDate>Mon, 6 Mar 2017 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2017/20170306-My-experience-in-the-Refugal.html</guid>
      <description>
      &lt;p&gt;This weekend I&apos;ve participated in the &lt;a href=&quot;http://refu.gal/&quot;&gt;Refugal&lt;/a&gt;, a hackathon for refugees. It isn&apos;t the fist time I participate in a hackathon but this one has been special in some way. Do you know those videos of strangers who doesn&apos;t know each other but they start to play together in the middle of the station?. Something like this one:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/5Y39CwHfOHM&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Well, this is exactly what I felt some times during the weekend.&lt;/p&gt;
&lt;p&gt;Let me start in the beginning. I arrived soon and started to speak with people. A nice introduction to the hackathon by &lt;a href=&quot;https://twitter.com/dvilchez&quot;&gt;David&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/edosadikovic&quot;&gt;Edo&lt;/a&gt;, a game to improve creativity and we started with the ideas.&lt;/p&gt;
&lt;p&gt;I know I&apos;m more a doer than a thinker. But I like to collaborate so I proposed two ideas: a bot to help communicated refugees and volunteers and a network of home webcams interconnected to provide real-time information to the refugees and also to people at home. My presentation of the ideas was quite bad, mainly I was speaking about a bot... but not all people were developers so later some people told me they didn&apos;t know what a bot is. Big fail.&lt;/p&gt;
&lt;p&gt;My &amp;quot;bot&amp;quot; idea was the third one with more votes. It was another one I liked a lot more (the first one) but I stayed with the bot. Very soon the team was formed: four developers (2 web, 1 mobile and myself) and one designer. It was the more technical team, probably because of my bad explanation of the idea.&lt;/p&gt;
&lt;p&gt;We moved to a room. We discussed the idea for a while in front of a whiteboard and we separated the bot in different sections: Facebook Connector, Telegram Connector, Bot Logic, Design (logo, web, slides, etc.) and DevOps (my part: server, docker, Apache Kafka, etc.). In less than 30 minutes, everything was ready and we were working on the project.&lt;/p&gt;
&lt;p&gt;Hard to explain what happened after that, four guys and a designer working like one person. Lines of code, commands, systems, drawings... everything happening so fast, &lt;a href=&quot;https://github.com/refu-gal/refubot/graphs/commit-activity&quot;&gt;133 commits in less than 10 hours&lt;/a&gt;. I remember the designer stopping her drawing and asking: &amp;quot;Ey, guys, I know some development but I&apos;m not understanding what are you are talking about. Is it complex what you are doing?&amp;quot;. The four developers in the room said Yes! at the same time. You may take a look to &lt;a href=&quot;https://github.com/refu-gal/refubot&quot;&gt;github repo&lt;/a&gt;: Docker, Docker Compose, AWS, Apache Kafka, four nodeJS and one SQLLite... Everything integrated and working!. And the designer, what a great work she did. You may have the best backend in the world, but without a good designer, people isn&apos;t going to appreciate it. &lt;a href=&quot;http://refubot.refu.gal/&quot;&gt;The bot web&lt;/a&gt; is done by her, nice work!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/a5r3LdOYsH4W6qW3F-wyOAzsaVI5Mgqim6yF64Qeq9zw4K-FRPzQMyVe4QmR-EU4Lwk3HO0I4aDFGyz8a8zfG3a1hZ0nFpHM-cAbJH2YkGm9h8GNFcSa9Dtf-2795D6Avn96gF43keZVLGeqAROMOUlG4Orf-D_n26pbPG5lv9xNWT6Po62hqWMW9WDOobBX1rn0Cv3mjqn7-Yu5l1lCuRTANOrv6U-4DwCD-sKpmFinUYPl8y3y-veH6nB9NORgf0yjBQpr7RO5KSKRrc9fiAOvP63O8_FCpcdV1Zb5U-_DrPPbYtAMwbk50YyhSiaXghcQpJglHlqx7O-NAxZHDxAfoHyVE70w1so_af6v_KZfJBKzdEDUCZQ8rYJuCCQ4CBeK4u-Xe62U598F15e5x3Wb0lYSzSj-M_JBC6-qyqErio9NOKj4_akItup6Vp3_iDy5emavrNr9fuPa7p1lSOqBIg31LkR1Gz5y_skIV5iitaJS9HXa8D_NJS17gnUngIgCrI2s0vsbVZ753AhZFFOXdEqYwsI6LOuMhhwntmHdQa7Jcf1nmn5ybkt9qwSwYf7YNRy1iugRpg7DMIQOR6iffrQklAXfRSIbdeUKV0ytCKlftlk8UFR4DlN4JaZU0WbnMz4upj8mkK5xFzZE51o8NIbQEsCWwEH6vEXR=w1287-h965-no&quot; alt=&quot;Working as a team&quot; /&gt;&lt;/p&gt;
&lt;p&gt;From time to time someone proposing something: always accepted or postponed to the end if there was time for that. And back to work, not even a discussion in the whole weekend. Sometimes we even forget go to eat (but a great organization and &lt;a href=&quot;http://vigo.impacthub.net/en/&quot;&gt;the impacthub Vigo is so cool&lt;/a&gt;!). Also we had some funny moments, smiles and lot of complicity.&lt;/p&gt;
&lt;p&gt;I even had time to add a SMS connector using Nexmo, the best 15 euros spent in my life. First time I develop something using nodejs. I don&apos;t like it yet but I have to say it was a good decision for the project: lot of libraries and SDKs, easy to deploy and fast to develop.&lt;/p&gt;
&lt;p&gt;Of course, we run the demo during the presentation, it was great to see people sending messages from different networks and speaking with our bot. So fun!. I will pay good money for a video of that moment but everybody was too busy sending messages.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/wEfS8qxIqm0Jg01y6C3t6wDnZslQz4-FsHs1gPuzqXxR51gH_xkSu7wZCAJ_9JYYZUteo0FvF2ThF_8XBuLcDtS0zKrnpz2AdARMVps7eCHgnaFxzKnyMp5KPerV7KOzhlJg1wX8avgpu7injwgz_0oiYLO7VIRs-uYDW8s_GavTiafJ3EpwftWJqP6sH-o9KmQRntwBuZt8QbggBhF7HWw4377Soc9GKm3mNsocqALa6Sl9Zwa5BFlZ-LnPQjp8Y2WA8_FVVq_KJdV0EzF8U4yEgcSkOlzZsiEShfcyfAwIF_NShDlOH-qYz8o22hF1rFP303zfoBfdSzuddIyD1jpMP9oRRAoQMEu7EuGEejp28Rz-GvzvbmgsJyvD3XzmuJgU-vJcq_es2D4PXabR9oHR_xQJXku2ip697ZiKrIhSlc0ye3oLFpANwC_Od_CiLp1m3NUG7KZ-vsf0BvfwYLrj1MURv2cRjChTXNTZ62LXXFbQv2uqUPWIdUlNVYcGrYoSg3lhWsCqzl3xm_80T5DDQOxyMavjJ7T4KwK-vN5CoFSiB3HSuy0NA__nUXYhhk6fudr1cw5myfyURuicvGjg1J9LD2NkbgSusyjPSgqVJqhBW4L84Q3cwMBJmcdFl921U-kD_iFRBG7VWYarTsWPPZ1i1mA_eoQCt8BRww=w1448-h965-no&quot; alt=&quot;RefuBot presentation&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This morning, when I terminated the EC2 instance hosting the bot, I felt some type of sadness. Yet it has been great to meet such great team this weekend. And who knows?. RefuBot works and it scales. I can assure that. Maybe someone will discover it in the future and RefuBot becomes real. If it&apos;s really useful, that would be fair.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Photos are from &lt;a href=&quot;https://photos.google.com/share/AF1QipMDKf-GpnBzjFBII47B_Yoy5jOUpFqM1_agHANPrlG3CcKsbba09EcMIeZNP_R3sA?key=cllPNDJFMjlTYWtybXNIZ01PT1RMSWpabU5LVFF3&quot;&gt;this Picassa album&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Vim as Java and Groovy IDE (again) but now with Neovim</title>
      <link>https://www.galiglobal.com/blog/2017/20170226-Vim-as-Java-IDE-again.html</link>
      <pubDate>Sun, 26 Feb 2017 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2017/20170226-Vim-as-Java-IDE-again.html</guid>
      <description>
      &lt;p&gt;I&apos;ve tried so many times change Intellij or Eclipse by vim.. But when it&apos;s related to Java is really hard to find a real alternative to those IDEs. And when we speak about Groovy, it&apos;s even worse. Yet I use vim a lot: edit files, write blog posts, etc. Also my Chrome and Thunderbird configuration uses Vim shortcuts, so I keep myself more or less trained.&lt;/p&gt;
&lt;p&gt;Some weeks ago I&apos;ve discovered this blog post &lt;a href=&quot;https://spacevim.org/use-vim-as-a-java-ide/&quot;&gt;Use Vim as a Java IDE&lt;/a&gt; and I want to give it another opportunity. Let&apos;s start.&lt;/p&gt;
&lt;h2&gt;Neovim in Fedora&lt;/h2&gt;
&lt;p&gt;This is straight-forward:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo dnf -y copr enable dperson/neovim sudo dnf -y install neovim sudo dnf -y install python3-neovim python3-neovim-gui&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For Fedora 25 is even easier:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo dnf -y install neovim sudo dnf -y install python2-neovim python3-neovim&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For other systems, just check &lt;a href=&quot;https://github.com/neovim/neovim/wiki/Installing-Neovim&quot;&gt;the official Neovim documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&apos;ll need some other plugins:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo dnf -y install astyle&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Install vim-plug&lt;/h2&gt;
&lt;p&gt;Again, this is straight-forward following &lt;a href=&quot;https://github.com/junegunn/vim-plug&quot;&gt;the official instructions&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -fLo ~/.local/share/nvim/site/autoload/plug.vim --create-dirs \ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Install plugins&lt;/h2&gt;
&lt;p&gt;This is when things become messy. Start editing &lt;code&gt;~/.config/nvim/init.vim&lt;/code&gt; to add the plugins:&lt;/p&gt;
&lt;p&gt;``` &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;    vim-plug     &amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; call plug#begin(&apos;~/.local/share/nvim/plugged&apos;)&lt;/p&gt;
&lt;p&gt;&amp;quot; Others&lt;/p&gt;
&lt;p&gt;Plug &apos;scrooloose/nerdtree&apos;, { &apos;on&apos;:  &apos;NERDTreeToggle&apos; } Plug &apos;majutsushi/tagbar&apos;&lt;/p&gt;
&lt;p&gt;&amp;quot; Java development&lt;/p&gt;
&lt;p&gt;Plug &apos;sbdchd/neoformat&apos; Plug &apos;artur-shaik/vim-javacomplete2&apos; Plug &apos;Shougo/deoplete.nvim&apos;, { &apos;do&apos;: &apos;:UpdateRemotePlugins&apos; } Plug &apos;neomake/neomake&apos;&lt;/p&gt;
&lt;p&gt;&amp;quot; Initialize plugin system call plug#end()&lt;/p&gt;
&lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;    deoplete     &amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; let g:deoplete#enable_at_startup = 1 let g:deoplete#omni_patterns = {} let g:deoplete#omni_patterns.java = &apos;[^. *\t].\w*&apos; let g:deoplete#sources = {} let g:deoplete#sources._ = [] let g:deoplete#file#enable_buffer_path = 1&lt;/p&gt;
&lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;  Java Complete  &amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; autocmd FileType java setlocal omnifunc=javacomplete#Complete&lt;/p&gt;
&lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;     neomake     &amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; autocmd! BufWritePost,BufEnter * Neomake&lt;/p&gt;
&lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;     neoformat   &amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; augroup astyle autocmd! autocmd BufWritePre * Neoformat augroup END ```&lt;/p&gt;
&lt;p&gt;Open &lt;code&gt;nvim&lt;/code&gt; and type &lt;code&gt;:PlugInstall&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Done!&lt;/h2&gt;
&lt;p&gt;Now, if you open a Java project, you should have auto completion, auto format and lint capabilities.&lt;/p&gt;
&lt;p&gt;I will update this blog post with new things as soon as I have them.&lt;/p&gt;
&lt;h2&gt;TODO&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[ ] Add Groovy support.&lt;/li&gt;
&lt;li&gt;[ ] Add some screenshots or recording.&lt;/li&gt;
&lt;/ul&gt;

	  </description>
    </item>
    
    <item>
      <title>How to persist your configuration in GKE</title>
      <link>https://www.galiglobal.com/blog/2017/20170109-how-to-persist-your-configuration-in-gke.html</link>
      <pubDate>Mon, 9 Jan 2017 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2017/20170109-how-to-persist-your-configuration-in-gke.html</guid>
      <description>
      &lt;p&gt;In my previous post, &lt;a href=&quot;https://antonmry.github.io/post/deploy-on-kubernetes-gke-with-terraform/&quot;&gt;Deploy on Kubernetes GKE with Terraform&lt;/a&gt;, we&apos;ve seen how to start to use kubernetes but in a very simple way. The next thing we would like to do is persist the configuration, so we don&apos;t need to reconfigure our bot each time we start the cluster. This post explain how to do it from the configuration created in the previous one.&lt;/p&gt;
&lt;p&gt;Again we&apos;ll use &lt;a href=&quot;https://github.com/antonmry/leanmanager&quot;&gt;Leanmanager bot&lt;/a&gt; but everything applies to any other system which needs to store configuration or data in a database. In the case of &lt;a href=&quot;https://github.com/antonmry/leanmanager&quot;&gt;Leanmanager&lt;/a&gt; we are using &lt;a href=&quot;https://github.com/boltdb/bolt&quot;&gt;Boltdb&lt;/a&gt;, a pure Go key/value store. &lt;a href=&quot;https://github.com/boltdb/bolt&quot;&gt;Boltdb&lt;/a&gt; is great for development but it doesn&apos;t support to have more than one process opening the same database file, so it may be problematic if we want to have more than one Docker instance at the same time. Yet it&apos;s enough for our purposes and the process is similar for &lt;a href=&quot;https://www.consul.io/&quot;&gt;Consul&lt;/a&gt; which it&apos;s already in the Roadmap.&lt;/p&gt;
&lt;h2&gt;Create your persistent disks&lt;/h2&gt;
&lt;p&gt;If we want to persist data, we are going to need a disk, that&apos;s common sense. In GCE we can do it very easily:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh gcloud compute disks create --size 1GB leanmanager-disk&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;But again, we want to do it in an automated way with Terraform. Use the following file &lt;code&gt;leanmanager-disk.tf&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;``` variable &amp;quot;disk_name&amp;quot; { default = &amp;quot;leanmanager-disk&amp;quot; }&lt;/p&gt;
&lt;p&gt;resource &amp;quot;google_compute_disk&amp;quot; &amp;quot;default&amp;quot; { name  = &amp;quot;${var.disk_name}&amp;quot; type  = &amp;quot;pd-ssd&amp;quot; zone = &amp;quot;${var.region}&amp;quot; size  = &amp;quot;1&amp;quot; } ```&lt;/p&gt;
&lt;p&gt;If you want to know more about it, visit the &lt;a href=&quot;https://www.terraform.io/docs/providers/google/r/compute_disk.html&quot;&gt;Terraform Google_Compute_Disk reference documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Tell the container about the disk&lt;/h2&gt;
&lt;p&gt;In our previous post, we&apos;ve launched the bot using &lt;code&gt;kubectl run&lt;/code&gt;. This is OK for simple configuration but if we need to have something more complex, it doesn&apos;t scale. We can create a &lt;a href=&quot;http://kubernetes.io/docs/user-guide/pods/&quot;&gt;pod&lt;/a&gt;, a group of one or more containers, using a YAML file like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;apiVersion: v1 kind: Pod metadata: name: leanmanager labels: name: leanmanager spec: containers: - image: antonmry/leanmanager:latest name: leanmanager env: - name: LEANMANAGER_TOKEN value: LEANMANAGER_TOKEN_TEMPLATE - name: LEANMANAGER_PATHDB value: /mnt volumeMounts: # This name must match the volumes.name below. - name: leanmanager-persistent-storage mountPath: /mnt volumes: - name: leanmanager-persistent-storage gcePersistentDisk: # This disk must already exist. pdName: leanmanager-disk fsType: ext4&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The file is auto-explanatory except the value &lt;code&gt;LEANMANAGER_TOKEN_TEMPLATE&lt;/code&gt;. I don&apos;t want to hardcode the Token here because the file will be uploaded to Github. Instead of that, I want to use my local environment variable LEANMANAGER_TOKEN but this isn&apos;t supported yet in K8s, see &lt;a href=&quot;http://stackoverflow.com/questions/33478555/kubernetes-equivalent-of-env-file-in-docker&quot;&gt;Kubernetes equivalent of env-file in Docker&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So I&apos;ve created a YAML template and in the Terraform file changed the last &lt;code&gt;local-exec&lt;/code&gt; to:&lt;/p&gt;
&lt;p&gt;``` provisioner &amp;quot;local-exec&amp;quot; { command = &amp;quot;cp leanmanager-pod-template.yaml leanmanager.tmp.yaml &amp;amp;&amp;amp; sed -i -- &apos;s/LEANMANAGER_TOKEN_TEMPLATE/${var.LEANMANAGER_TOKEN}/g&apos; leanmanager.tmp.yaml&amp;quot; }&lt;/p&gt;
&lt;p&gt;provisioner &amp;quot;local-exec&amp;quot; { command = &amp;quot;kubectl create -f leanmanager.tmp.yaml&amp;quot; }&lt;/p&gt;
&lt;p&gt;provisioner &amp;quot;local-exec&amp;quot; { command = &amp;quot;rm -f leanmanager.tmp.yaml&amp;quot; } ```&lt;/p&gt;
&lt;p&gt;Basically, I&apos;m replacing strings with &lt;code&gt;sed&lt;/code&gt;. Other more sophisticate approaches are possible as K8s secrets or Ansible, but this is simple and enough for the task we want to do.&lt;/p&gt;
&lt;h2&gt;Create the pod and test&lt;/h2&gt;
&lt;p&gt;Time to create the cluster and the pod:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh terraform plan terraform apply -var LEANMANAGER_TOKEN=$LEANMANAGER_TOKEN&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The bot should connect. Now we can do some changes in the configuration, delete the pod:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh kubectl delete pod leanmanager&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Create it again:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh kubectl create -f leanmanager.yaml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And check the status with the following commands and, once it&apos;s in &lt;em&gt;Running&lt;/em&gt; state, see if everything has been persisted:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh kubectl get pod leanmanager kubectl logs leanmanager&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Persist data in Kubernetes is quite easy, even if you are going to do it automatically.&lt;/p&gt;
&lt;p&gt;If you want to check all the files, the full project and the associated PR are in &lt;a href=&quot;https://github.com/antonmry/leanmanager/pull/27/commits/ffea981b5deca5376b7bb8de1ed797da9aa282b0&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Not already linked but useful resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://kubernetes.io/docs/user-guide/persistent-volumes/&quot;&gt;Kubernetes persistent volumes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://cloud.google.com/container-engine/docs/tutorials/persistent-disk/&quot;&gt;Using Persistent Disks with WordPress and MySQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

	  </description>
    </item>
    
    <item>
      <title>Introduction to Go kit</title>
      <link>https://www.galiglobal.com/blog/2017/20170108-introduction-to-go-kit.html</link>
      <pubDate>Sun, 8 Jan 2017 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2017/20170108-introduction-to-go-kit.html</guid>
      <description>
      &lt;h2&gt;Microservices don&apos;t fit all use cases&lt;/h2&gt;
&lt;p&gt;When I&apos;ve started &lt;a href=&quot;https://github.com/antonmry/leanmanager&quot;&gt;my Leanmanager bot&lt;/a&gt;, I&apos;ve chosen to use the same approach (well, really it&apos;s a framework but that word seems to be censured if you are a gopher so I will use &lt;em&gt;approach&lt;/em&gt;) as the kubernetes project: if it&apos;s good for k8s, it should be good for me and also a good way to learn a bit more about kubernetes. So I&apos;ve implemented all the REST APIs using &lt;a href=&quot;https://github.com/emicklei/go-restful&quot;&gt;github.com/emicklei/go-restful&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then I had the opportunity to work a bit with &lt;a href=&quot;https://gokit.io/&quot;&gt;go-kit&lt;/a&gt;. A framework, ups, no, sorry, a toolkit to create microservices. My initial opinion was too complicated and too much boilerplate. Yet I would like to give it another opportunity, there are some interesting things useful for bots (support many transports, RPC approach, instrumentation) and my main motivation with the bot is to test new technologies and ideas so... why not?&lt;/p&gt;
&lt;p&gt;If you visit the &lt;a href=&quot;https://gokit.io&quot;&gt;Go-kit website&lt;/a&gt;, and then, you will jump very soon into the &lt;a href=&quot;https://gokit.io/examples/stringsvc.html&quot;&gt;stringsvc tutorial&lt;/a&gt;. The tutorial is awesome but it isn&apos;t a five minutes read and it&apos;s a bit too complicated to start to work with Go-kit. I recommend an approach a bit different. First, watch &lt;a href=&quot;https://www.youtube.com/watch?v=JXEjAwNWays&quot;&gt;Go + Microservices = Go Kit&lt;/a&gt; from &lt;a href=&quot;https://peter.bourgon.org/&quot;&gt;Peter Bourgon&lt;/a&gt;. This is an awesome talk explaining microservices and their use cases. Clearly Peter knows a lot about the subject: microservices aren&apos;t for everyone.&lt;/p&gt;
&lt;p&gt;If after the video, you think microservices fit your case, go ahead and may the Force be with you.&lt;/p&gt;
&lt;h2&gt;Go-kit addsvc example&lt;/h2&gt;
&lt;p&gt;First step, download Go-kit:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh go get github.com/go-kit/kit&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then, just copy the &lt;a href=&quot;https://github.com/go-kit/kit/tree/master/examples/addsvc&quot;&gt;addsvc example&lt;/a&gt; and download the dependencies (this may take a while depending of what you&apos;ve already in the GOPATH).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cp -r ../../go-kit/kit/examples/addsvc/ . go get ./...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The plan is simple, modify it to fit your use case while you are becoming more familiar with go-kit. But first, let&apos;s try the example. Launch the server:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd cmd/addsvc/ go run main.go&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And in a different shell, launch the client:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd cmd/addcli/ go run main.go -http.addr=:8081 1 2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If everything goes well, you will obtain something like:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1 + 2 = 3&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Or you can use &lt;code&gt;curl&lt;/code&gt; directly:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh curl -H &amp;quot;Content-Type: application/json&amp;quot; -X POST -d &apos;{&amp;quot;A&amp;quot;:&amp;quot;xyz&amp;quot;,&amp;quot;B&amp;quot;:&amp;quot;abc&amp;quot;}&apos; http://localhost:8081/concat&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;There are some things to note now. First, the example has two methods, one for add numbers and another one to concat strings. Also, it supports many transport protocols, not only http, so you can launch the client using gRPC:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh go run main.go -grpc.addr=:8082 1 2&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Show me the code!&lt;/h2&gt;
&lt;p&gt;It&apos;s time to go deeper. Open &lt;code&gt;service.go&lt;/code&gt;. This is the file where the service definition is described and also implemented for this example.&lt;/p&gt;
&lt;p&gt;Note: I may continue this in the future if I resume my work with go-kit.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Deploy on kubernetes GKE with Terraform</title>
      <link>https://www.galiglobal.com/blog/2017/20170106-deploy-on-kubernetes-gke-with-terraform.html</link>
      <pubDate>Fri, 6 Jan 2017 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2017/20170106-deploy-on-kubernetes-gke-with-terraform.html</guid>
      <description>
      &lt;p&gt;Writing a new post after six months and in Christmas... New year, new promises, old projects. I&apos;ve been quite busy the second half of 2016, but also very happy and satisfied with some personal and professional projects. No more excuses and let&apos;s focus in this post.&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I want to deploy my &lt;a href=&quot;https://hub.docker.com/r/antonmry/leanmanager&quot;&gt;leanmanager Docker image&lt;/a&gt; so the bot is available all the time for the team, but you can choose any Docker image you want to use. I want to use &lt;a href=&quot;https://cloud.google.com/container-engine/docs/quickstart&quot;&gt;Google Container Engine&lt;/a&gt; Kubernetes implementation and do it everything as much automatic as possible using Terraform.&lt;/p&gt;
&lt;h2&gt;GCE installation&lt;/h2&gt;
&lt;p&gt;First step, make sure you&apos;ve created previously a project in the Google Cloud console. If you don&apos;t have the Cloud SDK, you are going to need it. It&apos;s quite easy to install following &lt;a href=&quot;https://cloud.google.com/sdk/docs/quickstart-linux&quot;&gt;the Google instructions&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd ~/Software curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-138.0.0-linux-x86_64.tar.gz tar -zxvf google-cloud-sdk-138.0.0-linux-x86_64.tar.gz rm google-cloud-sdk-138.0.0-linux-x86_64.tar.gz ./google-cloud-sdk/install.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: be careful, last command modifies your .bashrc and it may cause problems.&lt;/p&gt;
&lt;p&gt;Now, it&apos;s time to log in:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh gcloud init&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And now, install kubectl, the client to manage kubernetes:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh gcloud components install kubectl&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Launching the service&lt;/h2&gt;
&lt;p&gt;The first step is to create the cluster. It may take some time.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh gcloud container clusters create leanmanager-cluster&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Ensure kubectl can access to the service:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh gcloud auth application-default login&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And now, it&apos;s time to launch the leanmanager image:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh kubectl run leanmanager-node --image=antonmry/leanmanager:latest --env=&amp;quot;LEANMANAGER_TOKEN=$LEANMANAGER_TOKEN&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I have an environment variable &lt;code&gt;LEANMANAGER_TOKEN&lt;/code&gt; with the token to authenticate to Slack. The bot automatically connects using Websocket but if you want to expose any service, add &lt;code&gt;--port=8080&lt;/code&gt; to allow access to it. You will need also to create a Load Balancer, the steps are explained &lt;a href=&quot;https://cloud.google.com/container-engine/docs/quickstart&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Clean the service&lt;/h2&gt;
&lt;p&gt;To stop the service and delete the cluster:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh gcloud container clusters delete leanmanager-cluster&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Install Terraform&lt;/h2&gt;
&lt;p&gt;Our next step it&apos;s going to be to automate all the process. To do it, we&apos;ll use &lt;a href=&quot;https://www.terraform.io&quot;&gt;Terraform&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you don&apos;t have it, first step is download it from &lt;a href=&quot;https://www.terraform.io/downloads.html&quot;&gt;here&lt;/a&gt; and install it. For linux:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh curl -O https://releases.hashicorp.com/terraform/0.8.2/terraform_0.8.2_linux_amd64.zip unzip terraform_0.8.2_linux_amd64.zip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now move it to a folder which is in your PATH, in my case:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh terraform ~/bin/ echo terraform &amp;gt;&amp;gt; ~/bin/.gitignore&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Last command is executed because I&apos;ve &lt;code&gt;~/bin&lt;/code&gt; in github but I don&apos;t want upload a so big file as &lt;code&gt;terraform&lt;/code&gt; executable.&lt;/p&gt;
&lt;p&gt;Now you should be able to use &lt;code&gt;terraform&lt;/code&gt; in your system. If you&apos;ve never used before, it&apos;s a good moment to read the &lt;a href=&quot;https://www.terraform.io/intro/getting-started/build.html&quot;&gt;Getting started guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Download GKE credentials&lt;/h2&gt;
&lt;p&gt;Follow these instructions to download the credentials file:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Log into the &lt;a href=&quot;https://console.cloud.google.com&quot;&gt;Google Developers Console&lt;/a&gt; and select a project.&lt;/li&gt;
&lt;li&gt;Click the menu button in the top left corner, and navigate to &amp;quot;IAM &amp;amp; Admin&amp;quot;, then &amp;quot;Service accounts&amp;quot;, and finally &amp;quot;Create service account&amp;quot;.&lt;/li&gt;
&lt;li&gt;Provide a name and ID in the corresponding fields, select &amp;quot;Furnish a new private key&amp;quot;, and select &amp;quot;JSON&amp;quot; as the key type.&lt;/li&gt;
&lt;li&gt;Clicking &amp;quot;Create&amp;quot; will download your credentials.&lt;/li&gt;
&lt;li&gt;Rename it to &lt;code&gt;account.json&lt;/code&gt;. Make sure you don&apos;t publish this file, for instance in Github (add it to &lt;code&gt;.gitignore&lt;/code&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Create the cluster using Terraform&lt;/h2&gt;
&lt;p&gt;In the same folder you have your &lt;code&gt;account.json&lt;/code&gt;, create a Terraform file like &lt;code&gt;leanmanager.tf&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;``` variable &amp;quot;region&amp;quot; { default = &amp;quot;europe-west1-d&amp;quot; }&lt;/p&gt;
&lt;p&gt;provider &amp;quot;google&amp;quot; { credentials = &amp;quot;${file(&amp;quot;account.json&amp;quot;)}&amp;quot; project     = &amp;quot;wwwleanmanagereu&amp;quot; region      = &amp;quot;${var.region}&amp;quot; }&lt;/p&gt;
&lt;p&gt;resource &amp;quot;google_container_cluster&amp;quot; &amp;quot;primary&amp;quot; { name = &amp;quot;leanmanager-cluster&amp;quot; zone = &amp;quot;${var.region}&amp;quot; initial_node_count = 1&lt;/p&gt;
&lt;p&gt;master_auth { username = &amp;quot;mr.yoda&amp;quot; password = &amp;quot;testTest1&amp;quot; }&lt;/p&gt;
&lt;p&gt;node_config { oauth_scopes = [ &amp;quot;https://www.googleapis.com/auth/compute&amp;quot;, &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;, &amp;quot;https://www.googleapis.com/auth/logging.write&amp;quot;, &amp;quot;https://www.googleapis.com/auth/monitoring&amp;quot;     ] } } ```&lt;/p&gt;
&lt;p&gt;Check what it&apos;s going to create:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh terraform plan&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Review the output and if it&apos;s ok, launch it!.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh terraform apply&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If everything goes well, you will see a message like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Apply complete! Resources: 1 added, 0 changed, 0 destroyed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And you can check it with:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh gcloud container clusters list&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you want to access with &lt;code&gt;kubectl&lt;/code&gt; you need to login first:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;gcloud container clusters get-credentials leanmanager-cluster --zone europe-west1-d kubectl cluster-info&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This step can be added to the &lt;code&gt;leanmanager.tf&lt;/code&gt; inside the &lt;code&gt;resource&lt;/code&gt; block:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;provisioner &amp;quot;local-exec&amp;quot; { command = &amp;quot;gcloud container clusters get-credentials ${var.cluster_name} --zone ${google_container_cluster.primary.zone}&amp;quot; }&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Launch our Docker instance&lt;/h2&gt;
&lt;p&gt;Once you are logged in with &lt;code&gt;kubectl&lt;/code&gt;, it&apos;s exactly the same as before:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh kubectl run leanmanager-node --image=antonmry/leanmanager:latest --env=&amp;quot;LEANMANAGER_TOKEN=$LEANMANAGER_TOKEN&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;But you can also do it with Terraform adding this snippet in the beginning:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;variable &amp;quot;LEANMANAGER_TOKEN&amp;quot; { default = &amp;quot;USE YOUR OWN TOKEN&amp;quot; }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And after the previous &lt;code&gt;local-exec&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;provisioner &amp;quot;local-exec&amp;quot; { command = &amp;quot;kubectl run leanmanager-node --image=antonmry/leanmanager:latest --env=LEANMANAGER_TOKEN=${var.LEANMANAGER_TOKEN}&amp;quot; }&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And executing terraform passing the variable:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh terraform apply -var LEANMANAGER_TOKEN=$LEANMANAGER_TOKEN&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Other option would be read the variable directly but you have to change the name to fit the terraform requirements and I&apos;m using it for other things. More info &lt;a href=&quot;https://www.terraform.io/docs/configuration/variables.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Clean everything&lt;/h2&gt;
&lt;p&gt;With Terraform is really easy, just:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh terraform destroy&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Not already linked but useful resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://container-solutions.com/simple-gce-setup-terraform/&quot;&gt;Simple GCE setup Terraform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/l337ch/terraform-gke&quot;&gt;terraform-gke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/kelseyhightower/kubestack&quot;&gt;kubestack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://cloud.google.com/solutions/automated-build-images-with-jenkins-kubernetes&quot;&gt;Automated Image Builds with Jenkins, Packer, and Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

	  </description>
    </item>
    
    <item>
      <title>Time to start a Go blog with Hugo</title>
      <link>https://www.galiglobal.com/blog/2016/20160616-first-blog-post-with-hugo.html</link>
      <pubDate>Thu, 16 Jun 2016 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2016/20160616-first-blog-post-with-hugo.html</guid>
      <description>
      &lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: I finally merged both blogs, so this blog post doesn&apos;t make sense. I prefer Hugo to JBake but because I&apos;ve been doing more Java/Groovy development, I will stay with JBake.&lt;/p&gt;
&lt;p&gt;Well, this is embarrassing. I&apos;m launching another blog!. Why?. Some time ago I&apos;ve started to write a blog, in the beginning for corporate news but it has become a place where to write or document interesting things I do in my work, most of them related to Java, Groovy and Oracle technologies. The blog is generated with &lt;a href=&quot;http://jbake.org/&quot;&gt;JBake&lt;/a&gt; with the &lt;a href=&quot;https://github.com/antonmry/jbake-gradle-plugin&quot;&gt;gradle plugin&lt;/a&gt;, I like to use related technologies and I&apos;m quite happy with the result, but to be honest, I don&apos;t write frequently.&lt;/p&gt;
&lt;p&gt;Six months ago I&apos;ve started to learn and use &lt;a href=&quot;https://golang.org/&quot;&gt;Go&lt;/a&gt;. I was very impressed with the simplicity of the language and I&apos;ve started to read a lot of articles, books, etc., watch videos and develop some projects. I discovered &lt;a href=&quot;https://gohugo.io/&quot;&gt;Hugo&lt;/a&gt;, a site generator similar to JBake but written in Go. I was tempted to migrate my previous blog, but today I&apos;m going to continue writing about not Go subjects, so it&apos;s simpler to open a new one only for Go, bots, DevOps, concurrency and perfomance. In another post I will write more about Go and why I find it so interesting.&lt;/p&gt;
&lt;p&gt;As the first post, let&apos;s see how to configure &lt;a href=&quot;https://gohugo.io/&quot;&gt;Hugo&lt;/a&gt;. I&apos;ve to say it was really easy, I really impressed with piece of software. I can compare with other site generators as Jekyll, Hexo or JBake, and I have to say Hugo is my favourite.&lt;/p&gt;
&lt;p&gt;First of all, I&apos;ve created a new repo in my Gihub account and cloned it in my laptop:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git clone git@github.com:antonmry/antonmry.github.io.git cd antonmry.github.io&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Because I&apos;m going to use my github user page, the source code of the page must be in master branch. For your Hugo code, you can have a separate repo or just a different branch. I choose the second option with a branch named source, I prefer it in that way, it&apos;s simpler and this is the main difference with the procedure you can find in &lt;a href=&quot;https://gohugo.io/tutorials/github-pages-blog&quot;&gt;the excellent Hugo documentation&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git checkout -b source git push -u origin source&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Inside the source code folder, we are going to create a folder linking to the master branch:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git subtree add --prefix=public git@github.com:antonmry/antonmry.github.io.git master --squash git subtree pull --prefix=public git@github.com:antonmry/antonmry.github.io.git master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It&apos;s time to generate the site. First you have to install Hugo, plenty of options in the &lt;a href=&quot;https://gohugo.io/overview/installing/&quot;&gt;the Hugo website&lt;/a&gt;. I&apos;ve chosen the Fedora package, updates will be easier.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh hugo new site antonmry.github.io mv antonmry.github.io/* . rm -r antonmry.github.io&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Choose your theme, there are very nice options, I&apos;ve chosen beatifulhugo:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd themes git clone https://github.com/halogenica/Hugo-BeautifulHugo.git beautifulhugo cd .. echo &amp;quot;theme = \&amp;quot;beautifulhugo\&amp;quot;&amp;quot; &amp;gt;&amp;gt; config.toml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Create your first blog and start the server:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh hugo new post/hugo-site-created.md hugo server --buildDrafts&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Open in your browser http://localhost:1313/ and enjoy your first post with Hugo ;-)&lt;/p&gt;
&lt;p&gt;Let&apos;s move the post from draft to publised: edit the file content/post/hugo-site-created.md and change the draft line from true to false if exists.&lt;/p&gt;
&lt;p&gt;Now it&apos;s time to upload it to Gihub and make it public:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh hugo git add -A git commit -m &amp;quot;Initial version&amp;quot; git push git subtree push --prefix=public git@github.com:antonmry/antonmry.github.io.git master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Oh, really, can it be so easy?. Just go to https://antonmry.github.io (or your equivalent site)&lt;/p&gt;
&lt;p&gt;I was thinking in create a travis job to do the publishing in master (I did it before for jbake) but to be honest, this method is simple enough. I&apos;ve added to my .bash_alias the last command and that&apos;s all I need.&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;p&gt;PS: if you do a rebase in &lt;code&gt;source&lt;/code&gt;, you will need to do it a bit more tricky to push to master because you can&apos;t use &lt;code&gt;--force&lt;/code&gt; with the &lt;code&gt;subtree&lt;/code&gt; option:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git push origin `git subtree split --prefix public source`:master --force&lt;/code&gt; More info can be found in Stackoverflow &lt;a href=&quot;http://stackoverflow.com/questions/13756055/git-subtree-subtree-up-to-date-but-cant-push&quot;&gt;Git subtree - subtree up-to-date but can&apos;t push&lt;/a&gt;.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Developing in RestComm? Docker to the rescue</title>
      <link>https://www.galiglobal.com/blog/2016/20160508-Developing-in-RestComm-Docker-to-the-rescue.html</link>
      <pubDate>Sun, 8 May 2016 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2016/20160508-Developing-in-RestComm-Docker-to-the-rescue.html</guid>
      <description>
      &lt;p&gt;I&apos;m not a RestComm expert but I like to document the steps when I do something. It&apos;s quite schematic but yet, it may help someone. Start to contribute to RestComm is really hard because the lack of documentation and all the team very busy. But it&apos;s a interesting project and a nice community.&lt;/p&gt;
&lt;p&gt;The idea is quite simple: show how how create two PRs: one for Restcomm-Docker, another for Restcomm-Connect.&lt;/p&gt;
&lt;h2&gt;What do you need?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Java 7 development environment&lt;/li&gt;
&lt;li&gt;Ant and maven&lt;/li&gt;
&lt;li&gt;docker&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, what is the first step to become a RestComm maniac?&lt;/p&gt;
&lt;h2&gt;Download the source code&lt;/h2&gt;
&lt;p&gt;The easy part, I love github:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git clone git@github.com:antonmry/Restcomm-Connect.git git clone git@github.com:antonmry/Restcomm-Docker.git cd Restcomm-Docker/ git remote add upstream git@github.com:RestComm/Restcomm-Docker.git cd ../Restcomm-Connect/ git remote add upstream git@github.com:RestComm/Restcomm-Connect.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you&apos;ve done it previously, it&apos;s a good moment to sync with the official respository:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git fetch upstream git checkout master git merge upstream/master git push&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;RestComm-Docker&lt;/h2&gt;
&lt;p&gt;Now we are going to set up the RestComm environment: docker to the rescue!&lt;/p&gt;
&lt;p&gt;I always create a local branch to do my work:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd ../Restcomm-Docker/ git checkout -b s3bucketRegion#1 git push -u origin s3bucketRegion#1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;```sh docker build -t restcomm/yourname:latest -f Dockerfile .&lt;/p&gt;
&lt;p&gt;docker run -i -d -v /var/log/restcomm/:/var/log/restcomm/ -e VOICERSS_KEY=&amp;quot;CREATE A NEW ONE&amp;quot; -e S3_ACCESS_KEY=&amp;quot;ONLY IF YOU USE IT&amp;quot; -e S3_SECURITY_KEY=&amp;quot;ONLY IF YOU USE IT&amp;quot; -e S3_BUCKET_NAME=&amp;quot;ONLY IF YOU USE IT&amp;quot; -e STATIC_ADDRESS=&amp;quot;YOUR ETH0 IP?&amp;quot; -e ENVCONFURL=&amp;quot;https://raw.githubusercontent.com/RestComm/Restcomm-Docker/master/scripts/restcomm_env_locally.sh&amp;quot; -p 80:80 -p 443:443 -p 9990:9990 -p 5060:5060 -p 5061:5061 -p 5062:5062 -p 5063:5063 -p 5060:5060/udp -p 65000-65050:65000-65050/udp restcomm/yourname:latest ```&lt;/p&gt;
&lt;p&gt;We &amp;quot;enter&amp;quot; inside the docker instance:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker ps docker exec -it bfed9c0195f51c089b5edc001e48c31f4fb374a90a781f02f9c514a691fa6933 /bin/bash&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To copy the deployments folder:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd /opt/Restcomm-JBoss-AS7/standalone/deployments/ tar -cvf /tmp/deployments.tar * exit&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;REPLACE_WITH_READ_MORE&lt;/p&gt;
&lt;p&gt;We leave the container and extract the deployment folder in your system:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker cp bfed9c0195f51c089b5edc001e48c31f4fb374a90a781f02f9c514a691fa6933:/tmp/deployments.tar . mkdir deployments mv deployments.tar deployments rm deployments.tar&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Launch docker with the new folder as its deployment folder:&lt;/p&gt;
&lt;p&gt;```sh docker stop bfed9c0195f51c089b5edc001e48c31f4fb374a90a781f02f9c514a691fa6933&lt;/p&gt;
&lt;p&gt;docker run -i -d -v /var/log/restcomm/:/var/log/restcomm/ -v /home/antonmry/Workspace/Telestax/deployments:/opt/Restcomm-JBoss-AS7/standalone/deployments -e VOICERSS_KEY=&amp;quot;xxx&amp;quot; -e S3_ACCESS_KEY=&amp;quot;xxx&amp;quot; -e S3_SECURITY_KEY=&amp;quot;xxx&amp;quot; -e S3_BUCKET_NAME=&amp;quot;xxx&amp;quot; -e STATIC_ADDRESS=&amp;quot;your eth0 IP?&amp;quot; -e ENVCONFURL=&amp;quot;https://raw.githubusercontent.com/RestComm/Restcomm-Docker/master/scripts/restcomm_env_locally.sh&amp;quot; -p 80:80 -p 443:443 -p 9990:9990 -p 5060:5060 -p 5061:5061 -p 5062:5062 -p 5063:5063 -p 5060:5060/udp -p 65000-65050:65000-65050/udp restcomm/yourname:latest&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Time to make your changes in the Dockerfile. Once they are done, build the image and test. To upload it to github, first upload to your repository:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git add file1 file2 git commit -m &amp;quot;Descriptive message please&amp;quot; git push&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In github, open a Request using as Base the official repository and as a Head Fork your branch. Usually I add a &amp;quot;Closes #xx&amp;quot; to the end of the title, where xx is the number of the issue you are solving. It helps if you are using &lt;a href=&quot;http://www.waffle.io&quot;&gt;Waffle&lt;/a&gt;, a great service to organize your issues following agile methodologies.&lt;/p&gt;
&lt;h2&gt;RestComm-Connect&lt;/h2&gt;
&lt;p&gt;Ok, we have our Restcomm-docker PR, let&apos;s got with ResComm-Connect. First you need to create a file:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd ../Restcomm-Connect/ vim restcomm-connect-build.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;with the following content (change to your own values):&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h1&gt;!/bin/bash&lt;/h1&gt;
&lt;p&gt;export RESTCOMM_HOME=/home/antonmry/Workspace/Telestax/Restcomm-Connect export MAJOR_VERSION_NUMBER=7.6 export BUILD_NUMBER=0&lt;/p&gt;
&lt;p&gt;JAVA_HOME=/home/antonmry/Software/jdk/jdk1.7.0_80 export JAVA_HOME&lt;/p&gt;
&lt;p&gt;export WORKSPACE=$RESTCOMM_HOME mkdir $WORKSPACE/dependencies export DEPENDENCIES_HOME=$WORKSPACE/dependencies&lt;/p&gt;
&lt;p&gt;ant release -f ./release/build.xml -Drestcomm.release.version=$MAJOR_VERSION_NUMBER.$BUILD_NUMBER -Drestcomm.branch.name=restcomm-release-$MAJOR_VERSION_NUMBER.$BUILD_NUMBER -Dcheckout.restcomm.dir=$RESTCOMM_HOME -Dworkspace.restcomm.dir=$RESTCOMM_HOME/restcomm -Dcheckout.dir=$DEPENDENCIES_HOME ```&lt;/p&gt;
&lt;p&gt;Execute it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh chmod +x restcomm-connect-build.sh ./restcomm-connect-build.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Time to wait 5 minutes in a good laptop... after that, we should have our customozied JBoss ready to be launched:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh ls ./release/Restcomm-JBoss-AS7-7.6.0.zip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now you can unzip it and start to play with it... but how to start to develop?&lt;/p&gt;
&lt;p&gt;In the Intellij Idea, you can import the project as a Maven project. I&apos;ve imported the route &lt;strong&gt;Restcomm-Connect/restcomm&lt;/strong&gt; which has the root pom.xml and created a local branch as usual:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git checkout -b initTimeRVD#1 git push -u origin initTimeRVD#1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now you can develop as much as you want. To build it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cd restcomm mvn install&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Here you can do it with the different modules, you don&apos;t need to build everything each time but the specific module you&apos;ve changed. To deploy it and test it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker ps docker stop 06b117547bc5726fc74c42a61c6826342f04b9b194ebc0029f70be4ad1ef1a4f rm -r /home/antonmry/Workspace/Telestax/deployments/restcomm.war rm -r /home/antonmry/Workspace/Telestax/deployments/restcomm-rvd.war cp -r restcomm.application/target/restcomm/ ~/Workspace/Telestax/deployments/restcomm.war cp -r restcomm.application/target/restcomm.rvd/ ~/Workspace/Telestax/deployments/restcomm-rvd.war&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker run -i -d -v /var/log/restcomm/:/var/log/restcomm/ -v /home/antonmry/Workspace/Telestax/deployments:/opt/Restcomm-JBoss-AS7/standalone/deployments -e VOICERSS_KEY=&amp;quot;xxx&amp;quot; -e S3_ACCESS_KEY=&amp;quot;xxx&amp;quot; -e S3_SECURITY_KEY=&amp;quot;xxx&amp;quot; -e S3_BUCKET_NAME=&amp;quot;xxx&amp;quot; -e STATIC_ADDRESS=&amp;quot;YOUR ETH0 IP?&amp;quot; -e ENVCONFURL=&amp;quot;https://raw.githubusercontent.com/RestComm/Restcomm-Docker/master/scripts/restcomm_env_locally.sh&amp;quot; -p 80:80 -p 443:443 -p 9990:9990 -p 5060:5060 -p 5061:5061 -p 5062:5062 -p 5063:5063 -p 5060:5060/udp -p 65000-65050:65000-65050/udp restcomm/yourname:latest&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Know, just open RestComm as usual in https://eth0-ip or https://eth0-ip/olympus and test. Once you have finished your changes, upload them to Github:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh git add file1 file2 git commit &amp;quot;A good message #yourIssue&amp;quot; git push&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Create the PR in github and wait for the approbation ;-)&lt;/p&gt;
&lt;h1&gt;Reference documentation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://documentation.telestax.com/connect/configuration/How%20to%20build%20Restcomm-Connect%20from%20source.html#build-from-source&quot;&gt;How to build Restcomm-Connect from source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://docs.telestax.com/restcomm-docker-adding-a-jar-file-to-an-exiting-container/&quot;&gt;Restcomm – Docker Adding a Jar File to an Exiting Container&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

	  </description>
    </item>
    
    <item>
      <title>How to setup your environment for Kubernetes development</title>
      <link>https://www.galiglobal.com/blog/2016/20160430-how-to-develop-in-Kubernetes.html</link>
      <pubDate>Sat, 30 Apr 2016 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2016/20160430-how-to-develop-in-Kubernetes.html</guid>
      <description>
      &lt;p&gt;In this post I&apos;m going to show how to create a Kubernetes Development Environment and deploy RestComm (a quite complex software) on it for testing. If you want just deploy RestComm, it&apos;s better for you use the &lt;a href=&quot;http://kubernetes.io/docs/getting-started-guides/docker/&quot;&gt;Kubernetes Docker option&lt;/a&gt;, instead of doing all this process.&lt;/p&gt;
&lt;h1&gt;Install Go Development Environment&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;sh curl -O https://storage.googleapis.com/golang/go1.6.linux-amd64.tar.gz tar -zxvf go1.6.linux-amd64.tar.gz mv go ~/Software/ echo &amp;quot;GOROOT=~/Software/go&amp;quot; &amp;gt;&amp;gt; .bash_profile echo &amp;quot;export GOROOT&amp;quot; &amp;gt;&amp;gt; .bash_profile echo &amp;quot;PATH=\$GOROOT/bin:\$PATH&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile echo &amp;quot;export PATH&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile echo &amp;quot;GOPATH=~/Workspace/Telestax/go_kubernetes&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile echo &amp;quot;export GOPATH&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile source ~/.bash_profile mkdir -p $GOPATH&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;Basic Kubernetes installation&lt;/h1&gt;
&lt;h2&gt;Clone and download&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;sh mkdir -p $GOPATH/src/k8s.io cd $GOPATH/src/k8s.io git clone https://github.com/antonmry/kubernetes.git cd kubernetes git remote add upstream &apos;https://github.com/kubernetes/kubernetes.git&apos;&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Build and unit test&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;sh ./hack/build-go.sh &amp;amp;&amp;amp; notify-send &amp;quot;Compilation done&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Note! Integration test take a long time.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh ./hack/test-go.sh &amp;amp;&amp;amp; notify-send &amp;quot;Test done&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Integration test&lt;/h2&gt;
&lt;p&gt;We need etcd to run the integration test, Docker to the rescue?&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker run -d --name etcd quay.io/coreos/etcd:v2.3.3 alias etcdctl=&amp;quot;docker exec etcd /etcdctl&amp;quot; alias etcd=&amp;quot;docker exec etcd /etcd&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Nop, it fails because kubernetes look for it in the PATH :-(&lt;/p&gt;
&lt;p&gt;So,&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh curl -O https://github.com/coreos/etcd/releases/download/v2.3.3/etcd-v2.3.3-linux-amd64.tar.gz tar xzvf etcd-v2.3.3-linux-amd64.tar.gz mv etcd-v2.3.3-linux-amd64/ ~/Software/ echo &amp;quot;PATH=~/Software/etcd-v2.3.3-linux-amd64:\$PATH&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile echo &amp;quot;export PATH&amp;quot; &amp;gt;&amp;gt; ~./bash_profile source ~./bash_profile&lt;/code&gt; And now, time to test. Be careful, I think it uses your Google Cloud account :-S&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh go run hack/e2e.go -v --build --up --test --down &amp;amp;&amp;amp; notify-send &amp;quot;Integration test done&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;Running the Restcomm image&lt;/h1&gt;
&lt;h2&gt;Creating and launching the cluster&lt;/h2&gt;
&lt;p&gt;It will ask for sudo permission, you have to be quick, or relaunch.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh hack/local-up-cluster.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let this terminal open and create a new one (tmux&apos;s time?)&lt;/p&gt;
&lt;h2&gt;Running the container&lt;/h2&gt;
&lt;p&gt;We don&apos;t have any container running:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cluster/kubectl.sh get pods cluster/kubectl.sh get services cluster/kubectl.sh get deployments&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Time to launch RestComm:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh curl -O https://gist.githubusercontent.com/antonmry/0ab69e95e61617eb957a79beb25ba30b/raw/c5c2979be63297571968f7db88c27e714e557fca/restcomm_rc.yml vim restcomm_rc.yml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Change STATIC_ADDRESS to your own IP address.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cluster/kubectl.sh create -f restcomm_rc.yml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now we should be able to see our docker instance working, pods and so on.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cluster/kubectl.sh get services cluster/kubectl.sh get deployments cluster/kubectl.sh get pods&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We have to wait the STATUS pod become running instead of ContainerCreating.&lt;/p&gt;
&lt;p&gt;After that, we can see our RestComm containers running:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh docker images docker ps&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Once it&apos;s running, we can expose the ports to access our instance:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh wget -O https://gist.githubusercontent.com/antonmry/0ab69e95e61617eb957a79beb25ba30b/raw/77c4eea558fcba9a1ad09d9b89221fdbe3a263fe/restcomm_service.yml vim restcomm_service.yml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Change externalIPs to your own IP address.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh cluster/kubectl.sh create -f restcomm_service.yml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;With the following command we can check the status:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sh ./cluster/kubectl.sh get svc&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;Test Restcomm!&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;sh chromium-browser https://CHANGE_WITH_YOUR_IP/olympus&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Login as alice, call +1234 and you should listen the message ;-)&lt;/p&gt;
&lt;h1&gt;Stop all&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;sh ./cluster/kubectl.sh delete service restcomm-service ./cluster/kubectl.sh delete rc restcomm-core-controller&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And Ctrl+C in the terminal running the cluster.&lt;/p&gt;
&lt;h1&gt;Reference documentation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://kubernetes.io/docs/getting-started-guides/scratch/&quot;&gt;Creating a Custom Cluster from Scratch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/kubernetes/kubernetes/blob/master/docs/devel/development.md&quot;&gt;Kubernetes Development Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://kubernetes.io/docs/getting-started-guides/locally/&quot;&gt;Running Kubernetes Locally with No VM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/adimania/Restcomm-Docker/blob/master/kubernetes/README.md&quot;&gt;Kubernetes and RestComm by adimania&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

	  </description>
    </item>
    
    <item>
      <title>First year as ACE Associate and 2016 goals</title>
      <link>https://www.galiglobal.com/blog/2016/20160102-First-year-as-ACE-Associate-and-2016-goals.html</link>
      <pubDate>Sat, 2 Jan 2016 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2016/20160102-First-year-as-ACE-Associate-and-2016-goals.html</guid>
      <description>
      &lt;p&gt;Another year is gone and as you can see in the look of the blog, I have a lot of new goals for this year :-). In short, 2015 has been a quite good year, with interesting projects in Brazil, business trips to cool cities as London, Paris, Krakow, Barcelona or Lisbon. Also time to mature the team, learn new technologies and evolve our solutions. But now it&apos;s time to look to the future. Goals for 2016:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DevOps, DevOps, DevOps&lt;/strong&gt;: in some way, I have been involved in DevOps all my professional life. Jumping from development to project management to system administration depending of the needs of the moment... the only things has been always there are Oracle Comms and how much I like to work with Linux, scripts, deployments and so on. I worked with Solaris Zones (precursor of Docker) and proposed to Vodafone in 2008... 8 years ago! And because of this, I&apos;m always more focused in development and/or product/project management: those areas are not so natural for me and there is more room for improvement. Well, this has to change. There are a lot of new stuff now related to that and I want to learn more. This will mean start to use &lt;a href=&quot;https://github.com/aestasit/sshoogr&quot;&gt;sshoogr&lt;/a&gt; (Ansible-like but using Groovy), improve our Docker and Amazon AWS usage and, most important of all, integrate everything to work smoothly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Groovy as center of our universe&lt;/strong&gt;: Groovy is becoming a very important part in Oracle Comms Services Gatekeeper and Oracle Comms WebRTC Session Controller. We&apos;ve embraced this change, and now we are working with &lt;a href=&quot;http://www.gradle.org&quot;&gt;Gradle&lt;/a&gt; for deployments and with &lt;a href=&quot;https://github.com/spockframework/spock&quot;&gt;Spock&lt;/a&gt; for unit and integration testing. Also, as you can see, I have migrated the blog from Octopress to Hexo to &lt;a href=&quot;http://www.jbake.org&quot;&gt;JBake&lt;/a&gt;, a blogging framework based in Java and Groovy. It&apos;s cool to publish your post using gradle :-)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Became even more fluent with Java&lt;/strong&gt;: I have started to use Intellij Idea and learn the shortcuts, read some books as &lt;a href=&quot;https://www.manning.com/books/netty-in-action&quot;&gt;Netty in action&lt;/a&gt;, made &lt;a href=&quot;https://www.coursera.org/specializations/mobilecloudcomputing2&quot;&gt;three Android courses&lt;/a&gt; in Coursera and more activities. I have to continue focusing on this, it&apos;s not easy because most of the development I&apos;m able to do is out of the office in pet projects, training or peer reviews. I have been working with Java since 2007 but the only way to continue being fluent in a language is practice, practice, practice...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oracle Comms and ACE&lt;/strong&gt;: Become ACE Associate has been a great achievement. Also the participation in different events with Oracle Comms, launch this blog, write some articles, videos and other stuff. I&apos;m quite happy but there is still a long way...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Improving the team&lt;/strong&gt;: our workflow is effective but there is a point we have to improve: it&apos;s quite complex for newcomers. That&apos;s the reason I&apos;ve started a new book in &lt;a href=&quot;https://leanpub.com&quot;&gt;Leanpub&lt;/a&gt; titled &lt;a href=&quot;https://leanpub.com/developmentworkflowforagileteams&quot;&gt;Development workflow for agile teams&lt;/a&gt; focused in our workflow. This should help to solve the gap.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Don&apos;t use the mouse&lt;/strong&gt;: yes, I&apos;m a vim fan and a linux user. My goal is just stop to use the mouse for all the task I do. I feel quite confident with Intellij Idea now and the &lt;a href=&quot;https://plugins.jetbrains.com/plugin/164?pr=idea&quot;&gt;IdeaVim&lt;/a&gt; plugin, &lt;a href=&quot;https://addons.mozilla.org/en-US/firefox/addon/vimperator/&quot;&gt;Firefox vimperator&lt;/a&gt; for browsing and the Linux console for most of the tasks. My main problems are with the email, calendar and some webs as Waffle and Feedly...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A pet project&lt;/strong&gt;: that&apos;s something I have been looking for some time without luck. I would like to build something using Java/Groovy and WebRTC, working with others in something not too complex to start with / greenfield. Well, I hope 2016 is the year for this.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&apos;s all! &lt;strong&gt;Happy and prosperous 2016!!&lt;/strong&gt;.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Oracle Pre-conference and TADSummit 2015</title>
      <link>https://www.galiglobal.com/blog/2015/Oracle-Preworkshop-and-TADSummit-2015.html</link>
      <pubDate>Tue, 17 Nov 2015 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2015/Oracle-Preworkshop-and-TADSummit-2015.html</guid>
      <description>
      &lt;p&gt;Great event and people, I participated the first day in the Oracle pre-workshop and also I did a lightning talk about our winner hack in the TADHack. Here the video:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ao9GRo5cjxM&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

	  </description>
    </item>
    
    <item>
      <title>Services Gatekeeper 6 installed in fifteen minutes, is it possible? - Part 2</title>
      <link>https://www.galiglobal.com/blog/2015/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible-Part-2.html</link>
      <pubDate>Sun, 30 Aug 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible-Part-2.html</guid>
      <description>
      &lt;p&gt;This is the continuation of how to install and test OCSG, you can find the part 1 &lt;a href=&quot;/blog/2015/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible-Part-1.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Platform Test Environment (PTE) Installation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Login to &lt;a href=&quot;https://edelivery.oracle.com/&quot;&gt;Oracle Software Delivery Cloud&lt;/a&gt;, choose &lt;em&gt;Oracle Communications&lt;/em&gt; in &lt;strong&gt;Select a Product Pack&lt;/strong&gt; and &lt;em&gt;Linux x86-64&lt;/em&gt; and click on &lt;strong&gt;Go&lt;/strong&gt;. Click on &lt;em&gt;Oracle Communications Services Gatekeeper 6.0&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download Oracle Communications Services Gatekeeper 6.0 Platform Test Environment, V73999-01.zip and copy it into the VM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unzip the file and execute the installer:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;sh unzip V73999-01.zip java -jar ocsg_pte_generic.jar&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In the first window, accept the default Inventory Directory pressing &lt;strong&gt;OK&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Welcome screen appears, press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Introduce &lt;em&gt;/opt/ocsg6&lt;/em&gt; in the Oracle Home field and press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let &lt;strong&gt;PTE Installation&lt;/strong&gt; selected and press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/installationPTE.png&quot; alt=&quot;PTE Installation&quot; /&gt;&lt;/p&gt;
&lt;p&gt;REPLACE_WITH_READ_MORE 8. Review the Installation Summary and press &lt;strong&gt;Install&lt;/strong&gt;. It may take a while. Press &lt;strong&gt;Next&lt;/strong&gt; when available and &lt;strong&gt;Finish&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/installationPTEDone.png&quot; alt=&quot;PTE Installation Done&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Start the PTE&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open a new Terminal and execute the following commands.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;sh cd /opt/ocsg6/ocsg_pte/ ./run.sh&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The PTE should appear:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/PTE.png&quot; alt=&quot;The PTE&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Tools -&amp;gt; Variables Manager&lt;/strong&gt; or press &lt;strong&gt;Ctrl+3&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/VariablesManagerMenu.png&quot; alt=&quot;Variables Manager Menu&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Change the following fields and press &lt;strong&gt;OK&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;at.host:&lt;/strong&gt; &lt;em&gt;ocsg&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nt.host:&lt;/strong&gt; &lt;em&gt;ocsg&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/VariablesManager.png&quot; alt=&quot;Variables Manager Screen&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Click on &lt;strong&gt;Server&lt;/strong&gt; and change the following fields:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hostname:&lt;/strong&gt; &lt;em&gt;ocsg&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Port:&lt;/strong&gt; &lt;em&gt;8001&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Username:&lt;/strong&gt; &lt;em&gt;weblogic&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Password:&lt;/strong&gt; &lt;em&gt;welcome1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/ServerCredentials.png&quot; alt=&quot;Server Credentials&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Tools -&amp;gt; SLA Manager&lt;/strong&gt; or press &lt;strong&gt;Ctrl+1&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/SLAManagerMenu.png&quot; alt=&quot;SLA Manager Menu&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select &lt;strong&gt;default_app_group&lt;/strong&gt; and click on the pencil icon.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/default_app_group.png&quot; alt=&quot;Default App Group SLA&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Click on the globe icon with a green arrow pointing up and press &lt;strong&gt;Local&lt;/strong&gt;. The message &lt;em&gt;The SLA was succesfully uploaded to OCSG&lt;/em&gt; should appear. Press &lt;strong&gt;OK&lt;/strong&gt; twice.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/default_app_group_done.png&quot; alt=&quot;Default App Group SLA Done&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select &lt;strong&gt;default_sp_group&lt;/strong&gt; and click on the pencil icon. Click on the globe icon with a up arrow and press &lt;strong&gt;Local&lt;/strong&gt;. The message &lt;em&gt;The SLA was succesfully uploaded to OCSG&lt;/em&gt; should appear. Press &lt;strong&gt;OK&lt;/strong&gt; twice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;strong&gt;Simulators -&amp;gt; SMPP&lt;/strong&gt; and click on &lt;strong&gt;Start&lt;/strong&gt;. The button will change to &lt;strong&gt;Stop&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/SMPPSimulator.png&quot; alt=&quot;SMPP Simulator&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Final test: send SMS&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;In the PTE, go to &lt;strong&gt;Clients -&amp;gt; Login&lt;/strong&gt; and press &lt;strong&gt;Login&lt;/strong&gt; (green arrow). The button should change to &lt;strong&gt;Logout&lt;/strong&gt; (red square).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/login.png&quot; alt=&quot;Client Login&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Messaging -&amp;gt; Short Messaging -&amp;gt; Application-initiated&lt;/strong&gt; and change the message to &lt;em&gt;Hello SaNE!&lt;/em&gt;. Click on &lt;strong&gt;Send&lt;/strong&gt; (green arrow).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/sendSMS.png&quot; alt=&quot;Send SMS&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to the &lt;strong&gt;Map&lt;/strong&gt;, click on the second button over the phone &lt;strong&gt;1234&lt;/strong&gt; and choose &lt;em&gt;Read messages&lt;/em&gt;. Here it is!!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/SMS.png&quot; alt=&quot;SMS Sent&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Probably you have spent more than fifteen minutes to arrive here... but it&apos;s also true most of the actions are part of the configuration, not the installation. The process is straightforward and it can be easily explained. Even if you don&apos;t have advanced knowledge of Weblogic or Linux, it&apos;s possible to do it. So, as we can see in this article, OCSG is very easy to install now and it has a lot of features deployed out-of-the-box. Because it&apos;s a so extensive application supporting a huge number of business possibilities (Service API Exposure, Direct Carrier Billing, Policy Gateway, etc. ), a basic fresh installation is a very powerful way to focus in the functionality and forget problems with databases, OS and other technical questions and now we can have it in only 15 minutes!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>We are TADHack 2015 winners :-)</title>
      <link>https://www.galiglobal.com/blog/2015/We-are-TADHack-2015-winners.html</link>
      <pubDate>Fri, 31 Jul 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/We-are-TADHack-2015-winners.html</guid>
      <description>
      &lt;p&gt;Without any type of doubt, &lt;a href=&quot;http://www.tadhack.com&quot;&gt;TADHack&lt;/a&gt; is my favourite event in the year. Mainly because of three reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Excellent collaborative atmosphere and lots of friends. I love to have the opportunity to share some time with people involved in the same topics I&apos;m working with. And not only that, it&apos;s full of techies :-)&lt;/li&gt;
&lt;li&gt;Event is well managed by Alan Quayle and his team. Everything goes smoothly and you are always busy speaking, developing, visiting other vendors or watching other hacks.&lt;/li&gt;
&lt;li&gt;It&apos;s not too big, so you have the chance to have a chat with almost everybody... this seems weird but when I&apos;m participating in bigger events, I&apos;ve the feeling I don&apos;t have time enough to speak with all people I would like to speak with. That doesn&apos;t happen in TADHack.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My participation in this event is mainly because we are running and providing support for the Oracle Comms environment, there is a web with information about all the resources in case you are interested: &lt;a href=&quot;http://tadhack.optaresolutions.com&quot;&gt;http://tadhack.optaresolutions.com&lt;/a&gt;. Even if it&apos;s the second year we are doing it, the installation of the three Oracle SDP products it&apos;s not straightforward. We had to update to the last versions of the products and we are always looking for ways to improve it. It&apos;s not a secret we are using &lt;a href=&quot;https://aws.amazon.com/about-aws/&quot;&gt;Amazon Web Services&lt;/a&gt; to support this infrastructure. Some day I have to write a post about the whole infrastructure and how we are using AWS to support the service. The part about how we upload the VMs to AWS EC2 is quite awesome and tricky because some of them are based in customized Linux versions.&lt;/p&gt;
&lt;p&gt;One of the most interesting things this year was the opportunity to participate as developers. Obviously we cannot be winners of the Oracle prize, it wouldn&apos;t be fair, but we can combine the Oracle environment with other sponsors, in this case we chose Intel providing an embedded board. Also we have a new member in the NetApps team, &lt;a href=&quot;https://twitter.com/jonathrodriguez&quot;&gt;Jonathan&lt;/a&gt;, who is a great Java and Android developer. &lt;a href=&quot;https://www.youtube.com/embed/LgYdT9Q7OWw&quot;&gt;Here&lt;/a&gt; it&apos;s the video where he&apos;s showing the hack in Lisbon:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/LgYdT9Q7OWw&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;And now the big news... we won!&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Heart Rate Monitor team, winners of &lt;a href=&quot;https://twitter.com/Inteliot&quot;&gt;@Inteliot&lt;/a&gt; prize at &lt;a href=&quot;https://twitter.com/TADHack&quot;&gt;@TADHack&lt;/a&gt; &lt;a href=&quot;https://twitter.com/antonmry&quot;&gt;@antonmry&lt;/a&gt; &lt;a href=&quot;http://t.co/iPbWtemQ25&quot;&gt;pic.twitter.com/iPbWtemQ25&lt;/a&gt;&lt;/p&gt;&amp;mdash; Alan Quayle (@Alan_Quayle) &lt;a href=&quot;https://twitter.com/Alan_Quayle/status/610618140918157313&quot;&gt;June 16, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;You can see my big smile in the photo. I&apos;m more than happy being one of the winners. I guess I always have been a bit jealous of the others developers :-)&lt;/p&gt;
&lt;p&gt;In short, TADHack 2015 has been great and bigger than the 2014 edition. The TAD ecosystem is evolving very quick and I&apos;m really excited to see how this evolves in the following years.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>A look back to Geecon 2015</title>
      <link>https://www.galiglobal.com/blog/2015/A-look-back-to-Geecon-2015.html</link>
      <pubDate>Tue, 30 Jun 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/A-look-back-to-Geecon-2015.html</guid>
      <description>
      &lt;p&gt;I&apos;ve been invited by Oracle Comms to join &lt;a href=&quot;http://2015.geecon.org/speakers/info.html?id=70&quot;&gt;Geecon 2015&lt;/a&gt; to speak about Web Real Time Commutations – Voice, Video, and Data Communications with my good friend &lt;a href=&quot;https://twitter.com/Doug_Tait&quot;&gt;Douglas Tait&lt;/a&gt;. It&apos;s always a pleasure to work with someone as Doug and his feedback about previous editions was really good, so I was more than happy to participate in this event.&lt;/p&gt;
&lt;p&gt;When I joined the event, I quickly realized Doug was right. There are all things you can expect from a developer event but mixed with a lot of fun things. Everybody is really friendly, organizers made a huge effort to make everybody feel really well. There are a lot of jokes. I really like the speakers hats, even if my head is too big for them, I know, it&apos;s my fault ;-)&lt;/p&gt;
&lt;p&gt;One of the things I was more impressed with it&apos;s the place itself. It&apos;s a commercial cinema in Krakow. So everyday when the event ends, movies start. It&apos;s awesome. The place is perfect for conferences: great sound, great screen, comfortable chairs, etc. At the same time, it should be easy to book it, most of the cinemas are empty now, at least in Spain. It&apos;s a great idea and a good example of how Geecon organizers are able to think out of the box.&lt;/p&gt;
&lt;p&gt;The other thing I really enjoyed it was the attendees. They were very participative, making good questions, proposing new ideas. In one of the conferences, even helped the speaker with some IntelliJ Idea shortcuts, really cool! With our talk it wasn&apos;t different, they made a lot of questions and we finished speaking with a lot of them. For something so specific as WebRTC and communications, it was great to see some people really interested on it. I have been always jealous of the Java ecosystem in relation to the TAD ecosystem, even with the great help of TADHack, there is a big gap yet.&lt;/p&gt;
&lt;p&gt;Our talk was about how Java helps in communications, with focus on WebRTC, SIP and Telecom APIs. People was more interested in WebRTC than any other subject. We run some demos, show some code and made some jokes. &lt;a href=&quot;https://vimeo.com/131761796&quot;&gt;Here&lt;/a&gt; it&apos;s the video recorded by the Geecon organizers:&lt;/p&gt;
&lt;iframe src=&quot;https://player.vimeo.com/video/131761796&quot; width=&quot;500&quot; height=&quot;281&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/131761796&quot;&gt;GeeCON 2015: Ant&amp;oacute;n Yuste, Douglas Tait - Web Real Time Commutations &amp;ndash; Voice, Video, and Data Communications&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/geecon&quot;&gt;GeeCON Conference&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I really would like to repeat next year. This is one of the best events where I had the opportunity to participate.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>TMCnet Newsroom Interview with Anton R. Yuste</title>
      <link>https://www.galiglobal.com/blog/2015/TMCnet-Newsroom-Interview-with-Anton-R-Yuste.html</link>
      <pubDate>Sun, 21 Jun 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/TMCnet-Newsroom-Interview-with-Anton-R-Yuste.html</guid>
      <description>
      &lt;p&gt;Some days ago I had the opportunity to do a interview for &lt;a href=&quot;http://www.tmcnet.com&quot;&gt;TMCnet&lt;/a&gt; with Peter Bernstein. It was a fun experience and it&apos;s great to have time to speak about WebRTC, Hackathons and Oracle Communications. Here it&apos;s the interview:&lt;/p&gt;
&lt;iframe frameborder=&quot;0&quot; width=&quot;450&quot; height=&quot;270&quot; scrolling=&quot;no&quot; src=&quot;http://www.tmcnet.com/tmc/videos/videoiframe.aspx?vid=11239&amp;width=450&amp;height=270&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;TMCnet link: &lt;a href=&quot;http://www.tmcnet.com/tmc/videos/default.aspx?vid=11239#&quot;&gt;TMCnet Newsroom Interview with Optare Solutions&lt;/a&gt;&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>The Oracle ACE Associate award</title>
      <link>https://www.galiglobal.com/blog/2015/The-Oracle-ACE-Associate-award.html</link>
      <pubDate>Tue, 16 Jun 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/The-Oracle-ACE-Associate-award.html</guid>
      <description>
      &lt;p&gt;In the beginning of the year, I&apos;ve been awarded as &lt;a href=&quot;https://apex.oracle.com/pls/apex/f?p=19297:4:::NO:4:P4_ID:12240&quot;&gt;Oracle ACE Associate&lt;/a&gt;. It was the first time I&apos;ve earned something like that so I&apos;m very proud and happy. It&apos;s not a secret I&apos;ve been working with Oracle Comms since 2007 but it wasn&apos;t until last year I started to be more active in social networks, writing articles and attending conferences. I should have started to do it sooner but it&apos;s not so easy, and it isn&apos;t until now I really know my desired professional path.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/About-me/O_ACE_Icon_blk.png&quot; alt=&quot;Oracle ACE Associate&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Let me explain the different reasons because this award is important to me.&lt;/p&gt;
&lt;h2&gt;Optare Solutions&lt;/h2&gt;
&lt;p&gt;Optare is a great company full of potential ACEs. I remember RittmanMead (a similar company in the BI space) and how &lt;a href=&quot;http://www.rittmanmead.com/2014/12/six-months-an-ace/&quot;&gt;they promote their workers to became Oracle ACE and participate in technical conferences&lt;/a&gt;. I know how important is this type of activities. Things like that provide a more clear professional path, increase the visibility of the company (hey! They have 5 Orace ACE and 1 Oracle ACE Director) and, even more important, it helps to identify and retain talented people. I am the first Oracle ACE Associate in Optare. I hope this is only the beginning. There are really good Oracle consultants and developers in the company, so the most important thing (the know-how) is not going to be the problem.&lt;/p&gt;
&lt;h2&gt;Oracle Communications&lt;/h2&gt;
&lt;p&gt;Even if Oracle Comms is quite big after the adquisitions of ACME and Tekelec, the OTN community is quite inactive. For example, the last OTN article published &lt;a href=&quot;http://www.oracle.com/technetwork/articles/communications/index.html&quot;&gt;here&lt;/a&gt; it was in 2005, and not, the solution isn&apos;t close the section!. I would like to see a more active community and that was the reason of my Oracle ACE Associate submission. I know it&apos;s a big task and it&apos;s impossible to achieve it alone but there are some people inside Oracle working in this direction and I am quite positive. A probe of that is the &lt;a href=&quot;http://www.tadhack.com&quot;&gt;TADHack&lt;/a&gt; and the &lt;a href=&quot;http://tadhack.optaresolutions.com/&quot;&gt;Oracle Sandbox&lt;/a&gt; promoted by &lt;a href=&quot;https://twitter.com/Doug_Tait&quot;&gt;Douglas Tait&lt;/a&gt;, he&apos;s doing a great job building a developers community. I am sure we&apos;ll see important updates in the following months.&lt;/p&gt;
&lt;h2&gt;Myself&lt;/h2&gt;
&lt;p&gt;Everyone likes to receive awards and I am not different. But more important, it&apos;s a good sign about how I am doing things right now. In the end of 2012, I left Accenture and my work as Project Manager. I returned to Optare Solutions and it&apos;s a decision I don&apos;t regret. But I&apos;ve to paid the fee: stop my career as manager and back to be a technical guy. Being an IT worker in Spain is never more a professional suicide. There are some cool companies as Optare Solutions and Quobis, or you can work remotely for foreign companies. All you have to do is to be a good engineer and speak English well. That&apos;s the reason because Oracle ACE Associate is important to me: it probes both.&lt;/p&gt;
&lt;p&gt;Other important point, Oracle ACE Associate gives me access to some cool resources and the possibility to speak in technical conferences. I really appreciate that right now. And, of course, I have some cool Oracle stuff now :-)&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;A nice gift waiting for me in the office... thanks &lt;a href=&quot;https://twitter.com/oracleace&quot;&gt;@oracleace&lt;/a&gt;! I am really happy being part of the team &lt;a href=&quot;https://twitter.com/hashtag/OracleACE?src=hash&quot;&gt;#OracleACE&lt;/a&gt; &lt;a href=&quot;http://t.co/07Ebbky4MG&quot;&gt;pic.twitter.com/07Ebbky4MG&lt;/a&gt;&lt;/p&gt;&amp;mdash; Antón R. Yuste (@antonmry) &lt;a href=&quot;https://twitter.com/antonmry/status/595869056210751489&quot;&gt;May 6, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;I can not end this blog post without mention &lt;a href=&quot;https://es.linkedin.com/pub/miguel-garcia-lorenzo/33/69b/63a/en&quot;&gt;Miguel Garcia&lt;/a&gt;. He was the guy who has nominated me for the award. It&apos;s an honor to be nominated for someone so good and experienced as Miguel. Thanks!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Introductory videos to OCSG, OCCAS and OCWSC</title>
      <link>https://www.galiglobal.com/blog/2015/Introductory-videos-to-OCSG-OCCAS-and-OCWSC.html</link>
      <pubDate>Thu, 11 Jun 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/Introductory-videos-to-OCSG-OCCAS-and-OCWSC.html</guid>
      <description>
      &lt;p&gt;Tomorrow I will be travelling to &lt;a href=&quot;http://tadhack.com/2015/&quot;&gt;TADHack&lt;/a&gt; in Lisbon and I am so excited! It&apos;s going to be great! As part of the initiatives we&apos;ve done to promote &lt;a href=&quot;http://tadhack.optaresolutions.com/&quot;&gt;the Oracle sandbox&lt;/a&gt; and help the developers, I&apos;ve recorded three videos to introduce the three Oracle SDP applications. Even if they are oriented to the TADHack, they are a good resource for anyone interested in the products.&lt;/p&gt;
&lt;h2&gt;Oracle Communications WebRTC Session Controller&lt;/h2&gt;
&lt;p&gt;In this video, we are going to introduce Oracle Communications WebRTC Session Controller and how to use it to add audio, video and data communications to web and mobile applications. It provides an introduction to a sample application, a good starting point to develop more complex services. It ends explaining how to add a widget which allows developers to add Real-time communication in a very easy way.&lt;/p&gt;
&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/PBUyris2GUA&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h2&gt;Oracle Communications Service Gatekeeper&lt;/h2&gt;
&lt;p&gt;In this video, we are going to introduce the Telecom APIs available in the Oracle Communications sandbox: Messaging, Payment and Location. Developers will learn how to start to work with those APIs and how to add them to their own applications and hacks.&lt;/p&gt;
&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/e6W3Dpx4Rsc&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;h2&gt;Oracle Communications Converged Application Server&lt;/h2&gt;
&lt;p&gt;In this video, we are going to introduce Oracle Communications Converged Application Server and how to design and build applications able to manage HTTP and SIP protocols at the same time. We&apos;ll review also the new SIP Servlet 2.0 specification and the JSR-359 recently approved. We&apos;ll end the video reviewing a B2BUA application and learning to modify it to build more complex applications.&lt;/p&gt;
&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/50fZ1-3dpnE&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

	  </description>
    </item>
    
    <item>
      <title>Summary of the last news in the Oracle Communications Service Delivery Platform</title>
      <link>https://www.galiglobal.com/blog/2015/Summary-of-the-last-news-in-the-Oracle-Communications-Service-Delivery-Platform.html</link>
      <pubDate>Thu, 21 May 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/Summary-of-the-last-news-in-the-Oracle-Communications-Service-Delivery-Platform.html</guid>
      <description>
      &lt;p&gt;When I&apos;ve started this blog, my main motivation was to provide a central place with information about Service Delivery Platforms, mainly related to the Oracle Communication suite because it&apos;s what I know. But I am failing in this goal. I am very busy from the beginning of the year and I don&apos;t find time enough to write posts and articles. Excuses. I should keep in mind the original idea and don&apos;t miss the opportunity to keep readers updated with the last news.&lt;/p&gt;
&lt;p&gt;So, this post is going to be a summary of the releases and news in the Oracle Comms SDP.... and there are a lot!. Even a new product!.&lt;/p&gt;
&lt;h1&gt;Oracle Communications Services Gatekeeper (aka Gatekeeper)&lt;/h1&gt;
&lt;p&gt;I wrote about the new 6.0 version &lt;a href=&quot;/2015/01/23/OCSG-6-0v1-generally-available-new-features-introduction/&quot;&gt;here&lt;/a&gt; and even I&apos;ve published &lt;a href=&quot;/2015/04/30/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible-Part-1/&quot;&gt;the first part of a how-to explaining the installation&lt;/a&gt;. But there are two very interesting updates.&lt;/p&gt;
&lt;h2&gt;Oracle Communications Services Gatekeeper 6.0 Patch Set 1 Released&lt;/h2&gt;
&lt;p&gt;New patch solving more than 20 bugs: &lt;a href=&quot;https://support.oracle.com/epmos/faces/DocumentDisplay?_afrLoop=447946421774684&amp;amp;id=1993751.1&amp;amp;_afrWindowMode=0&amp;amp;_adf.ctrl-state=1de1letpct_4&quot;&gt;Doc ID 1993751.1&lt;/a&gt;. Whatever you are doing with OCSG, the installation of this patch should be mandatory.&lt;/p&gt;
&lt;p&gt;It provides also patches for JDK &lt;a href=&quot;https://support.oracle.com/epmos/faces/ui/patch/PatchDetail.jspx?parent=DOCUMENT&amp;amp;sourceId=1993751.1&amp;amp;patchId=20347164&quot;&gt;Patch 20347164&lt;/a&gt;, Weblogic &lt;a href=&quot;https://support.oracle.com/epmos/faces/ui/patch/PatchDetail.jspx?parent=DOCUMENT&amp;amp;sourceId=1993751.1&amp;amp;patchId=19637454&quot;&gt;Patch 19637454&lt;/a&gt; and Coherence &lt;a href=&quot;https://support.oracle.com/epmos/faces/ui/patch/PatchDetail.jspx?parent=DOCUMENT&amp;amp;sourceId=1993751.1&amp;amp;patchId=20164069&quot;&gt;Patch 20164069&lt;/a&gt;, be sure to apply them!&lt;/p&gt;
&lt;h2&gt;Oracle Communications Services Gatekeeper Statement of Direction - May 2015&lt;/h2&gt;
&lt;p&gt;Oracle has published recently a SoD for OCSG. It&apos;s always interesting to know what Oracle is working on. Here, &lt;a href=&quot;https://support.oracle.com/epmos/faces/DocumentDisplay?_afrLoop=448644669159009&amp;amp;id=1081178.1&amp;amp;_afrWindowMode=0&amp;amp;_adf.ctrl-state=1de1letpct_78&quot;&gt;Doc ID 1081178.1&lt;/a&gt;, you can find it. The document deserves a special post for it!.&lt;/p&gt;
&lt;h1&gt;Oracle Communications Application Server (aka OCCAS)&lt;/h1&gt;
&lt;p&gt;A new version for our favorite AS... from 5.1 to 7.0. A lot of new changes!. The most important item, it&apos;s the first implementation of the recently released &lt;a href=&quot;https://www.jcp.org/en/jsr/detail?id=359&quot;&gt;JSR 359: SIP Servlet 2.0&lt;/a&gt;. There are also other things, for instance, new (and more modern!) versions of the JDK and Weblogic. This is not a release with a lot of new features but with a lot of improvements for developers. Here it&apos;s the announcement:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Oracle Communications Converged Application Server (OCCAS) 7.0 release is now available to customers/partners for download. OCCAS 7.0 is the industry’s first JSR 359 (SIP Servlet 2.0) compliant SIP Application Server/Communications Middleware based on Java EE 6/Java EE 7.  OCCAS 7.0 also introduces Coherence based in-memory, distributed cache data architecture that enables the customers to dynamically scale mission-critical applications.  OCCAS 7.0 also introduces a flexible overload framework and monitoring functions which along with the auto scaling capabilities makes it Cloud/NFV ready.&lt;/p&gt;
&lt;p&gt;Here are some key capabilities of the release:&lt;/p&gt;
&lt;p&gt;** SIP Servlet 2.0/ JSR 359 Compliance ** * Makes SIP Servlet Development more agile  (Java EE 6/7, CDI, POJOs, Annotations etc) * Meets most demanding requirements of communications middleware (Converged container, abstraction, portability, standards compliance etc) * Fosters decentralized ecosystem  (Extensibility, Pluggability etc)&lt;/p&gt;
&lt;p&gt;** Coherence based data architecture ** * Elasticity – Scale in/out * Reliability/fault tolerance/HA * Performance&lt;/p&gt;
&lt;p&gt;** Monitoring and Overload Protection ** * Overload Framework/ Custom KPI policies and threshold configuration * Memory Based Overload Protection&lt;/p&gt;
&lt;p&gt;** Enhanced Diameter Support ** * SIP Application Interworking with Diameter&lt;/p&gt;
&lt;p&gt;** Virtualization Technologies Support ** * OVM &amp;amp; KVM Certification&lt;/p&gt;
&lt;p&gt;** Platform Upgrade ** * Based on WebLogic 12.1.3  (latest release)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Source: &lt;a href=&quot;https://community.oracle.com/docs/DOC-913298?sr=inbox&amp;amp;ru=831131&quot;&gt;Oracle Community&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Oracle Communications WebRTC Session Controller (aka WSC)&lt;/h1&gt;
&lt;h2&gt;New version of Oracle Communications WebRTC Session Controller&lt;/h2&gt;
&lt;p&gt;WSC 7.1 was announced on December 2014 &lt;a href=&quot;http://www.oracle.com/us/corporate/press/2391012?rssid=rss_ocom_pr&quot;&gt;here&lt;/a&gt; but it wasn&apos;t Generally Available until March 2015. Bugs fixed and some interesting features as invoke REST interfaces from the Groovy scripts or some improvements in the registrar. Check the &lt;a href=&quot;http://docs.oracle.com/cd/E55119_01/doc.71/e55133/toc.htm&quot;&gt;Release note&lt;/a&gt; for more info.&lt;/p&gt;
&lt;h2&gt;iOS SDK and Android SDK finally available&lt;/h2&gt;
&lt;p&gt;Recently the SDKs for Android and iOS have been published. You can find them &lt;a href=&quot;http://www.oracle.com/technetwork/developer-tools/webrtc-2525637.html&quot;&gt;here&lt;/a&gt;. Also there are some excellent how-to wrote by Leif Lourie &lt;a href=&quot;https://apexapps.oracle.com/pls/apex/f?p=44785:2:109737384896297:::2,CIR,RIR:P2_PRODUCT_ID,P2_RELEASE_ID:3479&quot;&gt;here&lt;/a&gt;. As usual, great work from Leif.&lt;/p&gt;
&lt;h1&gt;Oracle Communications Evolved Communications Application Server (aka eCAS)&lt;/h1&gt;
&lt;p&gt;The most important news for the end: a new product based in OCCAS. Here the note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As mobile operators drive their networks toward an all-IP and virtualized state, they require the means to design and deliver compelling high definition voice, video and multimedia offers via Voice over LTE (VoLTE) and Voice over WiFi (VoWiFi). Oracle Communications Evolved Communications Application Server (OCECAS) brings a sophisticated, yet easy-to-use network service design and delivery product to satisfy that need. OCECAS works out of the box; it is NFV-enabled and standards compliant; and it provides network-grade speed and reliability with the cost profile of an IT product.&lt;/p&gt;
&lt;p&gt;Beyond service delivery, OCECAS accelerates the operator&apos;s move to better network cost performance by driving subscribers to offers that engage IP assets, allowing the operator to retire more traditional components. This drive toward the single IP network also facilitates spectrum reuse for increased monetization opportunity. OCECAS is a significant step forward in the journey to the all-IP, virtualized network destination.&lt;/p&gt;
&lt;p&gt;Operators will also enjoy lower service update costs as the flexible user interface allows service changes to be implemented without costly, time-consuming software coding or vendor customizations.&lt;/p&gt;
&lt;p&gt;The Oracle Communications Evolved Communications Application Server includes:&lt;/p&gt;
&lt;p&gt;** Key Capabilities ** - Out of the box VoLTE and VoWiFi application designed for GSMA standards for immediate productivity - Built from the ground up to support NFV - Standards-compliant IMS interfaces built with SIP, Diameter and Java - Easy to use, yet powerful session design center providing intuitive drag and drop application configuration - Continuous design-time validation enforcement and version control to ensure quality - Automated deployment across testing, staging and production environments - Flexible data federation across multiple sources to prevent costly custom integrations - Productized integration with Oracle Communications Core Session Manager (OCCSM) - Runtime powered by the Oracle Communications Converged Application Server (OCCAS) 7.0 - Interoperability testing underway with Radisys and Dialogic Media Resource Functions - Integration of inbound third-party services, enabling differentiated offers&lt;/p&gt;
&lt;p&gt;** Benefits ** - Productive from the first day - Delivers true service agility for improved time to market - Enables attractive, differentiated offer creation - Freedom from vendor-specific customizations - Virtualized, interoperable, standards-compliant - Robust, network-grade operation on industry-standard platforms - Low TCO&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Source: &lt;a href=&quot;https://community.oracle.com/docs/DOC-913067?sr=inbox&amp;amp;ru=831131&quot;&gt;Oracle Community&lt;/a&gt; and also check the Press note &lt;a href=&quot;http://www.oracle.com/us/corporate/press/2526355?rssid=rss_ocom_pr&quot;&gt;here&lt;/a&gt;. There is also a &lt;a href=&quot;https://eventreg.oracle.com/profile/web/index.cfm?PKwebID=0x22479021e2&amp;amp;varPage=home&quot;&gt;webinar&lt;/a&gt;, don&apos;t miss it if you are interested.&lt;/p&gt;
&lt;p&gt;For me it&apos;s really good to have a release like this. Being OCCAS based, it&apos;s very easy for us to learn the new product and there are some interesting integration with ACME products. I will build a laboratory very soon and I hope to find time to write more about this new product.&lt;/p&gt;
&lt;p&gt;Stay tunned!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>SpringIO 2015: a great event for a great community</title>
      <link>https://www.galiglobal.com/blog/2015/SpringIO-2015-a-great-event-for-a-great-community.html</link>
      <pubDate>Thu, 14 May 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/SpringIO-2015-a-great-event-for-a-great-community.html</guid>
      <description>
      &lt;p&gt;I had the opportunity to participate in &lt;a href=&quot;http://www.springio.net/using-groovy-to-empower-webrtc-network-systems/&quot;&gt;SpringIO as speaker&lt;/a&gt; in April (Barcelona). It was quite scary to participate in a conference about Spring, I am not a web developer, and, in fact, when I have to develop or design any web system based in Java, I prefer just to use EJB3 and Servlet 3.2, avoiding any framework. But there is something more in this conference: &lt;a href=&quot;http://en.wikipedia.org/wiki/Groovy_%28programming_language%29&quot;&gt;Groovy&lt;/a&gt;. And we are using Groovy in a lot of cool things, specially in the WebRTC domain. So the idea was simple: introduce WebRTC and show an interesting Groovy use case.&lt;/p&gt;
&lt;p&gt;Unfortunately, Groovy is not in a good moment right now. Yes, there are a lot of people speaking about it... but after Strachan (Groovy&apos;s creator) wrote on his blog, &amp;quot;I can honestly say if someone had shown me the Programming in Scala book by Martin Odersky, Lex Spoon &amp;amp; Bill Venners back in 2003 I&apos;d probably have never created Groovy.&amp;quot; and Pivotal is not hosting the project any more... well, uncertain future for Groovy... and it&apos;s a pity. Because sometimes we need a scripting language and Groovy is a great choice if you are a Java developer, as I am. It&apos;s dynamically compiled to Java Virtual Machine (JVM) bytecode, so the performance is good, even for network system. Also it can interoperate with other Java code and libraries.&lt;/p&gt;
&lt;p&gt;For all these reasons, I would like to see Oracle more involved in the Groovy project, for instance reviving the &lt;a href=&quot;https://jcp.org/en/jsr/detail?id=241&quot;&gt;JSR-241&lt;/a&gt; and ending with &lt;a href=&quot;http://en.wikipedia.org/wiki/Jython&quot;&gt;jython&lt;/a&gt;... If you are working with &lt;a href=&quot;https://docs.oracle.com/cd/E29542_01/nav/wlst.htm&quot;&gt;Weblogic Scripting Tool (WLST)&lt;/a&gt;, you probably hate Jython as much I do.  Other important point is &lt;a href=&quot;https://gradle.org/&quot;&gt;gradle&lt;/a&gt;, it looks a great tool even if I didn&apos;t have opportunity to test it yet. Anyway, I am quite happy with Maven, specially now with the &lt;a href=&quot;https://blogs.oracle.com/WebLogicServer/entry/weblogic_server_and_the_oracle&quot;&gt;new Maven Oracle Repository&lt;/a&gt;. And I have also &lt;a href=&quot;https://code.google.com/p/spock/&quot;&gt;Spock&lt;/a&gt; in the &amp;quot;thing to review&amp;quot; list, a testing framework also based in Groovy.&lt;/p&gt;
&lt;p&gt;Even if my talk wasn&apos;t successful and my interest in the Spring framework is limited, I&apos;ve really enjoyed the event. First, because it was very well organized. Second, the quality of the speakers was awesome, the technical quality of some talks was superb. And not only because of the speakers, also because of the audience. I envy Spring having a so good community, it would we so great to have something similar with Telecom Application Developers. That&apos;s one of the reasons because I&apos;m so excited with the &lt;a href=&quot;http://tadhack.com/2015/&quot;&gt;TADHack&lt;/a&gt; and all the work &lt;a href=&quot;http://alanquayle.com&quot;&gt;Alan Quayle&lt;/a&gt; is doing. It is a long road yet but a good start.&lt;/p&gt;
&lt;p&gt;Here my slides. I&apos;ve covered WebRTC, then Groovy and I&apos;ve finished with some TADHack references.&lt;/p&gt;
&lt;iframe src=&quot;https://www.slideshare.net/slideshow/embed_code/key/bKBppeBAK8rQze&quot; width=&quot;476&quot; height=&quot;400&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;There is also a project in GitHub with the source code if you are interested: &lt;a href=&quot;https://github.com/antonmry/SpringIOWebRTCSampleApp&quot;&gt;SpringIOWebRTCSampleApp&lt;/a&gt;.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Services Gatekeeper 6 installed in fifteen minutes, is it possible? - Part 1</title>
      <link>https://www.galiglobal.com/blog/2015/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible-Part-1.html</link>
      <pubDate>Thu, 30 Apr 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible-Part-1.html</guid>
      <description>
      &lt;p&gt;Oracle Communications &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/connected-digital-lifestyle/services-gatekeeper/overview/index.html&quot;&gt;Services Gatekeeper 6&lt;/a&gt;, the industry-leading API exposure platform, is Generally Available and with many new and interesting features. One of them is the simplified configuration and deployment with installation in 15 minutes, based on lightweight single tier deployment option. I really like the idea, it&apos;s going to help with Proofs of Concept and Training. So in this article, I am going to review this feature: a fight against the clock to know how many time an OCSG student needs to deploy OCSG.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/StandaloneOCSG6.png&quot; alt=&quot;Services Gatekeeper Standalone System&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Disclaimer: some steps shouldn&apos;t be executed in production environments.&lt;/p&gt;
&lt;h2&gt;Preparations Overview&lt;/h2&gt;
&lt;p&gt;As good practice, the first step is always check the &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e50756/ins_sysreq.htm#SGINS122&quot;&gt;Supported Platform Matrix&lt;/a&gt;. For this installation, we have the following pre-requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Oracle Linux 6: in this case, it is version 6.6 x64, you can download it from &lt;a href=&quot;https://edelivery.oracle.com/linux&quot;&gt;Oracle Software Delivery Cloud&lt;/a&gt;. It may run hosted in an &lt;a href=&quot;http://www.oracle.com/technetwork/server-storage/virtualbox/downloads/index.html&quot;&gt;Oracle Virtualbox environment&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;JDK 1.7 installed: in this case, Java SE Development Kit 7u75 for Linux x64 (tgz). You can download it from &lt;a href=&quot;http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html&quot;&gt;Oracle Java SE Development Kit 7 Downloads&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Access as root user and also as oracle user.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;OCSG installation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Login to &lt;a href=&quot;https://edelivery.oracle.com/&quot;&gt;Oracle Software Delivery Cloud&lt;/a&gt;, choose &lt;em&gt;Oracle Communications&lt;/em&gt; in &lt;strong&gt;Select a Product Pack&lt;/strong&gt; and &lt;em&gt;Linux x86-64&lt;/em&gt; and click on &lt;strong&gt;Go&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on &lt;em&gt;Oracle Communications Services Gatekeeper 6.0&lt;/em&gt;. Download Oracle Communications Services Gatekeeper 6.0 Software, V73995-01.zip and copy it into the VM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open a Terminal and execute:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;sh sudo mkdir /opt/ocsg6 sudo chown oracle:oracle /opt/ocsg6&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Unzip the file and execute the installer:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;sh unzip V73995-01.zip java -jar ocsg_generic.jar&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In the first window, accept the default Inventory Directory pressing &lt;strong&gt;OK&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/Inventory.png&quot; alt=&quot;Inventory Screen&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The Welcome screen appears, press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/Welcome.png&quot; alt=&quot;Welcome Screen&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Introduce &lt;em&gt;/opt/ocsg6&lt;/em&gt; in the Oracle Home field and press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/Location.png&quot; alt=&quot;Location Screen&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select &lt;em&gt;Custom Installation&lt;/em&gt; and press &lt;strong&gt;Next&lt;/strong&gt;. Check all the features and press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/AllFeatures.png&quot; alt=&quot;Custom Installation&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The Prerequisite Check should be OK. Press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Note the IP in the first field. Introduce the password for the domain user and for the Partner and API Management Portal user. It&apos;s &lt;em&gt;welcome1&lt;/em&gt; in my case but you can use something different. Let the default value in others fields and press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/Credentials.png&quot; alt=&quot;Credentials&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Introduce the IP in /etc/hosts with &lt;strong&gt;ocsg&lt;/strong&gt; as reference. If you ping &lt;strong&gt;ocsg&lt;/strong&gt;, you should receive a response from the IP you&apos;ve noted in the previous step.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let &lt;em&gt;Java DB&lt;/em&gt; selected and press &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/Javadb.png&quot; alt=&quot;JavaDB&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Review the Installation Summary and press &lt;strong&gt;Install&lt;/strong&gt;. It may take a while.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/IntallationEnd.png&quot; alt=&quot;Installation End&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Press &lt;strong&gt;Next&lt;/strong&gt; when available and &lt;strong&gt;Finish&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Start OCSG&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open a Terminal and execute:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;sh cd /opt/ocsg6/user_projects/domains/services-gatekeeper-domain ./startWebLogic.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When it asks for username and password, introduce &lt;em&gt;weblogic&lt;/em&gt; and &lt;em&gt;welcome1&lt;/em&gt;. After a while, a &lt;em&gt;The server started in RUNNING mode.&lt;/em&gt; message should appear.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open a Terminal (or a tab in the previous one) and execute:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;sh cd /opt/ocsg6/user_projects/domains/services-gatekeeper-domain/bin ./startGatekeeper.sh&lt;/code&gt; When it asks for username and password, introduce &lt;em&gt;weblogic&lt;/em&gt; and &lt;em&gt;welcome1&lt;/em&gt;. After a while, &lt;em&gt;The server started in RUNNING mode.&lt;/em&gt; message should appear.&lt;/p&gt;
&lt;h2&gt;Account configuration&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open Firefox and go to &lt;a href=&quot;http://ocsg:7001/console&quot;&gt;http://ocsg:7001/console&lt;/a&gt; , login as &lt;strong&gt;weblogic&lt;/strong&gt; with password &lt;strong&gt;welcome1&lt;/strong&gt;. In the Domain Structure (left), go to &lt;strong&gt;OCSG&lt;/strong&gt; -&amp;gt; &lt;strong&gt;Server 1&lt;/strong&gt;. In the Oracle Communications Services Gatekeeper box, click on &lt;strong&gt;Container Services&lt;/strong&gt; and &lt;strong&gt;PluginManager&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/ContainerServices.png&quot; alt=&quot;Container Services&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Click on &lt;strong&gt;Operations tab&lt;/strong&gt; and choose &lt;em&gt;createPluginInstance&lt;/em&gt; in the &lt;strong&gt;Select An Operation:&lt;/strong&gt; combo. Fill the fields with the following values and click on &lt;strong&gt;Invoke&lt;/strong&gt;. An &lt;em&gt;Operation invoked successfully&lt;/em&gt; message should be returned.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PluginServiceId&lt;/strong&gt;: &lt;em&gt;Plugin_px21_short_messaging_smpp&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PluginInstanceId&lt;/strong&gt;: &lt;em&gt;Plugin_px21_short_messaging_smpp_instance&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/CreatePluginInstance.png&quot; alt=&quot;Create Plugin Instance&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Choose &lt;em&gt;Add Route&lt;/em&gt; in the &lt;strong&gt;Select An Operation:&lt;/strong&gt; combo. Fill the fields with the following values and click on &lt;strong&gt;Invoke&lt;/strong&gt;. An &lt;em&gt;Operation invoked successfully&lt;/em&gt; message should be returned.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PluginInstanceId&lt;/strong&gt;: &lt;em&gt;Plugin_px21_short_messaging_smpp_instance&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AddressExpression&lt;/strong&gt;: &lt;em&gt;.&lt;/em&gt;*&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/addRoute.png&quot; alt=&quot;add Route&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Container Services -&amp;gt; Application Groups -&amp;gt; addServiceProviderGroup&lt;/strong&gt;. Fill the fields with the following values and click on &lt;strong&gt;Invoke&lt;/strong&gt;. An &lt;em&gt;Operation invoked successfully&lt;/em&gt; message should be returned.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ServiceProviderGroupIdentifier&lt;/strong&gt;: &lt;em&gt;default_sp_group&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Properties&lt;/strong&gt;: &lt;em&gt;.&lt;/em&gt;*&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/serviceProviderGroup.png&quot; alt=&quot;Service Provider Group&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Container Services -&amp;gt; ApplicationGroups -&amp;gt; addApplicationGroup&lt;/strong&gt;. Fill the fields with the following values and click on &lt;strong&gt;Invoke&lt;/strong&gt;. An &lt;em&gt;Operation invoked successfully&lt;/em&gt; message should be returned.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ApplicationGroupIdentifier&lt;/strong&gt;: &lt;em&gt;default_app_group&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/ApplicationgGroup.png&quot; alt=&quot;Application Group&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Container Services -&amp;gt; ApplicationAccounts -&amp;gt; addServiceProviderAccount&lt;/strong&gt;. Fill the fields with the following values and click on &lt;strong&gt;Invoke&lt;/strong&gt;. An &lt;em&gt;Operation invoked successfully&lt;/em&gt; message should be returned.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ServiceProviderIdentifier:&lt;/strong&gt;: &lt;em&gt;default_sp&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ServiceProviderGroupIdentifier&lt;/strong&gt;: &lt;em&gt;default_sp_group&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference&lt;/strong&gt;: &lt;em&gt;default&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/serviceProviderAccount.png&quot; alt=&quot;Service Provider Account&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Container Services -&amp;gt; ApplicationAccounts -&amp;gt; addApplicationAccount&lt;/strong&gt;. Fill the fields with the following values and click on &lt;strong&gt;Invoke&lt;/strong&gt;. An &lt;em&gt;Operation invoked successfully&lt;/em&gt; message should be returned.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ApplicationIdentifier:&lt;/strong&gt;: &lt;em&gt;default_app&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ServiceProviderIdentifier:&lt;/strong&gt;: &lt;em&gt;default_sp&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApplicationGroupIdentifier&lt;/strong&gt;: &lt;em&gt;default_sp_group&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference&lt;/strong&gt;: &lt;em&gt;default&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/ApplicationAccount.png&quot; alt=&quot;Application Account&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;strong&gt;Container Services -&amp;gt; ApplicationInstances -&amp;gt; addApplicationInstance&lt;/strong&gt;. Fill the fields with the following values and click on &lt;strong&gt;Invoke&lt;/strong&gt;. An &lt;em&gt;Operation invoked successfully&lt;/em&gt; message should be returned.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ApplicationInstanceName:&lt;/strong&gt; &lt;em&gt;domain_user&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Password:&lt;/strong&gt; &lt;em&gt;domain_user&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApplicationIdentifier:&lt;/strong&gt;: &lt;em&gt;default_app&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ServiceProviderIdentifier:&lt;/strong&gt;: &lt;em&gt;default_sp&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference&lt;/strong&gt;: &lt;em&gt;default&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible/ApplicationInstance.png&quot; alt=&quot;Application Instance&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This post continues in &lt;a href=&quot;/blog/2015/Services-Gatekeeper-6-installed-in-fifteen-minutes-is-it-possible-Part-2.html&quot;&gt;the second part post&lt;/a&gt;&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>TADHack 2015: Oracle environment ready for your hack</title>
      <link>https://www.galiglobal.com/blog/2015/TADHack-2015-Oracle-environment-ready-for-your-hack.html</link>
      <pubDate>Thu, 23 Apr 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/TADHack-2015-Oracle-environment-ready-for-your-hack.html</guid>
      <description>
      &lt;p&gt;I am very glad to be part of TADHack again. The last year it was a great experience but everything was new so, with my previous experience, and I am sure this year I am going to enjoy it even more.&lt;/p&gt;
&lt;p&gt;Furthermore, we continue &lt;a href=&quot;http://blog.tadhack.com/2015/04/13/oracle-developer-resources/&quot;&gt;collaborating with Oracle Comms&lt;/a&gt; providing the &lt;a href=&quot;http://tadhack.optaresolutions.com/&quot;&gt;Oracle Sandbox&lt;/a&gt;. It&apos;s challenging and fun at the same time. Someone may think this year is easier because it&apos;s the second time... No!. There are a lot of new things and, even most important, we&apos;ve deployed the last versions of all the Oracle Comms products:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/web-rtc-session-controller/overview/index.html&quot;&gt;Oracle Communications Converged Application Server 7.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/connected-digital-lifestyle/services-gatekeeper/overview/index.html&quot;&gt;Oracle Communications Services Gatekeeper 6.0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/web-rtc-session-controller/overview/index.html&quot;&gt;Oracle Communications WebRTC Session Controller 7.1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am specially excited with OCCAS, there are a lot of new features and I&apos;m looking forward to learn more and do something with it. It would be great to develop some hack and participate also as developer in the Hackathon.&lt;/p&gt;
&lt;p&gt;If you are a developer or you work with Oracle Comms and you want to check the last versions, don&apos;t miss the opportunity. Visit &lt;a href=&quot;http://tadhack.optaresolutions.com&quot;&gt;tadhack.optaresolutions.com&lt;/a&gt; or check the following webinar with &lt;a href=&quot;http://alanquayle.com/&quot;&gt;Alan Quayle&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/Doug_Tait&quot;&gt;Doug Tait&lt;/a&gt; and myself introducing the Oracle sandbox.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/LDjzDVQucoM&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Here you can find my slides, I am trying a more visual style so I recommend the webinar.&lt;/p&gt;
&lt;iframe src=&quot;https://www.slideshare.net/slideshow/embed_code/key/HMWqhusiViKKdK&quot; width=&quot;476&quot; height=&quot;400&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;I hope see you in &lt;a href=&quot;http://tadhack.com/2015/&quot;&gt;TADHack Lisbon&lt;/a&gt;!!&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Oracle's demos in the MWC2015 review</title>
      <link>https://www.galiglobal.com/blog/2015/Oracle-s-demos-in-the-MWC2015-review.html</link>
      <pubDate>Wed, 15 Apr 2015 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2015/Oracle-s-demos-in-the-MWC2015-review.html</guid>
      <description>
      &lt;p&gt;This March has been crazy. Starting with the Mobile World Congress and next week flying to Brazil for three weeks because of an Oracle Comms project... Impossible to find time to tweet, blog or whatever, and it&apos;s a pity because there a lot of news!&lt;/p&gt;
&lt;p&gt;Let me start from the beginning: the Mobile World Congress. I always like to assist to this event. Everybody is there, so it&apos;s very tired but also very productive. I&apos;ve participated in more than 20 meetings, some conferences, the amazing &lt;a href=&quot;http://www.meetup.com/WebRTC-Barcelona/&quot;&gt;WebRTC Meetup&lt;/a&gt; organized by our friends Quobis (don&apos;t miss the &lt;a href=&quot;https://www.youtube.com/watch?v=B-81k_pDU24&quot;&gt;Stefano Gioia presentation&lt;/a&gt;) and, this year for first time, I was able to find some time slot to see demos.&lt;/p&gt;
&lt;p&gt;When I&apos;ve arrived to the Oracle booth, I quickly noticed the key topic of this year: Network Function Virtualization (NFV). So, it&apos;s not strange most of the demos were related to this in some way. I&apos;ve started with a demo using the &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/diameter-signaling-router/index.html&quot;&gt;Diameter Signaling Router&lt;/a&gt;, a Tekelec product. The demo was mainly showing how they are able to add new nodes to increase the processing capacity dynamically. They defined it as NFV compliant and well.. I was a bit disappointed with this. For me, NFV is not to be able to add new nodes to a cluster system.. it&apos;s the capacity to increase the resources dynamically.... and always in the same way, a centralized way. And this should be the point. NFV shouldn&apos;t be virtualization, clustering or geographic-redundancy... they were invented some time ago. The other thing I didn&apos;t like: the solutions wasn&apos;t based in Coherence or even Weblogic... which it should be pointless when you are in an Oracle booth. Anyway, the product looks very interesting, robust and well-designed.. and the people in the booth were really professional and skilled with diameter.&lt;/p&gt;
&lt;p&gt;I jumped to the next demo and I was very pleased to see &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/connected-digital-lifestyle/services-gatekeeper/overview/index.html&quot;&gt;Services Gatekeeper&lt;/a&gt; integrated with the Oracle Tekelec PCRF... very interesting use case. I&apos;ve to try it but I don&apos;t know the Tekelec PCRF and it&apos;s not easy to find documentation about it (I mean, a simple how-to). There are good documentation in the OCSG side, &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e55395/ipl_pcrf.htm#SGIPL700&quot;&gt;Integrating Services Gatekeeper with a PCRF&lt;/a&gt;, but it lacks the PCRF steps.&lt;/p&gt;
&lt;p&gt;I continued with a huge demo involving &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/connected-digital-lifestyle/services-gatekeeper/overview/index.html&quot;&gt;Services Gatekeeper&lt;/a&gt;, &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/unified-communications/converged-application-server-edition/overview/index.html&quot;&gt;Converged Application Server&lt;/a&gt; and &lt;a href=&quot;http://www.oracle.com/us/products/applications/siebel/overview/index.html&quot;&gt;Siebel&lt;/a&gt;. The use case is very well designed: the subscriber can browse the Siebel front-end where he has a lot of information available and now, he has also an interface to watch movies (or whatever) in streaming.. something like Netflix but linked to the CSP account. The subscriber choose a movie to watch and he can choose between pay the total amount (using his billing account in the CSP) or save some money watching some advertisement sponsored by Service Providers/Third parties (very clever use of the OCSG PRM interface!). The demo is very visual and the &lt;a href=&quot;https://twitter.com/SteveNorthridge&quot;&gt;@SteveNorthridge&lt;/a&gt; explanations very clear to understand the use case and possibilities. I am sure we&apos;ll speak a lot about this demo.&lt;/p&gt;
&lt;p&gt;The next demo it&apos;s well know: the WebRTC Real state demo. I was in the event where it was showed the first time and I am never tired of it. Here it&apos;s the video, I am sure &lt;a href=&quot;https://twitter.com/Doug_Tait&quot;&gt;@Doug_Tait&lt;/a&gt; explains it better than me :-)&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/t2CZxyR3ftw&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;There was also a demo showing &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/unified-communications/overview/index.html&quot;&gt;Oracle Communications Unified Communications Suite&lt;/a&gt; enhanced with WebRTC capabilities. It makes sense combine &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/web-rtc-session-controller/overview/index.html&quot;&gt;WebRTC Session Controller&lt;/a&gt; with different Oracle products, and UCS is the logical first step. In the &lt;a href=&quot;https://wikis.oracle.com/display/CommSuite/Overview+of+Convergence+with+WebRTC&quot;&gt;Oracle wiki&lt;/a&gt; there a lot of good information about it.&lt;/p&gt;
&lt;p&gt;I spend some time in the Analytics demo. It&apos;s not my area but the use case are pretty interesting, specially related to churn detection and some of the systems I work with are a good source of information. Furthermore the company where I work, Optare Solutions, is doing &lt;a href=&quot;http://optaresolutions.com/innovacion/&quot;&gt;some interesting things&lt;/a&gt; related to this and the guy in the stand was really kind and skilled in the subject.&lt;/p&gt;
&lt;p&gt;After that I jumped to the most interesting demo for me: the whole NFV solution. I didn&apos;t have luck this time because the main analyst (someone I had previous meeting with) was busy all the time and I didn&apos;t have the opportunity to have all my questions answered. Anyway, I found out some interesting points: * The solutions look good, very complete and mature, using a mix of Oracle technologies including virtualization, Oracle OSS (an old friend of mine, UIM) and Oracle ACME products. Oracle has a huge portfolio so it makes sense to use them instead of reinvent the wheel. * It&apos;s very flexible and powerful but it has a cost: it&apos;s complex because it involves some big products. Very good for carriers but no so good for small companies. * Openstack as cloud computing platform software but it&apos;s not mandatory, you can choose Oracle VM Server, for example.&lt;/p&gt;
&lt;p&gt;And for me the most important point, Oracle is starting to include Network functions. And it&apos;s easy, because the Oracle technologies are based in Java / Weblogic and they have some interesting Network applications, as for example &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/unified-communications/converged-application-server-edition/overview/index.html&quot;&gt;Oracle Communications Converged Application Server (OCCAS)&lt;/a&gt; or the &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/application-session-controller/index.html&quot;&gt;Oracle Communications Application Session Controller&lt;/a&gt;. I expect very interesting news in the next months related to this and it&apos;s going to be big, because this is something only Oracle can provide so easily, so a good competitive advantage over their competitors in the NFV area. Also don&apos;t miss [the demo with Intel](Oracle Communications Advances Network Function Virtualization by Delivering Carrier-Grade Data Center Performance) announced some days ago.&lt;/p&gt;
&lt;p&gt;I ended the tour with a visit to Connected Vehicle demo. It&apos;s not related to any Oracle Comms product but I worked in a similar project some months ago and Oracle solutions are always interesting. The demo isn&apos;t very impressive but it&apos;s amazing how they are using Java to build it. I thought a lot on it and how to use it for other use cases. Here it&apos;s &lt;a href=&quot;http://www.oracle.com/us/solutions/internetofthings/java-iot-connected-vehicle-wp-2401533.pdf&quot;&gt;the whitepaper with all the information about the Connected Vehicle&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In short, MWC2015 was a great event and I am not going anymore to miss the opportunity to review a demo .&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Access OCSG EDR JMS Topic with Talend Open Studio</title>
      <link>https://www.galiglobal.com/blog/2015/Access-OCSG-EDR-JMS-Topic-with-Talend-Open-Studio.html</link>
      <pubDate>Fri, 13 Feb 2015 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2015/Access-OCSG-EDR-JMS-Topic-with-Talend-Open-Studio.html</guid>
      <description>
      &lt;p&gt;I&apos;ve been using &lt;a href=&quot;https://www.talendforge.org/tutorials/tutorial.php?idTuto=14&quot;&gt;Talend Open Studio&lt;/a&gt; for a long time. It&apos;s an impressive software to do automated tasks, it works well and the development is quite fast. Furthermore, the TtHW (Time to Hello World) is really short. As you can see, I like it.&lt;/p&gt;
&lt;p&gt;In this tutorial, I am going to show how to use it Talend Open Studio to access the JMS Topic where OCSG shows all the runtime information: the Event Data Records (EDRs). This is the main place for debugging so it&apos;s really important. The article is based in the offical documentation &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e50771/pds_edrlistener.htm#SGPDS627&quot;&gt;Creating EDR Listeners&lt;/a&gt; but adapted to TOS.&lt;/p&gt;
&lt;h2&gt;Pre-requisites&lt;/h2&gt;
&lt;p&gt;You will need an OCSG 6 or 5.1 running and also the &lt;a href=&quot;http://www.talend.com/download/talend-open-studio?qt-product_tos_download=3#qt-product_tos_download&quot;&gt;TOS Data Integration&lt;/a&gt; installed in your computer.&lt;/p&gt;
&lt;h2&gt;Talend Open Studio development&lt;/h2&gt;
&lt;p&gt;Drop a tJMSInput component in the canvas and double click over it.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Access-OCSG-EDR-JMS-Topic-with-Talend-Open-Studio/tJMSInput.png&quot; alt=&quot;tJMSInput component&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Configure all the fields as you can see in the following picture:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Access-OCSG-EDR-JMS-Topic-with-Talend-Open-Studio/tJMSInput_form.png&quot; alt=&quot;tJMSInput fields&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Some important notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You have to import the library &lt;em&gt;wlthint3client.jar&lt;/em&gt; before to use the component. You can find it in &lt;em&gt;&lt;OCSG Installation folder&gt;/wlserver/server/lib/wlthint3client.jar&lt;/em&gt;. To import it, there are several ways, for instance, the tLibraryLoad component.&lt;/li&gt;
&lt;li&gt;Change the &lt;strong&gt;Server URL&lt;/strong&gt; to your environment configuration. It must be a Node, not an Admin. In this case it&apos;s an standalone configuration with Admin and Node in the same Weblogic instance.&lt;/li&gt;
&lt;li&gt;Change the &lt;strong&gt;Message from&lt;/strong&gt; to your environment configuration. If you don&apos;t know it, go to the Console,in the Domain Structure, &lt;strong&gt;Services -&amp;gt; Messaging -&amp;gt; JMS Servers&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Weblogic configuration&lt;/h2&gt;
&lt;p&gt;There is a missing point, and it&apos;s the key. In the Weblogic console:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to the Domain Structure and Select &lt;strong&gt;Services -&amp;gt; Messaging -&amp;gt; JMS-Modules&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Click on &lt;strong&gt;WLNGJMSResource -&amp;gt; EdrTopic -&amp;gt; Advanced&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Find &lt;strong&gt;Create Destination Identifier&lt;/strong&gt; and introduce &lt;em&gt;com.bea.wlcp.wlng.edr.EdrTopic&lt;/em&gt; and Save.&lt;/li&gt;
&lt;li&gt;Reboot the Weblogic.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/Access-OCSG-EDR-JMS-Topic-with-Talend-Open-Studio/WeblogicJMSConfiguration.png&quot; alt=&quot;Weblogic JMS Configuration&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This step is mandatory because of the tJMSInput component but it can be avoided if you are accessing the JMS Topic in another way.&lt;/p&gt;
&lt;h2&gt;The end&lt;/h2&gt;
&lt;p&gt;That&apos;s all. Click on Run in the Talend Open Studio and you should be subscribed to the Topic. Send an SMS from the PTE and you should start to generate EDRs. The next step would be create the Java classes to access the EDR information and start to work with it.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Ramblings about OCCAS and the Oracle Communications roadmap</title>
      <link>https://www.galiglobal.com/blog/2015/Ramblings-about-OCCAS-and-the-Oracle-Communications-roadmap.html</link>
      <pubDate>Wed, 11 Feb 2015 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2015/Ramblings-about-OCCAS-and-the-Oracle-Communications-roadmap.html</guid>
      <description>
      &lt;p&gt;This is going to be a different type of post. I usually write about technical things but today I am going to try something different. Well, maybe not so different, I have more questions than answers, but at least, I will try to explain as I see the Oracle Comms portfolio and its evolution. Just for the record, I don&apos;t work inside Oracle, I don&apos;t have privileged information and if you do any business decision based in this article, you are a fool.&lt;/p&gt;
&lt;h2&gt;Context&lt;/h2&gt;
&lt;p&gt;In 2006, &lt;a href=&quot;http://www.oracle.com/us/corporate/acquisitions/metasolv/index.html&quot;&gt;Oracle acquired MetaSolv&lt;/a&gt;, recognized leader in service fulfillment operations support system (OSS) solutions for next-generation communications service providers. Two years later, &lt;a href=&quot;http://www.oracle.com/us/corporate/acquisitions/bea/index.html&quot;&gt;Bea Systems... and with it, Weblogic Server&lt;/a&gt;, the Application Server leader of the market. After that, Oracle has build a strong position in the OSS market, no only from a business perspective, also from a technical point of view. All the products are similar (from the CRM to the Inventory) and they share the same architectural principles. As consequence, CSPs enjoy some advantages. For example, after the first deployment, they have the knowledge and experience to continue deploying the rest of the suite.&lt;/p&gt;
&lt;p&gt;In February 2013, &lt;a href=&quot;http://www.oracle.com/us/corporate/press/1903221&quot;&gt;Oracle bought Acme Packet&lt;/a&gt;, the leading global provider of session border control technology. One month later &lt;a href=&quot;http://www.oracle.com/us/corporate/acquisitions/tekelec/index.html&quot;&gt;Oracle bought Tekelec&lt;/a&gt;, a leading provider of network signaling, policy control, and subscriber data management solutions for communications networks. All the analysts saw this as a big movement to the Network market. Me too.&lt;/p&gt;
&lt;h2&gt;Oracle Comms Converged Application Server&lt;/h2&gt;
&lt;p&gt;Most of people didn&apos;t realize Oracle had a previous portfolio of Networks Applications before the acquisition. Even if this suite is no so big as the OSS and BSS suites, it has importance and business share inside the firm... and something more important, a very intelligent roadmap based in OCCAS as network platform for everything. But.... what is OCCAS? The &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/unified-communications/converged-application-server-edition/overview/index.html&quot;&gt;Oracle Communications Converged Application Server&lt;/a&gt; is a Weblogic with Telecom Network capabilities (mainly SIP and Diameter) and oriented to real-time applications. As product, it&apos;s very small. It&apos;s not easy to find a CSP asking for it, because the business case is not so clear. OCCAS is more like a Framework, something you are going to use to develop other things. And, in fact, most of the SDP portfolio is based in OCCAS, for instance, OCSG and the Unified Communications suite.&lt;/p&gt;
&lt;p&gt;The Converged Application Server &lt;a href=&quot;https://docs.oracle.com/cd/E27702_01/doc.51/e27705/tpd_developing.htm#autoId1&quot;&gt;Service Creation Environment&lt;/a&gt; (SCE) consists of a faceted framework that supplements the &lt;a href=&quot;http://www.oracle.com/technetwork/developer-tools/eclipse/downloads/index.html&quot;&gt;Oracle Enterprise Pack for Eclipse&lt;/a&gt; (OEPE). The SCE provides tools and resources you can use to develop converged applications, including wizards, simulators, and templates. And also it provides the &lt;a href=&quot;https://docs.oracle.com/cd/E27702_01/doc.51/e27707/sip_sft_overview.htm&quot;&gt;Service Foundation Toolkit&lt;/a&gt; (SFT), a converged application Java development framework. It provides APIs that abstract the details of the communication protocol for the application, enabling to focus on the service value provided by converged SIP and HTTP applications. The idea is simple: if you are a developer with Java and Eclipse knowledge, you can start to develop Telecom applications without knowledge about Telecom protocols. And those applications will run in the leader platform: Weblogic. So they will be carrier-grade with all the performance, security and scalability requirements.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://docs.oracle.com/cd/E27702_01/doc.51/e27705/img/sce_overview.gif&quot; alt=&quot;The Converged Application Server Service Creation Environment&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Oracle Comms Roadmap&lt;/h2&gt;
&lt;p&gt;A roadmap with all the Network products based in OCCAS makes sense for several reasons. Some of them are: * &lt;strong&gt;Contrasted technologies&lt;/strong&gt;: Java, Weblogic, the Oracle Database, Linux, Eclipse and so on. You are not reinventing the wheel. All those technologies are familiar to the CSPs, they trust them. * &lt;strong&gt;Cloud and virtualization&lt;/strong&gt;: CSPs want to be ready for the near future. They know about the advantages of virtualization and cloud strategies. And OCCAS is the perfect choice for that. You can run it in several platforms, deploy it, scale it and so on. It&apos;s flexible and modern. * &lt;strong&gt;Learn one, use many&lt;/strong&gt;: you start deploying one application, and after that, you will have the knowledge and resources to deploy the rest of the suite (if you want). You will save a lot of time learning complex systems or technologies so you will be more flexible and faster delivering new products to the market. * &lt;strong&gt;Easy support&lt;/strong&gt;: the Operation team needs to know about basic technologies: no more, no less. As you need a DBA, you will need a Weblogic expert who can work with all the systems. In short, the daily support will be easier because the level of complexity is smaller. * &lt;strong&gt;Maintenance and upgrade&lt;/strong&gt;: all the products are going to do it in the same way and it&apos;s out-of-the-box in Weblogic. Converged Applications Server&apos;s upgrade feature ensures that no calls are dropped while during the upgrade of a production application. The upgrade process also enables you to revert or rollback the process of upgrading an application. If, for example, you determine that there is a problem with the newer version of the deployed application, you can undeploy the newer version and activate the older version. * &lt;strong&gt;High availability and geographic redundancy&lt;/strong&gt;: it&apos;s provided out-of-the-box, so you don&apos;t need worry about that. * &lt;strong&gt;The BSS/OSS suite&lt;/strong&gt;: it&apos;s based on the same technologies. Any CSP with some of those products installed has the experience and knowledge to start to work with OCCAS or any OCCAS-based product and the integration between BSS/OSS and Network would be easier.&lt;/p&gt;
&lt;p&gt;As we saw before in the OSS suite, this is a winner strategy. And it doesn&apos;t end here. After have everything running in the same platform, Oracle can start to work in the integration between the products, something like the &lt;a href=&quot;http://www.oracle.com/us/products/applications/application-integration-architecture/overview/index.html&quot;&gt;Oracle Application Integration Architecture (AIA)&lt;/a&gt; but oriented to the network. Any network vendor in the market can compete with something like that.&lt;/p&gt;
&lt;h2&gt;The future&lt;/h2&gt;
&lt;p&gt;The final question: is Oracle going to migrate the ACME and Tekelec products to the OCCAS platform?. We know the advantages but there are also problems. Migrate part of the portfolio to this platform requires a lot of resources and it&apos;s very time-consuming. And of course, not all the products are valid (specific hardware systems doesn&apos;t have sense in OCCAS) or they are not going to have enough Return of Investment. So, I don&apos;t have an answer for that. After two years, I didn&apos;t see movements in this direction but I also know the acquisitions take a lot of time and it&apos;s soon yet. Oracle did a great job combining OCCAS and &lt;a href=&quot;http://docs.oracle.com/cd/E50379_01/index.htm&quot;&gt;Application Session Controller&lt;/a&gt; (ASC) to launch the &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/web-rtc-session-controller/overview/index.html&quot;&gt;WebRTC Session Controller&lt;/a&gt; (WSC). That is for sure &lt;a href=&quot;https://blogs.oracle.com/COMMSINFODEV/entry/new_tech_new_challenges_the&quot;&gt;the path to follow&lt;/a&gt; but they are just two products running independently and integrated using a REST interface and we are speaking about have the ASC capabilities running on OCCAS.&lt;/p&gt;
&lt;p&gt;On the other hand, Oracle has announced recently the &lt;a href=&quot;http://www.oracle.com/us/corporate/press/2418407&quot;&gt;Oracle Communications Network Service Orchestration Solution&lt;/a&gt;. This is the mainly Oracle NFV bet but it doesn&apos;t look based in OCCAS or even Weblogic. And we know, Oracle can buy some specific NFV/SDN company, they don&apos;t need to develop their own solution... but with more acquisitions the path to have only one platform will be even more complicated.&lt;/p&gt;
&lt;p&gt;This year we probably will see a new version release of OCCAS. That will be the moment to know about the future of this excellent platform.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>OCSG 6.0v1 generally available: new features introduction</title>
      <link>https://www.galiglobal.com/blog/2015/OCSG-6-0v1-generally-available-new-features-introduction.html</link>
      <pubDate>Fri, 23 Jan 2015 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2015/OCSG-6-0v1-generally-available-new-features-introduction.html</guid>
      <description>
      &lt;p&gt;The new OCSG version is available and there are a lot of new interesting things, starting with a Documentation reorganization.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/OCSG-doc-v6.png&quot; alt=&quot;OCSG v6 documentation&quot; /&gt;&lt;/p&gt;
&lt;p&gt;This is the press note (source &lt;a href=&quot;https://community.oracle.com/docs/DOC-894950?sr=stream#comment-897214&quot;&gt;Oracle Community&lt;/a&gt;):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Oracle Communications is pleased to announce that as of Thursday, 22 January 2015, we ntroduced the most comprehensive API exposure platform in the industry with the release of Oracle Communications Services Gatekeeper 6.0 (OCSG 6.0).&lt;/p&gt;
&lt;p&gt;OCSG 6.0 introduces expansive API Management capabilities to manage the entire API lifecycle enabling enterprises and CSPs to accelerate internal development, engage with partners and monetize assets. OCSG 6.0 delivers this alongside industry leading SLA management, analytics and an extensive array of built-in communications services.&lt;/p&gt;
&lt;p&gt;As part of the OCSG 6.0 release, a new OCSG-based solution, called “Network Policy as a Service” (NPaaS), was launched by integrating the Oracle Communications Policy Management (OCPM) PCRF to provide out-of-the-box exposure of network policy for both telephony and cable networks. This allows CSPs and partners to align the data bandwidth with the digital service being delivered, ensuring a higher rate of customer satisfaction. OCSG 6.0’s API Management, simplified configuration and lightweight deployment features enable new  API exposure use cases for enterprise IT integration, including: * Contact center application enablement * API exposure for Communications Enabled Business Processes (CEBP) and Unified Communications (UC)&lt;/p&gt;
&lt;p&gt;** KEY FEATURES OF THE OCSG 6.0 RELEASE ** * API Management made powerful and simple * Web Service API generation in the Portal allows APIs to be built in minutes * API catalog and versioning * Onboard and manage partners * API Monitoring, analytics, metering and charging * Management and partner portals * Simplified configuration and deployment with installation in 15 minutes * Lightweight single tier deployment option * Integration with the Oracle Communications Policy Management (OCPM) PCRF to safely and securely expose network policy through the Parlay X and Restful QoS APIs * Enhanced Oauth integration simplifies integration with SSO and IDM * Enterprise Manager Cloud Control integration facilitates cloud-based deployments * Advanced API firewall provides protection against a multitude of security threats * Integration with OCCAS Service Controller provides a broad array of SS7 interface options&lt;/p&gt;
&lt;p&gt;Product releases are available for download from the &lt;a href=&quot;https://edelivery.oracle.com/&quot;&gt;Oracle Software Delivery Cloud&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;More documentation can be found via Services &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/index.htm&quot;&gt;Gatekeeper 6.0 Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It&apos;s soon yet to write a detailed analysis but I would like to highlight some takeaways. This is not the typical release.. in fact, there isn&apos;t an official  announcement as we&apos;ve seen previously. There are a lot of small improvements to help operators and system integrators to work with OCSG which it&apos;s great. Some of them:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;** &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e54151/toc.htm&quot;&gt;New Default Single-system Installation Option and Getting Started Guide&lt;/a&gt;:** everything in a single package (database included), it&apos;s going to save us a lot of time and PoCs will be easier. Great point.&lt;/li&gt;
&lt;li&gt;** &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/index.htm&quot;&gt;Documentation Improvements&lt;/a&gt;:** I&apos;ve to check them yet but the new structure looks better and, for sure, some sections in the 5.1 documentation could be improved/corrected.&lt;/li&gt;
&lt;li&gt;** &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e55395/ipl_pcrf.htm#SGIPL700&quot;&gt;PCRF Integration Example&lt;/a&gt;:** This is something I really appreciate because I was working on that and it&apos;s really hard because of the lack of information and references to the Tekelec product. I will do it very soon but after a first look, it lacks a bit more of detail in the Tekelec PCRF setup.&lt;/li&gt;
&lt;li&gt;** &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e50764/prm_intro.htm#SGPRM106&quot;&gt;Extending the Portal User Interfaces and Portal Developer&apos;s Guide&lt;/a&gt;: ** I know there are a lot of improvements in this part. An easier installation and customization, for sure, one of the points everybody asked with the previous version.&lt;/li&gt;
&lt;li&gt;** &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e54898/toc.htm&quot;&gt;New API Management Features&lt;/a&gt;: ** OCSG competes some times (but not always) with more general products as API gateways. Improvements in this part are warmly welcomed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I miss some things as more Geographic redundancy improvements and more debugging options but it&apos;s soon yet to know if they&apos;re or not in this release. Anyway, there are more interesting improvements, consult the &lt;a href=&quot;http://docs.oracle.com/cd/E50778_01/doc.60/e50775/toc.htm&quot;&gt;Release Note&lt;/a&gt; for detailed information.&lt;/p&gt;
&lt;p&gt;I will try to write some specific articles showing the new features. Just &lt;a href=&quot;http://www.serviceandnetworkevolution.com/&quot;&gt;subscribe to the blog&lt;/a&gt; to keep yourself informed.&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Accessing Weblogic Runtime Information with WLST</title>
      <link>https://www.galiglobal.com/blog/2015/Accessing-Weblogic-Runtime-Information-with-WLST.html</link>
      <pubDate>Mon, 19 Jan 2015 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2015/Accessing-Weblogic-Runtime-Information-with-WLST.html</guid>
      <description>
      &lt;p&gt;Deal with java.lang.OutOfMemoryError: PermGen space errors is always tricky. Most of the times it&apos;s something related to the chosen JVM, probably not supported for the hosting OS (for example, using a 32bits JVM in a 64bits OS is a typical issue).&lt;/p&gt;
&lt;p&gt;Here I provide two interesting ways to check the JVM configuration:&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/antonmry/efe307a587388c3ecdfb.js&quot;&gt;&lt;/script&gt;
&lt;p&gt;For example, perhaps we could want to increase the PermSize, so we edit the  &amp;lt;Domain dir &amp;gt;/ &amp;lt;Server Name &amp;gt;/bin/setDomainEnv.sh to add something like this in the beginning:&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h1&gt;USER_MEM_ARGS   - The variable to override the standard memory arguments&lt;/h1&gt;
&lt;h1&gt;passed to java.&lt;/h1&gt;
&lt;p&gt;USER_MEM_ARGS=&amp;quot;-Xms1024m -Xmx1024m -XX:CompileThreshold=8000 -XX:PermSize=256m&amp;quot; export USER_MEM_ARGS ``` Now it&apos;s time to reboot the weblogic and check everything again using the same commands I showed previously.&lt;/p&gt;
&lt;p&gt;More info: - &lt;a href=&quot;http://docs.oracle.com/cd/E13222_01/wls/docs100/config_scripting/using_WLST.html#wp1093952&quot;&gt;Invoking WLST&lt;/a&gt; - &lt;a href=&quot;http://docs.oracle.com/cd/E13222_01/wls/docs100/config_scripting/monitoring.html&quot;&gt;Getting Runtime Information&lt;/a&gt; - &lt;a href=&quot;https://blogs.oracle.com/practicalbpm/entry/wlst_scripting_to_get_weblogic&quot;&gt;WLST Scripting Introduction&lt;/a&gt;&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Oracle Pre-conference TADSummit Workshop 2014</title>
      <link>https://www.galiglobal.com/blog/2014/Oracle-Preworkshop-TADSummit-2014.html</link>
      <pubDate>Mon, 17 Nov 2014 00:00:00 +0100</pubDate>
      <guid isPermaLink="false">blog/2014/Oracle-Preworkshop-TADSummit-2014.html</guid>
      <description>
      &lt;p&gt;I was invited recently to participate in the Pre-conference Oracle WebRTC Workshop of the &lt;a href=&quot;http://tadsummit.com/2014/&quot;&gt;TADSummit 2014&lt;/a&gt; (Istanbul). I should speak about the implementation and architecture details of a WebRTC deployment in a Communication Service Provider. It was a real challenge, I had a lot of work in the previous weeks and I know about the excellent quality of the other speakers: &lt;a href=&quot;https://twitter.com/Doug_Tait&quot;&gt;Doug&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/EPCarrera&quot;&gt;Elias&lt;/a&gt; from Quobis or Stephano Gioia (who made a highly recommended presentation about &lt;a href=&quot;http://www.slideshare.net/gioste/webrtc-workshop-what-i&quot;&gt;What is (and isn&apos;t WebRTC)&lt;/a&gt; ).&lt;/p&gt;
&lt;p&gt;Even without time and being a technical guy, I&apos;ve tried to do something different, speaking about our experience in the TADHack 2014 (where we&apos;ve deployed and supported the Oracle platform) and a combination of some previous experiences from the deployment in some LATAM operators. Here you can see the slides:&lt;/p&gt;
&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/41656265&quot; width=&quot;425&quot; height=&quot;355&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&quot; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&quot;margin-bottom:5px&quot;&gt; &lt;strong&gt; &lt;a href=&quot;//www.slideshare.net/antonry/webrtc-preconference-oracle-workshop-v3&quot; title=&quot;Oracle - WebRTC Pre-conference TADSummit Workshop&quot; target=&quot;_blank&quot;&gt;Oracle - WebRTC Pre-conference TADSummit Workshop&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a href=&quot;//www.slideshare.net/antonry&quot; target=&quot;_blank&quot;&gt;antonry&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;
&lt;p&gt;And also a photo from Optare (Thanks!):&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p&gt;SDPs team at &lt;a href=&quot;https://twitter.com/TADSummit&quot;&gt;@TADSummit&lt;/a&gt; present our experience with &lt;a href=&quot;https://twitter.com/OracleComms&quot;&gt;@OracleComms&lt;/a&gt; SDPs.Ask &lt;a href=&quot;https://twitter.com/antonmry&quot;&gt;@antonmry&lt;/a&gt; &lt;a href=&quot;https://twitter.com/NachoGarmilla&quot;&gt;@NachoGarmilla&lt;/a&gt; or &lt;a href=&quot;https://twitter.com/ulsni&quot;&gt;@ulsni&lt;/a&gt; for info &lt;a href=&quot;http://t.co/IO7ASFxJgb&quot;&gt;pic.twitter.com/IO7ASFxJgb&lt;/a&gt;&lt;/p&gt;&amp;mdash; Optare Solutions (@optaresolutions) &lt;a href=&quot;https://twitter.com/optaresolutions/status/532143459977920512&quot;&gt;November 11, 2014&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;I really enjoyed the Pre-conference workshop. It was very constructive and some of the assistants were very interested in WebRTC and the business model behind it. In general, TADSummit was an excellent event, three days full of meetings and very interesting conversations about WebRTC and Telecom APIs.&lt;/p&gt;
&lt;p&gt;There is something I&apos;ve particularly enjoyed this time: Istanbul. Amazing city.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p&gt;Great views of Asia &amp;amp; Europe from rooftop &lt;a href=&quot;https://twitter.com/360istanbul&quot;&gt;@360istanbul&lt;/a&gt; cc &lt;a href=&quot;https://twitter.com/optaresolutions&quot;&gt;@optaresolutions&lt;/a&gt; &lt;a href=&quot;https://twitter.com/Quobis&quot;&gt;@Quobis&lt;/a&gt; &lt;a href=&quot;http://t.co/agzylsMiCR&quot;&gt;pic.twitter.com/agzylsMiCR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Elias Perez Carrera (@EPCarrera) &lt;a href=&quot;https://twitter.com/EPCarrera/status/532657059213631488&quot;&gt;November 12, 2014&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

	  </description>
    </item>
    
    <item>
      <title>WebRTC as key part of Service Exposure</title>
      <link>https://www.galiglobal.com/blog/2014/WebRTC-as-key-part-of-Service-Exposure.html</link>
      <pubDate>Wed, 1 Oct 2014 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2014/WebRTC-as-key-part-of-Service-Exposure.html</guid>
      <description>
      &lt;p&gt;Some weeks ago, Oracle has proposed us to write an article about WebRTC to be published in its blog: http://blog.webrtc-solutions.com. I was in charge of the main edition, with some colleges helping in the revision (thanks Sandra, Eva and Nacho!).  It was a good time to review why WebRTC is so important to us. There are a lot of companies involved today with WebRTC, different sectors, different sizes and types as you can see in the &lt;a href=&quot;http://www.cio2cmo.com/webrtc-landscape-infographic-june-2014/&quot;&gt;The WebRTC Landscape Infographic&lt;/a&gt; from Brad Bush.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.cio2cmo.com/wp-content/uploads/2014/06/WebRTC-Landscape-Infographic-2014-06.png&quot; alt=&quot;The WebRTC Landscape Infographic – June 2014&quot; /&gt;&lt;/p&gt;
&lt;p&gt;WebRTC is so exciting for us because very specific reasons... so  I&apos;ve developed our motivations in the article: as expert in telecom service exposure, WebRTC is the perfect choice to expose one of the main telecom assets: voice, and with less importance yet, video. In fact, I see WebRTC as a key part of the Service Delivery Platforms of the near future.&lt;/p&gt;
&lt;p&gt;The article: &lt;a href=&quot;http://blog.webrtc-solutions.com/webrtc-as-key-part-of-service-exposure/&quot;&gt;WebRTC as key part of Service Exposure&lt;/a&gt;&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Introduction to OCSG SDK</title>
      <link>https://www.galiglobal.com/blog/2014/Introduction-to-OCSG-SDK.html</link>
      <pubDate>Mon, 26 May 2014 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2014/Introduction-to-OCSG-SDK.html</guid>
      <description>
      &lt;p&gt;As part of the activities we did for the &lt;a href=&quot;http://tadhack.com/2014/&quot;&gt;TADHack 2014&lt;/a&gt;, I&apos;ve recorded &lt;a href=&quot;https://www.youtube.com/watch?v=pvVYH-tpEw8&quot;&gt;this short tutorial&lt;/a&gt; about the Oracle Communications Services Gatekeeper SDK:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/pvVYH-tpEw8&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;This is a very interesting tool for developers, a lot of people asked us for it and Oracle allow us to distribute it between the TADHack participants... It can made a big different for a CSP trying to engage developers.&lt;/p&gt;
&lt;p&gt;More information is available in the &lt;a href=&quot;http://docs.oracle.com/cd/E36135_01/doc.51/e37529/toc.htm&quot;&gt;Oracle® Communications Services Gatekeeper SDK User&apos;s Guide Release 5.1&lt;/a&gt;&lt;/p&gt;

	  </description>
    </item>
    
    <item>
      <title>Oracle TADHack Webinar</title>
      <link>https://www.galiglobal.com/blog/2014/Oracle-TADHack-Webinar.html</link>
      <pubDate>Thu, 15 May 2014 00:00:00 +0200</pubDate>
      <guid isPermaLink="false">blog/2014/Oracle-TADHack-Webinar.html</guid>
      <description>
      &lt;p&gt;In May 2014, Oracle propose us to deploy and manage its &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/service-network-evolution/index.html&quot;&gt;SANE solution&lt;/a&gt; for the &lt;a href=&quot;http://tadhack.com/2014/&quot;&gt;TADHack event&lt;/a&gt; and support the developers community. With only a few weeks, it was a big challenge. I&apos;ve participated as technical responsible and it was a great experience because it was a very different type of project: any operator was involved so we were free to choose the platform. Also the requirements were very different: the main goal was engage the developers.&lt;/p&gt;
&lt;p&gt;This is the list of activities we did: 1. Create &lt;a href=&quot;http://tadhack.optaresolutions.com/&quot;&gt;a website&lt;/a&gt; with all the information needed by the developers. 2. Create a &lt;a href=&quot;https://github.com/OTADHack&quot;&gt;Github community&lt;/a&gt; to provide source code samples, a ticketing system and so on. 3. We&apos;ve deployed &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/connected-digital-lifestyle/services-gatekeeper/overview/index.html&quot;&gt;Oracle Communications Services Gatekeeper&lt;/a&gt; and &lt;a href=&quot;http://www.oracle.com/us/products/applications/communications/web-rtc-session-controller/overview/index.html&quot;&gt;Oracle Communications WebRTC Session Controller&lt;/a&gt; in Amazon Web Services to give access to the developers. * We run some webinars, as for example this one with &lt;a href=&quot;http://www.alanquayle.com/&quot;&gt;Alan Quayle&lt;/a&gt;, Oracle Comms and &lt;a href=&quot;http://www.alerant.com/&quot;&gt;Alerant&lt;/a&gt;:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/0NXr68zvGrA&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;It was a great experience and I hope to repeat the next year!.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p&gt;Optare Solutions consultant &lt;a href=&quot;https://twitter.com/antonmry&quot;&gt;@antonmry&lt;/a&gt; explains how to setup &lt;a href=&quot;https://twitter.com/OracleComms&quot;&gt;@OracleComms&lt;/a&gt; environments for &lt;a href=&quot;https://twitter.com/hashtag/TelcoAPI?src=hash&quot;&gt;#TelcoAPI&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/hashtag/webrtc?src=hash&quot;&gt;#webrtc&lt;/a&gt; &lt;a href=&quot;http://t.co/rDtmlxitxB&quot;&gt;pic.twitter.com/rDtmlxitxB&lt;/a&gt;&lt;/p&gt;&amp;mdash; Optare Solutions (@optaresolutions) &lt;a href=&quot;https://twitter.com/optaresolutions/status/474938349778903040&quot;&gt;June 6, 2014&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;More info can be found in the &lt;a href=&quot;http://blog.tadhack.com/2014/05/05/oracle-webinar/&quot;&gt;TADHack blog&lt;/a&gt;.&lt;/p&gt;

	  </description>
    </item>
    

  </channel> 
</rss>
