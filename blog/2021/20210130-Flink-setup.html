<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Flink setup for development (and some IntelliJ Idea cool tricks)</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="antonmry">
    <meta name="keywords" content="">
    <meta name="generator" content="generated-from-markdown">

    <link href="/css/bootstrap.min.css" rel="stylesheet">
    <link href="/css/asciidoctor.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link href="/css/prettify.css" rel="stylesheet">
  </head>
  <body>
    <div id="wrap">
      <div id="navbar-container"></div>
      <div class="container">
        <div id="content">
        <h1 id="flink-setup-for-development-and-some-intellij-idea-cool-tricks">Flink setup for development (and some IntelliJ Idea cool tricks)</h1>
        <p><em>30 January 2021</em></p>
        <h2 id="introduction">Introduction</h2>
        <p><a href="https://flink.apache.org/">Apache Flink</a> is an open-source, unified
        stream-processing and batch-processing framework. As any of those framework,
        start to work with it can be a challenge. Even if there is a good
        <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/local_installation.html">Getting Started</a>
        or a great (and free)
        <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/">Hands-on Training</a>,
        there are always questions about how to start, how to debug problems or how to
        launch the project in your IDE.</p>
        <p>In this article, I summarize some of the notes I've been writing since I started
        with Flink. If Flink is something new for you, it's an easy guide to follow. If
        you are already an experienced Flink developer, there are some tricks you may
        find useful: access to JMX metrics, profiling, etc.</p>
        <p>The source code is available in this <a href="https://github.com/antonmry/flink-playground">GitHub repository</a>.</p>
        <h2 id="install-flink">Install Flink</h2>
        <p>The first step is to install Flink. This is straightforward, just go to the
        Flink download page and download it:</p>
        <pre class="codehilite"><code class="language-sh">wget https://archive.apache.org/dist/flink/flink-1.12.0/flink-1.12.0-bin-scala_2.12.tgz
        tar -zxvf flink-1.12.0-bin-scala_2.12.tgz
        </code></pre>

        <p>Note: it's a good idea to create a variable $FLINK_HOME pointing to the Flink
        folder.</p>
        <p>Start the cluster:</p>
        <pre class="codehilite"><code class="language-sh">$FLINK_HOME/bin/start-cluster.sh
        </code></pre>

        <p>You can access the <a href="http://localhost:8081/">Flink Web Dashboard</a> in your browser.</p>
        <p>We aren't going to need it initially so it's better to stop it:</p>
        <pre class="codehilite"><code class="language-sh">$FLINK_HOME/bin/stop-cluster.sh
        </code></pre>

        <h2 id="bootstrap-a-flink-job">Bootstrap a Flink job</h2>
        <p>To bootstrap the project, just execute the following Maven command:</p>
        <pre class="codehilite"><code class="language-sh">mvn archetype:generate                               \
            -DarchetypeGroupId=org.apache.flink \
            -DarchetypeArtifactId=flink-quickstart-java \
            -DarchetypeVersion=1.12.0 \
            -DgroupId=galiglobal \
            -DartifactId=flink-playground \
            -Dversion=0.1 \
            -Dpackage=galiglobal.flink \
            -DinteractiveMode=false

        cd flink-playground
        </code></pre>

        <p>The structure of the project is quite simple:</p>
        <pre class="codehilite"><code class="language-text">.
        ├── pom.xml
        └── src
            └── main
                ├── java
                │   └── galiglobal
                │       └── flink
                │           ├── BatchJob.java
                │           └── StreamingJob.java
                └── resources
                    └── log4j2.properties
        </code></pre>

        <p>We are going to focus only on <code>StreamingJob.java</code>.</p>
        <h2 id="import-and-run-the-job-in-intellij-idea">Import and run the job in IntelliJ IDEA</h2>
        <p>We are going only to cover my favourite Java IDE: IntelliJ IDEA. Other IDEs
        should work similarly. First of all, import in the IDE as a maven project. You
        can do it easily from the command-line.</p>
        <pre class="codehilite"><code class="language-sh">idea pom.xml
        </code></pre>

        <p>You can go to <code>StreamingJob.java</code> and execute it as a normal Java application
        using the Shift+F10 shortcut on Linux/Windows. An error like this should appear
        in the output:</p>
        <blockquote>
        <p>Exception in thread "main" java.lang.NoClassDefFoundError: org/apache/flink/streaming/api/environment/StreamExecutionEnvironment at galiglobal.flink.StreamingJob.main(StreamingJob.java:39) Caused by: java.lang.ClassNotFoundException: org.apache.flink.streaming.api.environment.StreamExecutionEnvironment at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ... 1 more</p>
        </blockquote>
        <p>This is a particular problem of Flink running in the IDE: some dependencies are
        missing. To solve it, go to <code>Run</code> -&gt; <code>Edit Configuration</code> -&gt; <code>Modify options</code> -&gt;
        <code>Use classpath of module</code> and in the new field, mark
        <code>Include dependencies with "Provided" scope</code>.</p>
        <p><img alt="Run configuration for Flink" src="flink-idea-run-configuration.png" title="Run configuration for Flink"></p>
        <p>Re-run the job and a new error appears:</p>
        <blockquote>
        <p>Exception in thread "main" java.lang.IllegalStateException: No operators defined in streaming topology. Cannot execute. at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getStreamGraphGenerator(StreamExecutionEnvironment.java:2000) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getStreamGraph(StreamExecutionEnvironment.java:1991) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getStreamGraph(StreamExecutionEnvironment.java:1976) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1822) at galiglobal.flink.StreamingJob.main(StreamingJob.java:62)</p>
        </blockquote>
        <p>It's time to create our Flink job.</p>
        <h2 id="develop-our-first-flink-job">Develop our first Flink job</h2>
        <p>Let's add a new Java class to our project called <code>RandomLongSource</code>:</p>
        <pre class="codehilite"><code class="language-java">public class RandomLongSource extends RichParallelSourceFunction&lt;Long&gt; {

            private volatile boolean cancelled = false;
            private Random random;

            @Override
            public void open(Configuration parameters) throws Exception {
                super.open(parameters);
                random = new Random();
            }

            @Override
            public void run(SourceContext&lt;Long&gt; ctx) throws Exception {
                while (!cancelled) {
                    Long nextLong = random.nextLong();
                    synchronized (ctx.getCheckpointLock()) {
                        ctx.collect(nextLong);
                    }
                }
            }

            @Override
            public void cancel() {
                cancelled = true;
            }
        }
        </code></pre>

        <p>This class is just generating an infinite series of long numbers to feed our
        job.</p>
        <p>Let's modify now <code>StreamingJob.java</code> to process it and print the result:</p>
        <pre class="codehilite"><code class="language-java">public class StreamingJob {
            private SourceFunction&lt;Long&gt; source;
            private SinkFunction&lt;Long&gt; sink;

            public StreamingJob(SourceFunction&lt;Long&gt; source, SinkFunction&lt;Long&gt; sink) {
                this.source = source;
                this.sink = sink;
            }

            public void execute() throws Exception {
                StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

                DataStream&lt;Long&gt; LongStream =
                    env.addSource(source)
                        .returns(TypeInformation.of(Long.class));

                LongStream
                    .map(new IncrementMapFunction())
                    .addSink(sink);

                env.execute();
            }

            public static void main(String[] args) throws Exception {
                StreamingJob job = new StreamingJob(new RandomLongSource(), new PrintSinkFunction&lt;&gt;());
                job.execute();
            }

            public class IncrementMapFunction implements MapFunction&lt;Long, Long&gt; {

                @Override
                public Long map(Long record) throws Exception {
                    return record + 1;
                }
            }
        }
        </code></pre>

        <p>Note: this class is from the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/learn-flink/">Hands-on Training</a>.</p>
        <p>If you execute it, you will see an infinite list of long numbers:</p>
        <blockquote>
        <p>...<br />
        3&gt; 3869376031196493001<br />
        12&gt; 4265560998598976840<br />
        12&gt; -7434045225389162179<br />
        1&gt; 3964290136030554255<br />
        1&gt; 8881056576399978883<br />
        ...</p>
        </blockquote>
        <p>Note: The 3&gt;, 12&gt;, 1&gt; indicate which sub-task (i.e., thread) produced the
        output.</p>
        <p>This is one of the most surprising things for Flink beginners: you don't need a
        cluster to develop a Flink job, you can easily do it locally from your IDE and
        it works quite well.</p>
        <p>There are some minor differences. For example, to access the
        <a href="http://localhost:8081/">Flink Web Dashboard</a> you will need to add the following
        dependency to maven:</p>
        <pre class="codehilite"><code class="language-xml">&lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-runtime-web_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        </code></pre>

        <p>And modify the <code>env</code> variable with the following code:</p>
        <pre class="codehilite"><code class="language-java">Configuration conf = new Configuration();
        StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);
        </code></pre>

        <p>Note: credit goes to this <a href="https://stackoverflow.com/questions/46988499/flink-webui-when-running-from-ide">StackOverflow answer</a>.</p>
        <p>Re-run the job and you should be able to access the
        <a href="http://localhost:8081/">Flink Web Dashboard</a> and see your job running:</p>
        <p><img alt="Flink Dashboard in local mode" src="flink-dashboard.png" title="Flink Dashboard in local mode"></p>
        <h2 id="debug-with-breakpoints">Debug with breakpoints</h2>
        <p>One of the nice things of run Flink jobs in your IDE is to able to debug your
        Flink job
        <a href="https://www.jetbrains.com/help/idea/using-breakpoints.html">using breakpoints</a>
        as usual.</p>
        <p><img alt="Flink breakpoints" src="flink-breakpoint.png" title="Flink breakpoints"></p>
        <h2 id="profiling">Profiling</h2>
        <p>Other nice thing you may use with IntelliJ is profiling to research and improve
        the performance of your jobs. See
        <a href="https://blog.jetbrains.com/idea/2020/03/profiling-tools-and-intellij-idea-ultimate/">Profiling Tools and IntelliJ IDEA Ultimate</a>
        for more info. It works well with this setup:</p>
        <p><img alt="Flink with IDEA profiler" src="flink-profiler.png" title="Flink with IDEA profiler"></p>
        <p>You can also use VisualVM and launch it from IntelliJ with the
        <a href="https://github.com/krasa/VisualVMLauncher/">VisualVMLauncher plugin</a>:</p>
        <p><img alt="Flink with VisualVM" src="flink-visualvm.png" title="Flink with VisualVM"></p>
        <h2 id="metrics">Metrics</h2>
        <p>Flink generates metrics exposed through different interfaces including JMX. See
        <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/ops/metrics.html#metrics">Flink metrics</a>
        for more info.</p>
        <p>To activate it, add the following dependency to <code>pom.xml</code>:</p>
        <pre class="codehilite"><code class="language-xml">&lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-metrics-jmx_2.11&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        </code></pre>

        <p>And change the <code>env</code> variable to expose metrics in the JMX interface:</p>
        <pre class="codehilite"><code class="language-java">Properties props = new Properties();
        props.put(&quot;metrics.reporter.jmx.factory.class&quot;, &quot;org.apache.flink.metrics.jmx.JMXReporterFactory&quot;);
        Configuration conf = ConfigurationUtils.createConfiguration(props);
        StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);
        </code></pre>

        <p>Run the job as usual and open it in VisualVM. You need to install the
        <a href="https://visualvm.github.io/plugins.html">VisualVM MBeans Browser</a>. Metrics
        should be available in the MBeans tab:</p>
        <p><img alt="Flink metrics with VisualVM" src="flink-metrics.png" title="Flink metrics with VisualVM"></p>
        <h2 id="logging">Logging</h2>
        <p>Let's add some proper logging to our job. First of all, add the following field
        to <code>StreamingJob.java</code>:</p>
        <pre class="codehilite"><code class="language-java">private static final Logger LOG = LoggerFactory.getLogger(StreamingJob.class);
        </code></pre>

        <p>Let's delete the longStream variable and create a new one with some log
        messages:</p>
        <pre class="codehilite"><code class="language-java">LOG.debug(&quot;Start Flink example job&quot;);

        DataStreamSink&lt;Long&gt; logTestStream = env.fromElements(0L, 1L, 2L)
            .map(new IncrementMapFunction())
            .addSink(sink);

        LOG.debug(&quot;Stop Flink example job&quot;);
        </code></pre>

        <p>Modify <code>src/main/resources/log4j2.properties</code> to use the DEBUG log level:</p>
        <pre class="codehilite"><code class="language-text">rootLogger.level = DEBUG
        </code></pre>

        <p>Re-run the job and you should see the new log traces:</p>
        <p><img alt="Flink log messages" src="flink-logtraces.png" title="Flink log messages"></p>
        <p>When running the job locally, the log level is quite verbose and it may be hard
        to find your messages between the Flink messages. Let's configure that. Edit
        <code>src/main/resources/log4j2.properties</code> again to add the following lines:</p>
        <pre class="codehilite"><code class="language-text">logger.flink.name = org.apache.flink
        logger.flink.level = warn
        </code></pre>

        <p>Re-run the job and you should only see the proper logs messages.</p>
        <h2 id="tests">Tests</h2>
        <p>One of the most important things when creating jobs is to have proper tests you
        can run from your IDE. It will make you go faster because you can make changes,
        run the test and be sure everything is working as it was before the change. That
        level of confidence in your changes worths the cost of writing the test from the
        very beginning.</p>
        <p>Add the following dependency to your <code>pom.xml</code>:</p>
        <pre class="codehilite"><code class="language-xml">&lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-test-utils-junit&lt;/artifactId&gt;
            &lt;version&gt;${flink.version}&lt;/version&gt;
        &lt;/dependency&gt;
        </code></pre>

        <p>Move the inner class <code>IncrementMapFunction</code> to their own file:</p>
        <p><img alt="Refactor Map function" src="flink-refactor.png" title="Refactor Map function"></p>
        <p>Now let's add a unit test to <code>src/test/java</code> which tests this function:</p>
        <pre class="codehilite"><code class="language-java">public class StreamingJobTest {

            @Test
            public void testMap() throws Exception {
                IncrementMapFunction statelessMap = new IncrementMapFunction();
                Long out = statelessMap.map(1L);
                Assert.assertEquals(2L, out.longValue());
            }
        }
        </code></pre>

        <p>Run the test from the IDE and see the result:</p>
        <p><img alt="Flink Unit Test" src="flink-unittest.png" title="Flink Unit test"></p>
        <p>For more information, see
        <a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html">Testing Flink Jobs</a>
        in the official documentation. It's particularly interesting how to
        <a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html#testing-flink-jobs">test complete jobs</a>.
        You can find also good examples in the
        <a href="https://github.com/apache/flink-training/blob/master/ride-cleansing/src/test/java/org/apache/flink/training/exercises/ridecleansing/RideCleansingTest.java">official Flink training tests</a>.</p>
        <h2 id="run-in-the-local-cluster-with-proper-logging">Run in the local cluster with proper logging</h2>
        <p>Once we are done with our job, we can deploy it in a local cluster. The first
        step is to enable the log level Debug for the local cluster. Edit
        <code>$FLINK_HOME/conf/log4j-cli.properties</code> and change root level to debug:</p>
        <blockquote>
        <p>rootLogger.level = DEBUG</p>
        </blockquote>
        <p>Start the cluster again:</p>
        <pre class="codehilite"><code class="language-sh">$FLINK_HOME/bin/start-cluster.sh
        </code></pre>

        <p>We need to modify our source code to use a remote execution environment so you
        should replace the <code>env</code> variable again:</p>
        <pre class="codehilite"><code class="language-java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        </code></pre>

        <p>Compile our job:</p>
        <pre class="codehilite"><code class="language-sh">mvn clean package -Pbuild-jar
        </code></pre>

        <p>Run the job in the local cluster:</p>
        <pre class="codehilite"><code class="language-sh">$FLINK_HOME/bin/flink run target/flink-playground-0.1.jar
        </code></pre>

        <p>It should obtain an output similar to:</p>
        <blockquote>
        <p>Job has been submitted with JobID bbea3ed5f5082a7267f85d92807b19dc<br />
        Program execution finished<br />
        Job with JobID bbea3ed5f5082a7267f85d92807b19dc has finished.<br />
        Job Runtime: 827 ms</p>
        </blockquote>
        <p>If you check the logs, you should see your traces:</p>
        <pre class="codehilite"><code class="language-sh">grep -R &quot;example job&quot; $FLINK_HOME/log/
        </code></pre>

        <h2 id="summary-and-next-steps">Summary and next steps</h2>
        <p>In this article, we have covered the basics and some typical gotchas to work
        with Apache Flink in local environments. It's really important to invest time in
        your setup to be productive and have a pleasant experience building your jobs.
        Each minute you spent improving your workflow will pay off in the future.</p>
        <p>Did I miss something? You can comment on
        <a href="https://github.com/antonmry/galiglobal/pull/37">GitHub</a> or just drop me a note
        on <a href="https://bsky.app/profile/galiglobal.com">BlueSky</a>!</p>
        </div>
        <div id="leaflet-comments" class="mt-4"></div>
      </div>
      <div id="push"></div>
    </div>

    <div id="footer-container"></div>

    <script src="/js/jquery-1.11.1.min.js"></script>
    <script src="/js/bootstrap.min.js" defer></script>
    <script src="/js/prettify.js" defer></script>

    <script>
      async function loadContent(url, elementId) {
        try {
          const response = await fetch(url);
          if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
          const html = await response.text();
          const target = document.getElementById(elementId);
          if (!target) return;
          target.innerHTML = html;

          const scripts = target.querySelectorAll('script[data-execute="true"]');
          scripts.forEach((oldScript) => {
            const newScript = document.createElement('script');
            [...oldScript.attributes].forEach((attr) => newScript.setAttribute(attr.name, attr.value));
            newScript.textContent = oldScript.textContent;
            target.appendChild(newScript);
          });
        } catch (error) {
          console.error(`Error loading ${url}:`, error);
        }
      }

      document.addEventListener('DOMContentLoaded', async () => {
        await loadContent('/navbar.html', 'navbar-container');
        await loadContent('/footer.html', 'footer-container');

        if (typeof prettyPrint === 'function') {
          prettyPrint();
        }
      });
    </script>
  </body>
</html>
